{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mrnfqrbl/sd-forge-colab/blob/main/comfyui.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "s-UlIe6iYp0u",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "94d98df7-dbb7-496d-ecf8-2fb6fed32bcf"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "正在挂载 Google 云盘...\n",
            "/\n",
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "/content/drive/MyDrive\n",
            "/content/drive/MyDrive/ComfyUI\n",
            "-= 正在安装依赖项 =-\n",
            "Looking in indexes: https://pypi.org/simple, https://download.pytorch.org/whl/cu121, https://download.pytorch.org/whl/cu118, https://download.pytorch.org/whl/cu117\n",
            "Requirement already satisfied: xformers!=0.0.18 in /usr/local/lib/python3.11/dist-packages (0.0.29.post2)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 1)) (2.6.0+cu118)\n",
            "Requirement already satisfied: torchsde in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 2)) (0.2.6)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 3)) (0.21.0+cu118)\n",
            "Requirement already satisfied: torchaudio in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 4)) (2.6.0+cu118)\n",
            "Requirement already satisfied: numpy>=1.25.0 in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 5)) (1.26.4)\n",
            "Requirement already satisfied: einops in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 6)) (0.8.0)\n",
            "Requirement already satisfied: transformers>=4.28.1 in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 7)) (4.48.2)\n",
            "Requirement already satisfied: tokenizers>=0.13.3 in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 8)) (0.21.0)\n",
            "Requirement already satisfied: sentencepiece in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 9)) (0.2.0)\n",
            "Requirement already satisfied: safetensors>=0.4.2 in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 10)) (0.5.2)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 11)) (3.11.11)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 12)) (6.0.2)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 13)) (11.1.0)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 14)) (1.13.1)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 15)) (4.67.1)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 16)) (5.9.5)\n",
            "Requirement already satisfied: kornia>=0.7.1 in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 19)) (0.8.0)\n",
            "Requirement already satisfied: spandrel in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 20)) (0.4.1)\n",
            "Requirement already satisfied: soundfile in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 21)) (0.13.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch->-r requirements.txt (line 1)) (3.17.0)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.11/dist-packages (from torch->-r requirements.txt (line 1)) (4.12.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch->-r requirements.txt (line 1)) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch->-r requirements.txt (line 1)) (3.1.5)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch->-r requirements.txt (line 1)) (2024.10.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu11==11.8.89 in /usr/local/lib/python3.11/dist-packages (from torch->-r requirements.txt (line 1)) (11.8.89)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu11==11.8.89 in /usr/local/lib/python3.11/dist-packages (from torch->-r requirements.txt (line 1)) (11.8.89)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu11==11.8.87 in /usr/local/lib/python3.11/dist-packages (from torch->-r requirements.txt (line 1)) (11.8.87)\n",
            "Requirement already satisfied: nvidia-cudnn-cu11==9.1.0.70 in /usr/local/lib/python3.11/dist-packages (from torch->-r requirements.txt (line 1)) (9.1.0.70)\n",
            "Requirement already satisfied: nvidia-cublas-cu11==11.11.3.6 in /usr/local/lib/python3.11/dist-packages (from torch->-r requirements.txt (line 1)) (11.11.3.6)\n",
            "Requirement already satisfied: nvidia-cufft-cu11==10.9.0.58 in /usr/local/lib/python3.11/dist-packages (from torch->-r requirements.txt (line 1)) (10.9.0.58)\n",
            "Requirement already satisfied: nvidia-curand-cu11==10.3.0.86 in /usr/local/lib/python3.11/dist-packages (from torch->-r requirements.txt (line 1)) (10.3.0.86)\n",
            "Requirement already satisfied: nvidia-cusolver-cu11==11.4.1.48 in /usr/local/lib/python3.11/dist-packages (from torch->-r requirements.txt (line 1)) (11.4.1.48)\n",
            "Requirement already satisfied: nvidia-cusparse-cu11==11.7.5.86 in /usr/local/lib/python3.11/dist-packages (from torch->-r requirements.txt (line 1)) (11.7.5.86)\n",
            "Requirement already satisfied: nvidia-nccl-cu11==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch->-r requirements.txt (line 1)) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu11==11.8.86 in /usr/local/lib/python3.11/dist-packages (from torch->-r requirements.txt (line 1)) (11.8.86)\n",
            "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch->-r requirements.txt (line 1)) (3.2.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch->-r requirements.txt (line 1)) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch->-r requirements.txt (line 1)) (1.3.0)\n",
            "Requirement already satisfied: trampoline>=0.1.2 in /usr/local/lib/python3.11/dist-packages (from torchsde->-r requirements.txt (line 2)) (0.1.2)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.24.0 in /usr/local/lib/python3.11/dist-packages (from transformers>=4.28.1->-r requirements.txt (line 7)) (0.28.1)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from transformers>=4.28.1->-r requirements.txt (line 7)) (24.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers>=4.28.1->-r requirements.txt (line 7)) (2024.11.6)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from transformers>=4.28.1->-r requirements.txt (line 7)) (2.32.3)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->-r requirements.txt (line 11)) (2.4.4)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp->-r requirements.txt (line 11)) (1.3.2)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->-r requirements.txt (line 11)) (25.1.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp->-r requirements.txt (line 11)) (1.5.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp->-r requirements.txt (line 11)) (6.1.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->-r requirements.txt (line 11)) (0.2.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->-r requirements.txt (line 11)) (1.18.3)\n",
            "Requirement already satisfied: kornia_rs>=0.1.0 in /usr/local/lib/python3.11/dist-packages (from kornia>=0.7.1->-r requirements.txt (line 19)) (0.1.8)\n",
            "Requirement already satisfied: cffi>=1.0 in /usr/local/lib/python3.11/dist-packages (from soundfile->-r requirements.txt (line 21)) (1.17.1)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.11/dist-packages (from cffi>=1.0->soundfile->-r requirements.txt (line 21)) (2.22)\n",
            "Requirement already satisfied: idna>=2.0 in /usr/local/lib/python3.11/dist-packages (from yarl<2.0,>=1.17.0->aiohttp->-r requirements.txt (line 11)) (3.10)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch->-r requirements.txt (line 1)) (3.0.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->transformers>=4.28.1->-r requirements.txt (line 7)) (3.4.1)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->transformers>=4.28.1->-r requirements.txt (line 7)) (1.26.20)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->transformers>=4.28.1->-r requirements.txt (line 7)) (2025.1.31)\n",
            "使用 Cloudflare Tunnel 运行 ComfyUI\n",
            "--2025-02-08 14:39:55--  https://github.com/cloudflare/cloudflared/releases/latest/download/cloudflared-linux-amd64.deb\n",
            "Resolving github.com (github.com)... 20.205.243.166\n",
            "Connecting to github.com (github.com)|20.205.243.166|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://github.com/cloudflare/cloudflared/releases/download/2025.2.0/cloudflared-linux-amd64.deb [following]\n",
            "--2025-02-08 14:39:55--  https://github.com/cloudflare/cloudflared/releases/download/2025.2.0/cloudflared-linux-amd64.deb\n",
            "Reusing existing connection to github.com:443.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://objects.githubusercontent.com/github-production-release-asset-2e65be/106867604/8176fe8a-cc28-4022-90f5-59d75983238d?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=releaseassetproduction%2F20250208%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20250208T143955Z&X-Amz-Expires=300&X-Amz-Signature=a7fb0237aab169dcfabd3f6b33f4cb2ad9044d1534742fbbda23c5fce7d33e96&X-Amz-SignedHeaders=host&response-content-disposition=attachment%3B%20filename%3Dcloudflared-linux-amd64.deb&response-content-type=application%2Foctet-stream [following]\n",
            "--2025-02-08 14:39:55--  https://objects.githubusercontent.com/github-production-release-asset-2e65be/106867604/8176fe8a-cc28-4022-90f5-59d75983238d?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=releaseassetproduction%2F20250208%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20250208T143955Z&X-Amz-Expires=300&X-Amz-Signature=a7fb0237aab169dcfabd3f6b33f4cb2ad9044d1534742fbbda23c5fce7d33e96&X-Amz-SignedHeaders=host&response-content-disposition=attachment%3B%20filename%3Dcloudflared-linux-amd64.deb&response-content-type=application%2Foctet-stream\n",
            "Resolving objects.githubusercontent.com (objects.githubusercontent.com)... 185.199.110.133, 185.199.109.133, 185.199.111.133, ...\n",
            "Connecting to objects.githubusercontent.com (objects.githubusercontent.com)|185.199.110.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 18543368 (18M) [application/octet-stream]\n",
            "Saving to: ‘cloudflared-linux-amd64.deb’\n",
            "\n",
            "cloudflared-linux-a 100%[===================>]  17.68M  64.3MB/s    in 0.3s    \n",
            "\n",
            "2025-02-08 14:39:58 (64.3 MB/s) - ‘cloudflared-linux-amd64.deb’ saved [18543368/18543368]\n",
            "\n",
            "(Reading database ... 124930 files and directories currently installed.)\n",
            "Preparing to unpack cloudflared-linux-amd64.deb ...\n",
            "Unpacking cloudflared (2025.2.0) over (2025.2.0) ...\n",
            "Setting up cloudflared (2025.2.0) ...\n",
            "Processing triggers for man-db (2.10.2-1) ...\n",
            "Adding extra search path checkpoints /content/drive/MyDrive/ComfyUI/mx/ckpt\n",
            "Adding extra search path clip /content/drive/MyDrive/ComfyUI/mx/clip/\n",
            "Adding extra search path clip_vision /content/drive/MyDrive/ComfyUI/mx/clip_vision/\n",
            "Adding extra search path configs /content/drive/MyDrive/ComfyUI/mx/configs/\n",
            "Adding extra search path controlnet /content/drive/MyDrive/ComfyUI/mx/controlnet/\n",
            "Adding extra search path diffusion_models /content/drive/MyDrive/ComfyUI/mx/diffusion_models\n",
            "Adding extra search path diffusion_models /content/drive/MyDrive/ComfyUI/mx/unet\n",
            "Adding extra search path embeddings /content/drive/MyDrive/ComfyUI/mx/embeddings/\n",
            "Adding extra search path loras /content/drive/MyDrive/ComfyUI/mx/lora\n",
            "Adding extra search path upscale_models /content/drive/MyDrive/ComfyUI/mx/upscale_models/\n",
            "Adding extra search path vae /content/drive/MyDrive/ComfyUI/mx/vae\n",
            "[START] Security scan\n",
            "[DONE] Security scan\n",
            "## ComfyUI-Manager: installing dependencies done.\n",
            "** ComfyUI startup time: 2025-02-08 14:40:00.931\n",
            "** Platform: Linux\n",
            "** Python version: 3.11.11 (main, Dec  4 2024, 08:55:07) [GCC 11.4.0]\n",
            "** Python executable: /usr/bin/python3\n",
            "** ComfyUI Path: /content/drive/MyDrive/ComfyUI\n",
            "** ComfyUI Base Folder Path: /content/drive/MyDrive/ComfyUI\n",
            "** User directory: /content/drive/MyDrive/ComfyUI/user\n",
            "** ComfyUI-Manager config path: /content/drive/MyDrive/ComfyUI/user/default/ComfyUI-Manager/config.ini\n",
            "** Log path: /content/drive/MyDrive/ComfyUI/user/comfyui.log\n",
            "\n",
            "Prestartup times for custom nodes:\n",
            "   4.0 seconds: /content/drive/MyDrive/ComfyUI/custom_nodes/ComfyUI-Manager\n",
            "\n",
            "Checkpoint files will always be loaded safely.\n",
            "Total VRAM 15095 MB, total RAM 12979 MB\n",
            "pytorch version: 2.6.0+cu118\n",
            "xformers version: 0.0.29.post2\n",
            "Set vram state to: NORMAL_VRAM\n",
            "Device: cuda:0 Tesla T4 : cudaMallocAsync\n",
            "Using xformers attention\n",
            "ComfyUI version: 0.3.14\n",
            "[Prompt Server] web root: /content/drive/MyDrive/ComfyUI/web\n",
            "### Loading: ComfyUI-Manager (V3.17.10)\n",
            "### ComfyUI Version: 0.1.0-2-g1a3c5701 | Released on '2025-02-08'\n",
            "\u001b[92m[💾 save_image_extended] AVIF   is supported! Woohoo!\u001b[0m\n",
            "\u001b[92m[💾 save_image_extended] JPEGXL is supported! YeePee!\u001b[0m\n",
            "\u001b[92m[💾 save_image_extended]\u001b[0m version: 2.83\u001b[0m\n",
            "[ComfyUI-Manager] default cache updated: https://raw.githubusercontent.com/ltdrdata/ComfyUI-Manager/main/model-list.json\n",
            "\n",
            "Import times for custom nodes:\n",
            "   0.0 seconds: /content/drive/MyDrive/ComfyUI/custom_nodes/websocket_image_save.py\n",
            "   0.0 seconds: /content/drive/MyDrive/ComfyUI/custom_nodes/comfyui-filepathcreator\n",
            "   0.0 seconds: /content/drive/MyDrive/ComfyUI/custom_nodes/save-image-extended-comfyui\n",
            "   1.4 seconds: /content/drive/MyDrive/ComfyUI/custom_nodes/ComfyUI-Manager\n",
            "\n",
            "\n",
            "ComfyUI 加载完成，尝试启动 cloudflared (如果卡住，cloudflared 可能有问题)\n",
            "\n",
            "[ComfyUI-Manager] default cache updated: https://raw.githubusercontent.com/ltdrdata/ComfyUI-Manager/main/extension-node-map.json\n",
            "[ComfyUI-Manager] default cache updated: https://raw.githubusercontent.com/ltdrdata/ComfyUI-Manager/main/custom-node-list.json\n",
            "[ComfyUI-Manager] default cache updated: https://raw.githubusercontent.com/ltdrdata/ComfyUI-Manager/main/alter-list.json\n",
            "[ComfyUI-Manager] default cache updated: https://raw.githubusercontent.com/ltdrdata/ComfyUI-Manager/main/github-stats.json\n",
            "FETCH ComfyRegistry Data: 5/32\n",
            "ComfyUI 的访问链接: https://pierce-descriptions-bbs-concord.trycloudflare.com                                 |\n",
            "FETCH ComfyRegistry Data: 10/32\n",
            "FETCH ComfyRegistry Data: 15/32\n",
            "FETCH ComfyRegistry Data: 20/32\n",
            "FETCH ComfyRegistry Data: 25/32\n",
            "FETCH ComfyRegistry Data: 30/32\n",
            "FETCH ComfyRegistry Data [DONE]\n",
            "[ComfyUI-Manager] default cache updated: https://api.comfy.org/nodes\n",
            "nightly_channel: https://raw.githubusercontent.com/ltdrdata/ComfyUI-Manager/main/remote\n",
            "FETCH DATA from: https://raw.githubusercontent.com/ltdrdata/ComfyUI-Manager/main/custom-node-list.json [DONE]\n",
            "[ComfyUI-Manager] All startup tasks have been completed.\n",
            "FETCH DATA from: /content/drive/MyDrive/ComfyUI/custom_nodes/ComfyUI-Manager/extension-node-map.json [DONE]\n",
            "FETCH DATA from: /content/drive/MyDrive/ComfyUI/custom_nodes/ComfyUI-Manager/extension-node-map.json [DONE]\n",
            "FETCH DATA from: /content/drive/MyDrive/ComfyUI/custom_nodes/ComfyUI-Manager/extension-node-map.json [DONE]\n",
            "FETCH DATA from: /content/drive/MyDrive/ComfyUI/user/default/ComfyUI-Manager/cache/1742899825_extension-node-map.json [DONE]\n",
            "[ComfyUI-Manager] The ComfyRegistry cache update is still in progress, so an outdated cache is being used.\n",
            "nightly_channel: https://raw.githubusercontent.com/ltdrdata/ComfyUI-Manager/main/cache\n",
            "FETCH DATA from: /content/drive/MyDrive/ComfyUI/user/default/ComfyUI-Manager/cache/1514988643_custom-node-list.json [DONE]\n",
            "FETCH DATA from: /content/drive/MyDrive/ComfyUI/user/default/ComfyUI-Manager/cache/746607195_github-stats.json [DONE]\n",
            "FETCH DATA from: /content/drive/MyDrive/ComfyUI/user/default/ComfyUI-Manager/cache/832903789_extras.json [DONE]\n",
            "got prompt\n",
            "model weight dtype torch.float16, manual cast: None\n",
            "model_type V_PREDICTION\n",
            "Using xformers attention in VAE\n",
            "Using xformers attention in VAE\n",
            "VAE load device: cuda:0, offload device: cpu, dtype: torch.float32\n",
            "Requested to load SDXLClipModel\n",
            "loaded completely 9.5367431640625e+25 1560.802734375 True\n",
            "CLIP/text encoder model load device: cuda:0, offload device: cpu, current: cuda:0, dtype: torch.float16\n",
            "loaded diffusion model directly to GPU\n",
            "Requested to load SDXL\n",
            "loaded completely 9.5367431640625e+25 4897.0483474731445 True\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (116 > 77). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (116 > 77). Running this sequence through the model will result in indexing errors\n",
            "Requested to load SDXLClipModel\n",
            "loaded completely 8855.828739929198 1560.802734375 True\n",
            "Requested to load SDXL\n",
            "loaded completely 11513.187393188477 4897.0483474731445 True\n",
            "100% 25/25 [02:22<00:00,  5.70s/it]\n",
            "Requested to load AutoencoderKL\n",
            "loaded completely 1291.7459899902344 319.11416244506836 True\n",
            "Prompt executed in 227.58 seconds\n",
            "got prompt\n",
            "SaveImageExtended 2.83 error: An error occurred while creating the subfolder or saving the image: [Errno 2] No such file or directory: '/content/drive/MyDrive/ComfyUI/output/2025-02-08/ComfyUI/0001/2025-02-08 14-56-18.png'\n",
            "!!! Exception during processing !!! object of type 'NoneType' has no len()\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/drive/MyDrive/ComfyUI/execution.py\", line 327, in execute\n",
            "    output_data, output_ui, has_subgraph = get_output_data(obj, input_data_all, execution_block_cb=execution_block_cb, pre_execute_cb=pre_execute_cb)\n",
            "                                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/drive/MyDrive/ComfyUI/execution.py\", line 232, in get_output_data\n",
            "    output = merge_result_data(results, obj)\n",
            "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/drive/MyDrive/ComfyUI/execution.py\", line 180, in merge_result_data\n",
            "    output_is_list = [False] * len(results[0])\n",
            "                               ^^^^^^^^^^^^^^^\n",
            "TypeError: object of type 'NoneType' has no len()\n",
            "\n",
            "Prompt executed in 0.11 seconds\n",
            "got prompt\n",
            "SaveImageExtended 2.83 error: An error occurred while creating the subfolder or saving the image: [Errno 2] No such file or directory: '/content/drive/MyDrive/ComfyUI/output/2025-02-08/ComfyUI/0001/2025-02-08 14-56-28.png'\n",
            "!!! Exception during processing !!! object of type 'NoneType' has no len()\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/drive/MyDrive/ComfyUI/execution.py\", line 327, in execute\n",
            "    output_data, output_ui, has_subgraph = get_output_data(obj, input_data_all, execution_block_cb=execution_block_cb, pre_execute_cb=pre_execute_cb)\n",
            "                                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/drive/MyDrive/ComfyUI/execution.py\", line 232, in get_output_data\n",
            "    output = merge_result_data(results, obj)\n",
            "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/drive/MyDrive/ComfyUI/execution.py\", line 180, in merge_result_data\n",
            "    output_is_list = [False] * len(results[0])\n",
            "                               ^^^^^^^^^^^^^^^\n",
            "TypeError: object of type 'NoneType' has no len()\n",
            "\n",
            "Prompt executed in 0.08 seconds\n",
            "got prompt\n",
            "SaveImageExtended 2.83 error: An error occurred while creating the subfolder or saving the image: [Errno 2] No such file or directory: '/content/drive/MyDrive/ComfyUI/output/2025-02-08/ComfyUI/0001/2025-02-08 14-56-38.png'\n",
            "!!! Exception during processing !!! object of type 'NoneType' has no len()\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/drive/MyDrive/ComfyUI/execution.py\", line 327, in execute\n",
            "    output_data, output_ui, has_subgraph = get_output_data(obj, input_data_all, execution_block_cb=execution_block_cb, pre_execute_cb=pre_execute_cb)\n",
            "                                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/drive/MyDrive/ComfyUI/execution.py\", line 232, in get_output_data\n",
            "    output = merge_result_data(results, obj)\n",
            "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/drive/MyDrive/ComfyUI/execution.py\", line 180, in merge_result_data\n",
            "    output_is_list = [False] * len(results[0])\n",
            "                               ^^^^^^^^^^^^^^^\n",
            "TypeError: object of type 'NoneType' has no len()\n",
            "\n",
            "Prompt executed in 0.08 seconds\n",
            "got prompt\n",
            "SaveImageExtended 2.83 error: An error occurred while creating the subfolder or saving the image: [Errno 2] No such file or directory: '/content/drive/MyDrive/ComfyUI/output/2025-02-08/ComfyUI/0001/2025-02-08 14-57-54.png'\n",
            "!!! Exception during processing !!! object of type 'NoneType' has no len()\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/drive/MyDrive/ComfyUI/execution.py\", line 327, in execute\n",
            "    output_data, output_ui, has_subgraph = get_output_data(obj, input_data_all, execution_block_cb=execution_block_cb, pre_execute_cb=pre_execute_cb)\n",
            "                                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/drive/MyDrive/ComfyUI/execution.py\", line 232, in get_output_data\n",
            "    output = merge_result_data(results, obj)\n",
            "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/drive/MyDrive/ComfyUI/execution.py\", line 180, in merge_result_data\n",
            "    output_is_list = [False] * len(results[0])\n",
            "                               ^^^^^^^^^^^^^^^\n",
            "TypeError: object of type 'NoneType' has no len()\n",
            "\n",
            "Prompt executed in 0.08 seconds\n",
            "got prompt\n",
            "Prompt executed in 17.79 seconds\n",
            "got prompt\n",
            "Prompt executed in 0.00 seconds\n",
            "got prompt\n",
            "Prompt executed in 0.00 seconds\n",
            "got prompt\n",
            "Prompt executed in 0.01 seconds\n",
            "got prompt\n",
            "Prompt executed in 17.70 seconds\n",
            "got prompt\n",
            "Requested to load SDXL\n",
            "loaded completely 12746.875972747803 4897.0483474731445 True\n",
            "100% 25/25 [02:10<00:00,  5.22s/it]\n",
            "Prompt executed in 164.89 seconds\n",
            "got prompt\n",
            "Requested to load SDXL\n",
            "got prompt\n",
            "loaded completely 13391.675972747802 4897.0483474731445 True\n",
            "100% 25/25 [00:33<00:00,  1.33s/it]\n",
            "Prompt executed in 43.32 seconds\n",
            "got prompt\n",
            "Prompt executed in 0.40 seconds\n",
            "got prompt\n",
            "Requested to load SDXLClipModel\n",
            "loaded completely 11352.140854644775 1560.802734375 True\n",
            "loaded completely 11830.873230743407 4897.0483474731445 True\n",
            "100% 25/25 [00:33<00:00,  1.35s/it]\n",
            "Prompt executed in 40.69 seconds\n",
            "got prompt\n",
            "Prompt executed in 3.67 seconds\n",
            "got prompt\n",
            "Prompt executed in 0.00 seconds\n",
            "got prompt\n",
            "Prompt executed in 0.00 seconds\n",
            "got prompt\n",
            "Prompt executed in 0.00 seconds\n",
            "got prompt\n",
            "loaded completely 13391.675972747802 4897.0483474731445 True\n",
            "100% 25/25 [00:33<00:00,  1.34s/it]\n",
            "Prompt executed in 41.53 seconds\n",
            "got prompt\n",
            "got prompt\n",
            "loaded completely 12746.875972747803 4897.0483474731445 True\n",
            "  0% 0/25 [00:00<?, ?it/s]got prompt\n",
            "  4% 1/25 [00:02<00:55,  2.30s/it]got prompt\n",
            " 52% 13/25 [01:09<01:09,  5.76s/it]got prompt\n",
            "got prompt\n",
            " 72% 18/25 [01:38<00:40,  5.78s/it]got prompt\n",
            "got prompt\n",
            "got prompt\n",
            " 76% 19/25 [01:44<00:34,  5.76s/it]got prompt\n",
            "100% 25/25 [02:18<00:00,  5.54s/it]\n",
            "got prompt\n",
            "got prompt\n",
            "Prompt executed in 170.15 seconds\n",
            "Prompt executed in 0.00 seconds\n",
            "Prompt executed in 0.00 seconds\n",
            "Prompt executed in 0.00 seconds\n",
            "Requested to load SDXLClipModel\n",
            "loaded completely 11352.140854644775 1560.802734375 True\n",
            "loaded completely 11186.073230743408 4897.0483474731445 True\n",
            " 24% 6/25 [00:31<01:49,  5.74s/it]got prompt\n",
            "got prompt\n",
            "100% 25/25 [02:21<00:00,  5.65s/it]\n",
            "Prompt executed in 176.56 seconds\n",
            "Prompt executed in 0.00 seconds\n",
            "Requested to load SDXLClipModel\n",
            "loaded completely 11352.140854644775 1560.802734375 True\n",
            "loaded completely 11186.073230743408 4897.0483474731445 True\n",
            "100% 25/25 [02:16<00:00,  5.46s/it]\n",
            "Prompt executed in 169.22 seconds\n",
            "Prompt executed in 0.00 seconds\n",
            "Prompt executed in 0.00 seconds\n",
            "Prompt executed in 0.00 seconds\n",
            "Requested to load SDXLClipModel\n",
            "loaded completely 11352.140854644775 1560.802734375 True\n",
            "loaded completely 11186.073230743408 4897.0483474731445 True\n",
            "100% 25/25 [02:16<00:00,  5.46s/it]\n",
            "Prompt executed in 166.01 seconds\n",
            "Prompt executed in 0.01 seconds\n",
            "Requested to load SDXLClipModel\n",
            "loaded completely 11352.140854644775 1560.802734375 True\n",
            "loaded completely 11186.073230743408 4897.0483474731445 True\n",
            " 20% 5/25 [00:25<01:51,  5.58s/it]got prompt\n",
            " 24% 6/25 [00:31<01:48,  5.73s/it]got prompt\n",
            " 28% 7/25 [00:37<01:44,  5.79s/it]got prompt\n",
            "got prompt\n",
            " 32% 8/25 [00:43<01:38,  5.80s/it]got prompt\n",
            " 36% 9/25 [00:49<01:32,  5.80s/it]got prompt\n",
            " 40% 10/25 [00:55<01:26,  5.79s/it]got prompt\n",
            " 44% 11/25 [01:00<01:20,  5.76s/it]got prompt\n",
            " 48% 12/25 [01:06<01:14,  5.74s/it]got prompt\n",
            " 52% 13/25 [01:12<01:08,  5.73s/it]got prompt\n",
            " 56% 14/25 [01:17<01:02,  5.71s/it]got prompt\n",
            " 60% 15/25 [01:23<00:57,  5.71s/it]got prompt\n",
            " 64% 16/25 [01:29<00:51,  5.71s/it]got prompt\n",
            " 68% 17/25 [01:34<00:45,  5.72s/it]got prompt\n",
            "100% 25/25 [02:21<00:00,  5.65s/it]\n",
            "Prompt executed in 177.99 seconds\n",
            "Prompt executed in 0.00 seconds\n",
            "Requested to load SDXLClipModel\n",
            "loaded completely 11352.140854644775 1560.802734375 True\n",
            "loaded completely 11186.073230743408 4897.0483474731445 True\n",
            "100% 25/25 [02:16<00:00,  5.46s/it]\n",
            "Prompt executed in 172.17 seconds\n",
            "Prompt executed in 0.00 seconds\n",
            "Prompt executed in 0.00 seconds\n",
            "Prompt executed in 0.00 seconds\n",
            "Prompt executed in 0.00 seconds\n",
            "Prompt executed in 0.00 seconds\n",
            "Prompt executed in 0.00 seconds\n",
            "Prompt executed in 0.00 seconds\n",
            "Prompt executed in 0.00 seconds\n",
            "Prompt executed in 0.00 seconds\n",
            "Prompt executed in 0.00 seconds\n",
            "Prompt executed in 0.00 seconds\n",
            "Prompt executed in 0.00 seconds\n",
            "Prompt executed in 0.00 seconds\n",
            "got prompt\n",
            "Prompt executed in 0.00 seconds\n",
            "got prompt\n",
            "Prompt executed in 0.00 seconds\n",
            "got prompt\n",
            "Requested to load SDXLClipModel\n",
            "loaded completely 11352.140854644775 1560.802734375 True\n",
            "loaded completely 11186.073230743408 4897.0483474731445 True\n",
            "  4% 1/25 [00:02<01:00,  2.50s/it]got prompt\n",
            "  8% 2/25 [00:08<01:42,  4.44s/it]got prompt\n",
            " 12% 3/25 [00:14<01:52,  5.09s/it]got prompt\n",
            " 40% 10/25 [00:53<01:22,  5.51s/it]got prompt\n",
            " 44% 11/25 [00:58<01:16,  5.49s/it]got prompt\n",
            " 76% 19/25 [01:43<00:33,  5.57s/it]got prompt\n",
            " 80% 20/25 [01:48<00:27,  5.59s/it]got prompt\n",
            "100% 25/25 [02:16<00:00,  5.47s/it]\n",
            "Prompt executed in 166.43 seconds\n",
            "Prompt executed in 0.00 seconds\n",
            "Prompt executed in 0.00 seconds\n",
            "Prompt executed in 0.00 seconds\n",
            "Requested to load SDXLClipModel\n",
            "loaded completely 11352.140854644775 1560.802734375 True\n",
            "loaded completely 11186.073230743408 4897.0483474731445 True\n",
            " 12% 3/25 [00:13<01:45,  4.81s/it]got prompt\n",
            " 16% 4/25 [00:19<01:48,  5.15s/it]got prompt\n",
            "100% 25/25 [02:16<00:00,  5.45s/it]\n",
            "Prompt executed in 166.06 seconds\n",
            "Prompt executed in 0.00 seconds\n",
            "Requested to load SDXLClipModel\n",
            "loaded completely 11352.140854644775 1560.802734375 True\n",
            "loaded completely 11186.073230743408 4897.0483474731445 True\n",
            "100% 25/25 [02:16<00:00,  5.45s/it]\n",
            "Prompt executed in 172.05 seconds\n",
            "Requested to load SDXLClipModel\n",
            "loaded completely 11352.140854644775 1560.802734375 True\n",
            "loaded completely 11186.073230743408 4897.0483474731445 True\n",
            "100% 25/25 [02:16<00:00,  5.45s/it]\n",
            "Prompt executed in 165.30 seconds\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/drive/MyDrive/ComfyUI/main.py\", line 300, in <module>\n",
            "    event_loop.run_until_complete(start_all_func())\n",
            "  File \"/usr/lib/python3.11/asyncio/base_events.py\", line 641, in run_until_complete\n",
            "    self.run_forever()\n",
            "  File \"/usr/lib/python3.11/asyncio/base_events.py\", line 608, in run_forever\n",
            "    self._run_once()\n",
            "  File \"/usr/lib/python3.11/asyncio/base_events.py\", line 1898, in _run_once\n",
            "    event_list = self._selector.select(timeout)\n",
            "                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/lib/python3.11/selectors.py\", line 468, in select\n",
            "    fd_event_list = self._selector.poll(timeout, max_ev)\n",
            "                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "KeyboardInterrupt\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/drive/MyDrive/ComfyUI/main.py\", line 302, in <module>\n",
            "    logging.info(\"\\nStopped server\")\n",
            "  File \"/usr/lib/python3.11/logging/__init__.py\", line 2141, in info\n",
            "    root.info(msg, *args, **kwargs)\n",
            "  File \"/usr/lib/python3.11/logging/__init__.py\", line 1489, in info\n",
            "    self._log(INFO, msg, args, **kwargs)\n",
            "  File \"/usr/lib/python3.11/logging/__init__.py\", line 1610, in _log\n",
            "    def _log(self, level, msg, args, exc_info=None, extra=None, stack_info=False,\n",
            "\n",
            "KeyboardInterrupt\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name '检查cloudflared_URL' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-2-d5a6cb14909c>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    218\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    219\u001b[0m    \u001b[0;31m# 在 ComfyUI 启动后 10 秒启动 URL 检查线程\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 220\u001b[0;31m    \u001b[0mthreading\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mThread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtarget\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0m检查cloudflared_URL\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdaemon\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstart\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    221\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    222\u001b[0m \u001b[0;32melif\u001b[0m \u001b[0m运行方式\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"localtunnel\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name '检查cloudflared_URL' is not defined"
          ]
        }
      ],
      "source": [
        " # @title ComfyUI 一键安装脚本 (Google Colab)\n",
        "\n",
        "# @markdown 确保您已连接到 GPU 运行时 (运行时 -> 更改运行时类型 -> GPU)\n",
        "\n",
        "# @markdown **环境设置**\n",
        "\n",
        "使用_谷歌云盘 = True  # @param {type:\"boolean\"}\n",
        "更新_ComfyUI = True  # @param {type:\"boolean\"}\n",
        "工作区 = '/content/ComfyUI'\n",
        "\n",
        "选项 = {}\n",
        "选项['使用_谷歌云盘'] = 使用_谷歌云盘\n",
        "选项['更新_ComfyUI'] = 更新_ComfyUI\n",
        "\n",
        "if 选项['使用_谷歌云盘']:\n",
        "    print(\"正在挂载 Google 云盘...\")\n",
        "    %cd /\n",
        "\n",
        "    from google.colab import drive\n",
        "    drive.mount('/content/drive')\n",
        "\n",
        "    工作区 = \"/content/drive/MyDrive/ComfyUI\"\n",
        "    %cd /content/drive/MyDrive\n",
        "\n",
        "![ ! -d $工作区 ] && echo -= 首次安装 ComfyUI =- && git clone https://github.com/mrnfqrbl/ComfyUI\n",
        "%cd $工作区\n",
        "\n",
        "if 选项['更新_ComfyUI']:\n",
        "  # !git remote set-url origin https://github.com/mrnfqrbl/ComfyUI\n",
        "  print(\"-= 正在更新 ComfyUI =-\")\n",
        "\n",
        "  !git pull\n",
        "\n",
        "print(\"-= 正在安装依赖项 =-\")\n",
        "!pip install xformers!=0.0.18 -r requirements.txt --extra-index-url https://download.pytorch.org/whl/cu121 --extra-index-url https://download.pytorch.org/whl/cu118 --extra-index-url https://download.pytorch.org/whl/cu117\n",
        "\n",
        "\n",
        "\n",
        "# 检查点 (Checkpoints)\n",
        "\n",
        "# SDXL\n",
        "# 推荐工作流示例: https://comfyanonymous.github.io/ComfyUI_examples/sdxl/\n",
        "\n",
        "#!wget -c https://huggingface.co/stabilityai/stable-diffusion-xl-base-1.0/resolve/main/sd_xl_base_1.0.safetensors -P ./models/checkpoints/\n",
        "#!wget -c https://huggingface.co/stabilityai/stable-diffusion-xl-refiner-1.0/resolve/main/sd_xl_refiner_1.0.safetensors -P ./models/checkpoints/\n",
        "\n",
        "# SDXL ReVision\n",
        "#!wget -c https://huggingface.co/comfyanonymous/clip_vision_g/resolve/main/clip_vision_g.safetensors -P ./models/clip_vision/\n",
        "\n",
        "# SD1.5\n",
        "# !wget -c https://huggingface.co/Comfy-Org/stable-diffusion-v1-5-archive/resolve/main/v1-5-pruned-emaonly-fp16.safetensors -P ./models/checkpoints/\n",
        "\n",
        "# SD2\n",
        "#!wget -c https://huggingface.co/stabilityai/stable-diffusion-2-1-base/resolve/main/v2-1_512-ema-pruned.safetensors -P ./models/checkpoints/\n",
        "#!wget -c https://huggingface.co/stabilityai/stable-diffusion-2-1/resolve/main/v2-1_768-ema-pruned.safetensors -P ./models/checkpoints/\n",
        "\n",
        "# 一些 SD1.5 动漫风格模型\n",
        "#!wget -c https://huggingface.co/WarriorMama777/OrangeMixs/resolve/main/Models/AbyssOrangeMix2/AbyssOrangeMix2_hard.safetensors -P ./models/checkpoints/\n",
        "#!wget -c https://huggingface.co/WarriorMama777/OrangeMixs/resolve/main/Models/AbyssOrangeMix3/AOM3A1_orangemixs.safetensors -P ./models/checkpoints/\n",
        "#!wget -c https://huggingface.co/WarriorMama777/OrangeMixs/resolve/main/Models/AbyssOrangeMix3/AOM3A3_orangemixs.safetensors -P ./models/checkpoints/\n",
        "#!wget -c https://huggingface.co/Linaqruf/anything-v3.0/resolve/main/anything-v3-fp16-pruned.safetensors -P ./models/checkpoints/\n",
        "\n",
        "# Waifu Diffusion 1.5 (动漫风格 SD2.x 768-v)\n",
        "#!wget -c https://huggingface.co/waifu-diffusion/wd-1-5-beta3/resolve/main/wd-illusion-fp16.safetensors -P ./models/checkpoints/\n",
        "\n",
        "# unCLIP 模型\n",
        "#!wget -c https://huggingface.co/comfyanonymous/illuminatiDiffusionV1_v11_unCLIP/resolve/main/illuminatiDiffusionV1_v11-unclip-h-fp16.safetensors -P ./models/checkpoints/\n",
        "#!wget -c https://huggingface.co/comfyanonymous/wd-1.5-beta2_unCLIP/resolve/main/wd-1-5-beta2-aesthetic-unclip-h-fp16.safetensors -P ./models/checkpoints/\n",
        "\n",
        "# VAE\n",
        "# !wget -c https://huggingface.co/stabilityai/sd-vae-ft-mse-original/resolve/main/vae-ft-mse-840000-ema-pruned.safetensors -P ./models/vae/\n",
        "#!wget -c https://huggingface.co/WarriorMama777/OrangeMixs/resolve/main/VAEs/orangemix.vae.pt -P ./models/vae/\n",
        "#!wget -c https://huggingface.co/hakurei/waifu-diffusion-v1-4/resolve/main/vae/kl-f8-anime2.ckpt -P ./models/vae/\n",
        "\n",
        "# Loras\n",
        "#!wget -c https://civitai.com/api/download/models/10350 -O ./models/loras/theovercomer8sContrastFix_sd21768.safetensors #theovercomer8sContrastFix SD2.x 768-v\n",
        "#!wget -c https://civitai.com/api/download/models/10638 -O ./models/loras/theovercomer8sContrastFix_sd15.safetensors #theovercomer8sContrastFix SD1.x\n",
        "#!wget -c https://huggingface.co/stabilityai/stable-diffusion-xl-base-1.0/resolve/main/sd_xl_offset_example-lora_1.0.safetensors -P ./models/loras/ #SDXL offset noise lora\n",
        "\n",
        "# T2I-Adapter\n",
        "#!wget -c https://huggingface.co/TencentARC/T2I-Adapter/resolve/main/models/t2iadapter_depth_sd14v1.pth -P ./models/controlnet/\n",
        "#!wget -c https://huggingface.co/TencentARC/T2I-Adapter/resolve/main/models/t2iadapter_seg_sd14v1.pth -P ./models/controlnet/\n",
        "#!wget -c https://huggingface.co/TencentARC/T2I-Adapter/resolve/main/models/t2iadapter_sketch_sd14v1.pth -P ./models/controlnet/\n",
        "#!wget -c https://huggingface.co/TencentARC/T2I-Adapter/resolve/main/models/t2iadapter_keypose_sd14v1.pth -P ./models/controlnet/\n",
        "#!wget -c https://huggingface.co/TencentARC/T2I-Adapter/resolve/main/models/t2iadapter_openpose_sd14v1.pth -P ./models/controlnet/\n",
        "#!wget -c https://huggingface.co/TencentARC/T2I-Adapter/resolve/main/models/t2iadapter_color_sd14v1.pth -P ./models/controlnet/\n",
        "#!wget -c https://huggingface.co/TencentARC/T2I-Adapter/resolve/main/models/t2iadapter_canny_sd14v1.pth -P ./models/controlnet/\n",
        "\n",
        "# T2I Styles Model\n",
        "#!wget -c https://huggingface.co/TencentARC/T2I-Adapter/resolve/main/models/t2iadapter_style_sd14v1.pth -P ./models/style_models/\n",
        "\n",
        "# CLIPVision 模型 (styles model 需要)\n",
        "#!wget -c https://huggingface.co/openai/clip-vit-large-patch14/resolve/main/pytorch_model.bin -O ./models/clip_vision/clip_vit14.bin\n",
        "\n",
        "# ControlNet\n",
        "#!wget -c https://huggingface.co/comfyanonymous/ControlNet-v1-1_fp16_safetensors/resolve/main/control_v11e_sd15_ip2p_fp16.safetensors -P ./models/controlnet/\n",
        "#!wget -c https://huggingface.co/comfyanonymous/ControlNet-v1-1_fp16_safetensors/resolve/main/control_v11e_sd15_shuffle_fp16.safetensors -P ./models/controlnet/\n",
        "#!wget -c https://huggingface.co/comfyanonymous/ControlNet-v1-1_fp16_safetensors/resolve/main/control_v11p_sd15_canny_fp16.safetensors -P ./models/controlnet/\n",
        "#!wget -c https://huggingface.co/comfyanonymous/ControlNet-v1-1_fp16_safetensors/resolve/main/control_v11f1p_sd15_depth_fp16.safetensors -P ./models/controlnet/\n",
        "#!wget -c https://huggingface.co/comfyanonymous/ControlNet-v1-1_fp16_safetensors/resolve/main/control_v11p_sd15_inpaint_fp16.safetensors -P ./models/controlnet/\n",
        "#!wget -c https://huggingface.co/comfyanonymous/ControlNet-v1-1_fp16_safetensors/resolve/main/control_v11p_sd15_lineart_fp16.safetensors -P ./models/controlnet/\n",
        "#!wget -c https://huggingface.co/comfyanonymous/ControlNet-v1-1_fp16_safetensors/resolve/main/control_v11p_sd15_mlsd_fp16.safetensors -P ./models/controlnet/\n",
        "#!wget -c https://huggingface.co/comfyanonymous/ControlNet-v1-1_fp16_safetensors/resolve/main/control_v11p_sd15_normalbae_fp16.safetensors -P ./models/controlnet/\n",
        "#!wget -c https://huggingface.co/comfyanonymous/ControlNet-v1-1_fp16_safetensors/resolve/main/control_v11p_sd15_openpose_fp16.safetensors -P ./models/controlnet/\n",
        "#!wget -c https://huggingface.co/comfyanonymous/ControlNet-v1-1_fp16_safetensors/resolve/main/control_v11p_sd15_scribble_fp16.safetensors -P ./models/controlnet/\n",
        "#!wget -c https://huggingface.co/comfyanonymous/ControlNet-v1-1_fp16_safetensors/resolve/main/control_v11p_sd15_seg_fp16.safetensors -P ./models/controlnet/\n",
        "#!wget -c https://huggingface.co/comfyanonymous/ControlNet-v1-1_fp16_safetensors/resolve/main/control_v11p_sd15_softedge_fp16.safetensors -P ./models/controlnet/\n",
        "#!wget -c https://huggingface.co/comfyanonymous/ControlNet-v1-1_fp16_safetensors/resolve/main/control_v11p_sd15s2_lineart_anime_fp16.safetensors -P ./models/controlnet/\n",
        "#!wget -c https://huggingface.co/comfyanonymous/ControlNet-v1-1_fp16_safetensors/resolve/main/control_v11u_sd15_tile_fp16.safetensors -P ./models/controlnet/\n",
        "\n",
        "# ControlNet SDXL\n",
        "#!wget -c https://huggingface.co/stabilityai/control-lora/resolve/main/control-LoRAs-rank256/control-lora-canny-rank256.safetensors -P ./models/controlnet/\n",
        "#!wget -c https://huggingface.co/stabilityai/control-lora/resolve/main/control-LoRAs-rank256/control-lora-depth-rank256.safetensors -P ./models/controlnet/\n",
        "#!wget -c https://huggingface.co/stabilityai/control-lora/resolve/main/control-LoRAs-rank256/control-lora-recolor-rank256.safetensors -P ./models/controlnet/\n",
        "#!wget -c https://huggingface.co/stabilityai/control-lora/resolve/main/control-LoRAs-rank256/control-lora-sketch-rank256.safetensors -P ./models/controlnet/\n",
        "\n",
        "# Controlnet Preprocessor nodes by Fannovel16\n",
        "#!cd custom_nodes && git clone https://github.com/Fannovel16/comfy_controlnet_preprocessors; cd comfy_controlnet_preprocessors && python install.py\n",
        "\n",
        "# GLIGEN\n",
        "#!wget -c https://huggingface.co/comfyanonymous/GLIGEN_pruned_safetensors/resolve/main/gligen_sd14_textbox_pruned_fp16.safetensors -P ./models/gligen/\n",
        "\n",
        "# ESRGAN 放大模型\n",
        "#!wget -c https://github.com/xinntao/Real-ESRGAN/releases/download/v0.1.0/RealESRGAN_x4plus.pth -P ./models/upscale_models/\n",
        "#!wget -c https://huggingface.co/sberbank-ai/Real-ESRGAN/resolve/main/RealESRGAN_x2.pth -P ./models/upscale_models/\n",
        "#!wget -c https://huggingface.co/sberbank-ai/Real-ESRGAN/resolve/main/RealESRGAN_x4.pth -P ./models/upscale_models/\n",
        "\n",
        "安装自定义节点=True #@param {type:\"boolean\"}\n",
        "\n",
        "if 安装自定义节点:\n",
        "  !echo -= Install custom nodes dependencies =-\n",
        "  !pip install GitPython\n",
        "  !python custom_nodes/ComfyUI-Manager/cm-cli.py restore-dependencies\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# @markdown **运行 ComfyUI**\n",
        "\n",
        "# @markdown 选择一种运行 ComfyUI 的方式\n",
        "\n",
        "运行方式 = \"Cloudflare Tunnel\" #@param [\"Cloudflare Tunnel\", \"localtunnel\", \"Colab iframe\"]\n",
        "\n",
        "if 运行方式 == \"Cloudflare Tunnel\":\n",
        "\n",
        "    print(\"使用 Cloudflare Tunnel 运行 ComfyUI\")\n",
        "    !wget -O cloudflared-linux-amd64.deb https://github.com/cloudflare/cloudflared/releases/latest/download/cloudflared-linux-amd64.deb\n",
        "    !dpkg -i cloudflared-linux-amd64.deb\n",
        "\n",
        "    import subprocess\n",
        "    import threading\n",
        "    import time\n",
        "    import socket\n",
        "    import urllib.request\n",
        "\n",
        "    def 隧道线程(端口):\n",
        "      while True:\n",
        "          time.sleep(0.5)\n",
        "          套接字 = socket.socket(socket.AF_INET, socket.SOCK_STREAM)\n",
        "          结果 = 套接字.connect_ex(('127.0.0.1', 端口))\n",
        "          if 结果 == 0:\n",
        "            break\n",
        "          套接字.close()\n",
        "      print(\"\\nComfyUI 加载完成，尝试启动 cloudflared (如果卡住，cloudflared 可能有问题)\\n\")\n",
        "\n",
        "      def 启动cloudflared():\n",
        "        global cloudflared_url  # 使用全局变量存储 cloudflared URL\n",
        "        cloudflared_url = None\n",
        "        进程 = subprocess.Popen([\"cloudflared\", \"tunnel\", \"--url\", \"http://127.0.0.1:{}\".format(端口)], stdout=subprocess.PIPE, stderr=subprocess.PIPE)\n",
        "        for 行 in 进程.stderr:\n",
        "          文本 = 行.decode()\n",
        "          if \"trycloudflare.com \" in 文本:\n",
        "            cloudflared_url = 文本[文本.find(\"http\"):].strip()  # 保存 URL 并去除首尾空格\n",
        "            print(\"ComfyUI 的访问链接:\", cloudflared_url)\n",
        "            break\n",
        "        return 进程\n",
        "\n",
        "      cloudflared_进程 = 启动cloudflared()  # 首次启动 cloudflared\n",
        "      cloudflared_url = None # 初始化 cloudflared_url\n",
        "\n",
        "      def 检查cloudflared_URL():\n",
        "        global cloudflared_url\n",
        "        time.sleep(10)  # 等待 10 秒，确保 cloudflared 和 ComfyUI 都启动完成\n",
        "        if cloudflared_url:\n",
        "          try:\n",
        "            # 尝试访问 cloudflared URL\n",
        "            请求 = urllib.request.Request(cloudflared_url, method=\"HEAD\")\n",
        "            响应 = urllib.request.urlopen(请求, timeout=5) # 设置超时时间为 5 秒\n",
        "            if 响应.status == 200:\n",
        "              print(\"Cloudflare Tunnel URL 可访问\")\n",
        "            else:\n",
        "              print(\"Cloudflare Tunnel URL 访问失败，状态码:\", 响应.status)\n",
        "              cloudflared_进程.terminate()  # 终止旧的 cloudflared 进程\n",
        "              cloudflared_进程 = 启动cloudflared()  # 重新启动 cloudflared\n",
        "              print(\"已重新启动 cloudflared，生成新的 URL\")\n",
        "\n",
        "          except urllib.error.URLError as e:\n",
        "            print(\"Cloudflare Tunnel URL 访问失败:\", e)\n",
        "            cloudflared_进程.terminate()  # 终止旧的 cloudflared 进程\n",
        "            cloudflared_进程 = 启动cloudflared()  # 重新启动 cloudflared\n",
        "            print(\"已重新启动 cloudflared，生成新的 URL\")\n",
        "          except Exception as e:\n",
        "            print(\"检查 Cloudflare Tunnel URL 时发生错误:\", e)\n",
        "            cloudflared_进程.terminate()  # 终止旧的 cloudflared 进程\n",
        "            cloudflared_进程 = 启动cloudflared()  # 重新启动 cloudflared\n",
        "            print(\"已重新启动 cloudflared，生成新的 URL\")\n",
        "        else:\n",
        "          print(\"Cloudflare Tunnel URL 尚未生成，等待...\")\n",
        "          cloudflared_进程.terminate()  # 终止旧的 cloudflared 进程\n",
        "          cloudflared_进程 = 启动cloudflared()  # 重新启动 cloudflared\n",
        "          print(\"已重新启动 cloudflared，生成新的 URL\")\n",
        "\n",
        "      # 将线程启动移动到 ComfyUI 启动之后\n",
        "\n",
        "    threading.Thread(target=隧道线程, daemon=True, args=(8188,)).start()\n",
        "\n",
        "    !python main.py --dont-print-server\n",
        "\n",
        "    # 在 ComfyUI 启动后 10 秒启动 URL 检查线程\n",
        "    threading.Thread(target=检查cloudflared_URL, daemon=True).start()\n",
        "\n",
        "elif 运行方式 == \"localtunnel\":\n",
        "    print(\"使用 localtunnel 运行 ComfyUI\")\n",
        "    !npm install -g localtunnel\n",
        "\n",
        "    import threading\n",
        "    import time\n",
        "    import socket\n",
        "    import urllib\n",
        "    import subprocess\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "    def 隧道线程(端口):\n",
        "      while True:\n",
        "          time.sleep(0.5)\n",
        "          套接字 = socket.socket(socket.AF_INET, socket.SOCK_STREAM)\n",
        "          结果 = 套接字.connect_ex(('127.0.0.1', 端口))\n",
        "          if 结果 == 0:\n",
        "            break\n",
        "          套接字.close()\n",
        "      print(\"\\nComfyUI 加载完成，尝试启动 localtunnel (如果卡住，localtunnel 可能有问题)\\n\")\n",
        "\n",
        "      print(\"localtunnel 的密码/终端 IP:\", urllib.request.urlopen('https://ipv4.icanhazip.com').read().decode('utf8').strip(\"\\n\"))\n",
        "      进程 = subprocess.Popen([\"lt\", \"--port\", \"{}\".format(端口)], stdout=subprocess.PIPE)\n",
        "      for 行 in 进程.stdout:\n",
        "        print(行.decode(), end='')\n",
        "\n",
        "    threading.Thread(target=隧道线程, daemon=True, args=(8188,)).start()\n",
        "\n",
        "    !python main.py --dont-print-server\n",
        "\n",
        "elif 运行方式 == \"Colab iframe\":\n",
        "    print(\"使用 Colab iframe 运行 ComfyUI (不推荐，可能无法正常工作)\")\n",
        "    import threading\n",
        "    def iframe线程(端口):\n",
        "      while True:\n",
        "          time.sleep(0.5)\n",
        "          套接字 = socket.socket(socket.AF_INET, socket.SOCK_STREAM)\n",
        "          结果 = 套接字.connect_ex(('127.0.0.1', 端口))\n",
        "          if 结果 == 0:\n",
        "            break\n",
        "          套接字.close()\n",
        "      from google.colab import output\n",
        "      output.serve_kernel_port_as_iframe(端口, height=1024)\n",
        "      print(\"在新窗口中打开链接:\")\n",
        "      output.serve_kernel_port_as_window(端口)\n",
        "\n",
        "    threading.Thread(target=iframe线程, daemon=True, args=(8188,)).start()\n",
        "\n",
        "    !python main.py --dont-print-server\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "import os\n",
        "!pip install torch==2.6.0+cu118 torchvision --index-url https://download.pytorch.org/whl/cu118 --target /content/drive/MyDrive/pip-mod\n",
        "!pip install transformers>=4.28.1 kornia>=0.7.1 spandrel -i https://pypi.tuna.tsinghua.edu.cn/simple --target /content/drive/MyDrive/pip-mod\n"
      ],
      "metadata": {
        "id": "LZW4z0u8jgxw",
        "outputId": "0a66231a-c5a3-41a3-a1c0-65428c1fba2b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "Looking in indexes: https://download.pytorch.org/whl/cu118\n",
            "Collecting torch==2.6.0+cu118\n",
            "  Using cached https://download.pytorch.org/whl/cu118/torch-2.6.0%2Bcu118-cp311-cp311-linux_x86_64.whl.metadata (27 kB)\n",
            "Collecting torchvision\n",
            "  Using cached https://download.pytorch.org/whl/cu118/torchvision-0.21.0%2Bcu118-cp311-cp311-linux_x86_64.whl.metadata (6.1 kB)\n",
            "Collecting filelock (from torch==2.6.0+cu118)\n",
            "  Using cached https://download.pytorch.org/whl/filelock-3.13.1-py3-none-any.whl.metadata (2.8 kB)\n",
            "Collecting typing-extensions>=4.10.0 (from torch==2.6.0+cu118)\n",
            "  Using cached https://download.pytorch.org/whl/typing_extensions-4.12.2-py3-none-any.whl.metadata (3.0 kB)\n",
            "Collecting networkx (from torch==2.6.0+cu118)\n",
            "  Using cached https://download.pytorch.org/whl/networkx-3.3-py3-none-any.whl.metadata (5.1 kB)\n",
            "Collecting jinja2 (from torch==2.6.0+cu118)\n",
            "  Using cached https://download.pytorch.org/whl/Jinja2-3.1.4-py3-none-any.whl.metadata (2.6 kB)\n",
            "Collecting fsspec (from torch==2.6.0+cu118)\n",
            "  Using cached https://download.pytorch.org/whl/fsspec-2024.6.1-py3-none-any.whl.metadata (11 kB)\n",
            "Collecting nvidia-cuda-nvrtc-cu11==11.8.89 (from torch==2.6.0+cu118)\n",
            "  Using cached https://download.pytorch.org/whl/cu118/nvidia_cuda_nvrtc_cu11-11.8.89-py3-none-manylinux1_x86_64.whl (23.2 MB)\n",
            "Collecting nvidia-cuda-runtime-cu11==11.8.89 (from torch==2.6.0+cu118)\n",
            "  Using cached https://download.pytorch.org/whl/cu118/nvidia_cuda_runtime_cu11-11.8.89-py3-none-manylinux1_x86_64.whl (875 kB)\n",
            "Collecting nvidia-cuda-cupti-cu11==11.8.87 (from torch==2.6.0+cu118)\n",
            "  Using cached https://download.pytorch.org/whl/cu118/nvidia_cuda_cupti_cu11-11.8.87-py3-none-manylinux1_x86_64.whl (13.1 MB)\n",
            "Collecting nvidia-cudnn-cu11==9.1.0.70 (from torch==2.6.0+cu118)\n",
            "  Using cached https://download.pytorch.org/whl/cu118/nvidia_cudnn_cu11-9.1.0.70-py3-none-manylinux2014_x86_64.whl (663.9 MB)\n",
            "Collecting nvidia-cublas-cu11==11.11.3.6 (from torch==2.6.0+cu118)\n",
            "  Using cached https://download.pytorch.org/whl/cu118/nvidia_cublas_cu11-11.11.3.6-py3-none-manylinux1_x86_64.whl (417.9 MB)\n",
            "Collecting nvidia-cufft-cu11==10.9.0.58 (from torch==2.6.0+cu118)\n",
            "  Using cached https://download.pytorch.org/whl/cu118/nvidia_cufft_cu11-10.9.0.58-py3-none-manylinux1_x86_64.whl (168.4 MB)\n",
            "Collecting nvidia-curand-cu11==10.3.0.86 (from torch==2.6.0+cu118)\n",
            "  Using cached https://download.pytorch.org/whl/cu118/nvidia_curand_cu11-10.3.0.86-py3-none-manylinux1_x86_64.whl (58.1 MB)\n",
            "Collecting nvidia-cusolver-cu11==11.4.1.48 (from torch==2.6.0+cu118)\n",
            "  Using cached https://download.pytorch.org/whl/cu118/nvidia_cusolver_cu11-11.4.1.48-py3-none-manylinux1_x86_64.whl (128.2 MB)\n",
            "Collecting nvidia-cusparse-cu11==11.7.5.86 (from torch==2.6.0+cu118)\n",
            "  Using cached https://download.pytorch.org/whl/cu118/nvidia_cusparse_cu11-11.7.5.86-py3-none-manylinux1_x86_64.whl (204.1 MB)\n",
            "Collecting nvidia-nccl-cu11==2.21.5 (from torch==2.6.0+cu118)\n",
            "  Using cached https://download.pytorch.org/whl/cu118/nvidia_nccl_cu11-2.21.5-py3-none-manylinux2014_x86_64.whl (147.8 MB)\n",
            "Collecting nvidia-nvtx-cu11==11.8.86 (from torch==2.6.0+cu118)\n",
            "  Using cached https://download.pytorch.org/whl/cu118/nvidia_nvtx_cu11-11.8.86-py3-none-manylinux1_x86_64.whl (99 kB)\n",
            "Collecting triton==3.2.0 (from torch==2.6.0+cu118)\n",
            "  Using cached https://download.pytorch.org/whl/triton-3.2.0-cp311-cp311-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (1.4 kB)\n",
            "Collecting sympy==1.13.1 (from torch==2.6.0+cu118)\n",
            "  Using cached https://download.pytorch.org/whl/sympy-1.13.1-py3-none-any.whl (6.2 MB)\n",
            "Collecting mpmath<1.4,>=1.1.0 (from sympy==1.13.1->torch==2.6.0+cu118)\n",
            "  Using cached https://download.pytorch.org/whl/mpmath-1.3.0-py3-none-any.whl (536 kB)\n",
            "Collecting numpy (from torchvision)\n",
            "  Using cached https://download.pytorch.org/whl/numpy-2.1.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (60 kB)\n",
            "Collecting pillow!=8.3.*,>=5.3.0 (from torchvision)\n",
            "  Using cached https://download.pytorch.org/whl/pillow-11.0.0-cp311-cp311-manylinux_2_28_x86_64.whl.metadata (9.1 kB)\n",
            "Collecting MarkupSafe>=2.0 (from jinja2->torch==2.6.0+cu118)\n",
            "  Using cached https://download.pytorch.org/whl/MarkupSafe-2.1.5-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (28 kB)\n",
            "Using cached https://download.pytorch.org/whl/cu118/torch-2.6.0%2Bcu118-cp311-cp311-linux_x86_64.whl (848.7 MB)\n",
            "Using cached https://download.pytorch.org/whl/triton-3.2.0-cp311-cp311-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (166.7 MB)\n",
            "Using cached https://download.pytorch.org/whl/cu118/torchvision-0.21.0%2Bcu118-cp311-cp311-linux_x86_64.whl (6.5 MB)\n",
            "Using cached https://download.pytorch.org/whl/pillow-11.0.0-cp311-cp311-manylinux_2_28_x86_64.whl (4.4 MB)\n",
            "Using cached https://download.pytorch.org/whl/typing_extensions-4.12.2-py3-none-any.whl (37 kB)\n",
            "Using cached https://download.pytorch.org/whl/filelock-3.13.1-py3-none-any.whl (11 kB)\n",
            "Using cached https://download.pytorch.org/whl/fsspec-2024.6.1-py3-none-any.whl (177 kB)\n",
            "Using cached https://download.pytorch.org/whl/Jinja2-3.1.4-py3-none-any.whl (133 kB)\n",
            "Using cached https://download.pytorch.org/whl/networkx-3.3-py3-none-any.whl (1.7 MB)\n",
            "Using cached https://download.pytorch.org/whl/numpy-2.1.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (16.3 MB)\n",
            "Installing collected packages: triton, mpmath, typing-extensions, sympy, pillow, nvidia-nvtx-cu11, nvidia-nccl-cu11, nvidia-cusparse-cu11, nvidia-curand-cu11, nvidia-cufft-cu11, nvidia-cuda-runtime-cu11, nvidia-cuda-nvrtc-cu11, nvidia-cuda-cupti-cu11, nvidia-cublas-cu11, numpy, networkx, MarkupSafe, fsspec, filelock, nvidia-cusolver-cu11, nvidia-cudnn-cu11, jinja2, torch, torchvision\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "pytensor 2.26.4 requires filelock>=3.15, but you have filelock 3.13.1 which is incompatible.\n",
            "pytensor 2.26.4 requires numpy<2,>=1.17.0, but you have numpy 2.1.2 which is incompatible.\n",
            "langchain 0.3.17 requires numpy<2,>=1.22.4; python_version < \"3.12\", but you have numpy 2.1.2 which is incompatible.\n",
            "gcsfs 2024.10.0 requires fsspec==2024.10.0, but you have fsspec 2024.6.1 which is incompatible.\n",
            "gensim 4.3.3 requires numpy<2.0,>=1.18.5, but you have numpy 2.1.2 which is incompatible.\n",
            "tensorflow 2.18.0 requires numpy<2.1.0,>=1.26.0, but you have numpy 2.1.2 which is incompatible.\n",
            "torchaudio 2.5.1+cu124 requires torch==2.5.1, but you have torch 2.6.0+cu118 which is incompatible.\n",
            "thinc 8.2.5 requires numpy<2.0.0,>=1.19.0; python_version >= \"3.9\", but you have numpy 2.1.2 which is incompatible.\n",
            "fastai 2.7.18 requires torch<2.6,>=1.10, but you have torch 2.6.0+cu118 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed MarkupSafe-2.1.5 filelock-3.13.1 fsspec-2024.6.1 jinja2-3.1.4 mpmath-1.3.0 networkx-3.3 numpy-2.1.2 nvidia-cublas-cu11-11.11.3.6 nvidia-cuda-cupti-cu11-11.8.87 nvidia-cuda-nvrtc-cu11-11.8.89 nvidia-cuda-runtime-cu11-11.8.89 nvidia-cudnn-cu11-9.1.0.70 nvidia-cufft-cu11-10.9.0.58 nvidia-curand-cu11-10.3.0.86 nvidia-cusolver-cu11-11.4.1.48 nvidia-cusparse-cu11-11.7.5.86 nvidia-nccl-cu11-2.21.5 nvidia-nvtx-cu11-11.8.86 pillow-11.0.0 sympy-1.13.1 torch-2.6.0+cu118 torchvision-0.21.0+cu118 triton-3.2.0 typing-extensions-4.12.2\n",
            "\u001b[33mWARNING: Target directory /content/drive/MyDrive/pip-mod/jinja2 already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n",
            "\u001b[0m\u001b[33mWARNING: Target directory /content/drive/MyDrive/pip-mod/filelock already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n",
            "\u001b[0m\u001b[33mWARNING: Target directory /content/drive/MyDrive/pip-mod/isympy.py already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n",
            "\u001b[0m\u001b[33mWARNING: Target directory /content/drive/MyDrive/pip-mod/nvidia_cusolver_cu11-11.4.1.48.dist-info already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n",
            "\u001b[0m\u001b[33mWARNING: Target directory /content/drive/MyDrive/pip-mod/nvidia_curand_cu11-10.3.0.86.dist-info already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n",
            "\u001b[0m\u001b[33mWARNING: Target directory /content/drive/MyDrive/pip-mod/pillow.libs already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n",
            "\u001b[0m\u001b[33mWARNING: Target directory /content/drive/MyDrive/pip-mod/triton already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n",
            "\u001b[0m\u001b[33mWARNING: Target directory /content/drive/MyDrive/pip-mod/PIL already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n",
            "\u001b[0m\u001b[33mWARNING: Target directory /content/drive/MyDrive/pip-mod/nvidia_cuda_cupti_cu11-11.8.87.dist-info already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n",
            "\u001b[0m\u001b[33mWARNING: Target directory /content/drive/MyDrive/pip-mod/mpmath already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n",
            "\u001b[0m\u001b[33mWARNING: Target directory /content/drive/MyDrive/pip-mod/nvidia_cudnn_cu11-9.1.0.70.dist-info already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n",
            "\u001b[0m\u001b[33mWARNING: Target directory /content/drive/MyDrive/pip-mod/torchvision-0.21.0+cu118.dist-info already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n",
            "\u001b[0m\u001b[33mWARNING: Target directory /content/drive/MyDrive/pip-mod/torchvision already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n",
            "\u001b[0m\u001b[33mWARNING: Target directory /content/drive/MyDrive/pip-mod/nvidia_cusparse_cu11-11.7.5.86.dist-info already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n",
            "\u001b[0m\u001b[33mWARNING: Target directory /content/drive/MyDrive/pip-mod/triton-3.2.0.dist-info already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n",
            "\u001b[0m\u001b[33mWARNING: Target directory /content/drive/MyDrive/pip-mod/torchgen already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n",
            "\u001b[0m\u001b[33mWARNING: Target directory /content/drive/MyDrive/pip-mod/fsspec already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n",
            "\u001b[0m\u001b[33mWARNING: Target directory /content/drive/MyDrive/pip-mod/jinja2-3.1.4.dist-info already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n",
            "\u001b[0m\u001b[33mWARNING: Target directory /content/drive/MyDrive/pip-mod/sympy-1.13.1.dist-info already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n",
            "\u001b[0m\u001b[33mWARNING: Target directory /content/drive/MyDrive/pip-mod/nvidia_cufft_cu11-10.9.0.58.dist-info already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n",
            "\u001b[0m\u001b[33mWARNING: Target directory /content/drive/MyDrive/pip-mod/markupsafe already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n",
            "\u001b[0m\u001b[33mWARNING: Target directory /content/drive/MyDrive/pip-mod/networkx-3.3.dist-info already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n",
            "\u001b[0m\u001b[33mWARNING: Target directory /content/drive/MyDrive/pip-mod/sympy already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n",
            "\u001b[0m\u001b[33mWARNING: Target directory /content/drive/MyDrive/pip-mod/fsspec-2024.6.1.dist-info already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n",
            "\u001b[0m\u001b[33mWARNING: Target directory /content/drive/MyDrive/pip-mod/MarkupSafe-2.1.5.dist-info already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n",
            "\u001b[0m\u001b[33mWARNING: Target directory /content/drive/MyDrive/pip-mod/nvidia_cuda_runtime_cu11-11.8.89.dist-info already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n",
            "\u001b[0m\u001b[33mWARNING: Target directory /content/drive/MyDrive/pip-mod/torchvision.libs already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n",
            "\u001b[0m\u001b[33mWARNING: Target directory /content/drive/MyDrive/pip-mod/typing_extensions.py already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n",
            "\u001b[0m\u001b[33mWARNING: Target directory /content/drive/MyDrive/pip-mod/typing_extensions-4.12.2.dist-info already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n",
            "\u001b[0m\u001b[33mWARNING: Target directory /content/drive/MyDrive/pip-mod/numpy-2.1.2.dist-info already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n",
            "\u001b[0m\u001b[33mWARNING: Target directory /content/drive/MyDrive/pip-mod/nvidia_nvtx_cu11-11.8.86.dist-info already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n",
            "\u001b[0m\u001b[33mWARNING: Target directory /content/drive/MyDrive/pip-mod/functorch already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n",
            "\u001b[0m\u001b[33mWARNING: Target directory /content/drive/MyDrive/pip-mod/nvidia already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n",
            "\u001b[0m\u001b[33mWARNING: Target directory /content/drive/MyDrive/pip-mod/numpy.libs already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n",
            "\u001b[0m\u001b[33mWARNING: Target directory /content/drive/MyDrive/pip-mod/nvidia_nccl_cu11-2.21.5.dist-info already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n",
            "\u001b[0m\u001b[33mWARNING: Target directory /content/drive/MyDrive/pip-mod/numpy already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n",
            "\u001b[0m\u001b[33mWARNING: Target directory /content/drive/MyDrive/pip-mod/__pycache__ already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n",
            "\u001b[0m\u001b[33mWARNING: Target directory /content/drive/MyDrive/pip-mod/filelock-3.13.1.dist-info already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n",
            "\u001b[0m\u001b[33mWARNING: Target directory /content/drive/MyDrive/pip-mod/mpmath-1.3.0.dist-info already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n",
            "\u001b[0m\u001b[33mWARNING: Target directory /content/drive/MyDrive/pip-mod/networkx already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n",
            "\u001b[0m\u001b[33mWARNING: Target directory /content/drive/MyDrive/pip-mod/pillow-11.0.0.dist-info already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n",
            "\u001b[0m\u001b[33mWARNING: Target directory /content/drive/MyDrive/pip-mod/torch-2.6.0+cu118.dist-info already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n",
            "\u001b[0m\u001b[33mWARNING: Target directory /content/drive/MyDrive/pip-mod/nvidia_cublas_cu11-11.11.3.6.dist-info already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n",
            "\u001b[0m\u001b[33mWARNING: Target directory /content/drive/MyDrive/pip-mod/nvidia_cuda_nvrtc_cu11-11.8.89.dist-info already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n",
            "\u001b[0m\u001b[33mWARNING: Target directory /content/drive/MyDrive/pip-mod/torch already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n",
            "\u001b[0m\u001b[33mWARNING: Target directory /content/drive/MyDrive/pip-mod/bin already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n",
            "\u001b[0m\u001b[33mWARNING: Target directory /content/drive/MyDrive/pip-mod/share already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n",
            "\u001b[0m\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "pytensor 2.26.4 requires numpy<2,>=1.17.0, but you have numpy 2.2.2 which is incompatible.\n",
            "langchain 0.3.17 requires numpy<2,>=1.22.4; python_version < \"3.12\", but you have numpy 2.2.2 which is incompatible.\n",
            "gcsfs 2024.10.0 requires fsspec==2024.10.0, but you have fsspec 2025.2.0 which is incompatible.\n",
            "gensim 4.3.3 requires numpy<2.0,>=1.18.5, but you have numpy 2.2.2 which is incompatible.\n",
            "numba 0.61.0 requires numpy<2.2,>=1.24, but you have numpy 2.2.2 which is incompatible.\n",
            "tensorflow 2.18.0 requires numpy<2.1.0,>=1.26.0, but you have numpy 2.2.2 which is incompatible.\n",
            "torchaudio 2.5.1+cu124 requires torch==2.5.1, but you have torch 2.6.0 which is incompatible.\n",
            "thinc 8.2.5 requires numpy<2.0.0,>=1.19.0; python_version >= \"3.9\", but you have numpy 2.2.2 which is incompatible.\n",
            "fastai 2.7.18 requires torch<2.6,>=1.10, but you have torch 2.6.0 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0m\u001b[33mWARNING: Target directory /content/drive/MyDrive/pip-mod/jinja2 already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n",
            "\u001b[0m\u001b[33mWARNING: Target directory /content/drive/MyDrive/pip-mod/filelock already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n",
            "\u001b[0m\u001b[33mWARNING: Target directory /content/drive/MyDrive/pip-mod/isympy.py already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n",
            "\u001b[0m\u001b[33mWARNING: Target directory /content/drive/MyDrive/pip-mod/pillow.libs already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n",
            "\u001b[0m\u001b[33mWARNING: Target directory /content/drive/MyDrive/pip-mod/triton already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n",
            "\u001b[0m\u001b[33mWARNING: Target directory /content/drive/MyDrive/pip-mod/PIL already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n",
            "\u001b[0m\u001b[33mWARNING: Target directory /content/drive/MyDrive/pip-mod/mpmath already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n",
            "\u001b[0m\u001b[33mWARNING: Target directory /content/drive/MyDrive/pip-mod/torchvision already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n",
            "\u001b[0m\u001b[33mWARNING: Target directory /content/drive/MyDrive/pip-mod/triton-3.2.0.dist-info already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n",
            "\u001b[0m\u001b[33mWARNING: Target directory /content/drive/MyDrive/pip-mod/torchgen already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n",
            "\u001b[0m\u001b[33mWARNING: Target directory /content/drive/MyDrive/pip-mod/fsspec already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n",
            "\u001b[0m\u001b[33mWARNING: Target directory /content/drive/MyDrive/pip-mod/sympy-1.13.1.dist-info already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n",
            "\u001b[0m\u001b[33mWARNING: Target directory /content/drive/MyDrive/pip-mod/markupsafe already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n",
            "\u001b[0m\u001b[33mWARNING: Target directory /content/drive/MyDrive/pip-mod/sympy already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n",
            "\u001b[0m\u001b[33mWARNING: Target directory /content/drive/MyDrive/pip-mod/torchvision.libs already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n",
            "\u001b[0m\u001b[33mWARNING: Target directory /content/drive/MyDrive/pip-mod/typing_extensions.py already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n",
            "\u001b[0m\u001b[33mWARNING: Target directory /content/drive/MyDrive/pip-mod/typing_extensions-4.12.2.dist-info already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n",
            "\u001b[0m\u001b[33mWARNING: Target directory /content/drive/MyDrive/pip-mod/functorch already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n",
            "\u001b[0m\u001b[33mWARNING: Target directory /content/drive/MyDrive/pip-mod/nvidia already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n",
            "\u001b[0m\u001b[33mWARNING: Target directory /content/drive/MyDrive/pip-mod/numpy.libs already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n",
            "\u001b[0m\u001b[33mWARNING: Target directory /content/drive/MyDrive/pip-mod/numpy already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n",
            "\u001b[0m\u001b[33mWARNING: Target directory /content/drive/MyDrive/pip-mod/__pycache__ already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n",
            "\u001b[0m\u001b[33mWARNING: Target directory /content/drive/MyDrive/pip-mod/mpmath-1.3.0.dist-info already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n",
            "\u001b[0m\u001b[33mWARNING: Target directory /content/drive/MyDrive/pip-mod/networkx already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n",
            "\u001b[0m\u001b[33mWARNING: Target directory /content/drive/MyDrive/pip-mod/torch already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n",
            "\u001b[0m\u001b[33mWARNING: Target directory /content/drive/MyDrive/pip-mod/bin already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n",
            "\u001b[0m\u001b[33mWARNING: Target directory /content/drive/MyDrive/pip-mod/share already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n",
            "\u001b[0m"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import sys\n",
        "\n",
        "目标目录 = \"/content/drive/MyDrive/pip-mod\"\n",
        "\n",
        "# 清空 sys.path\n",
        "sys.path = []\n",
        "\n",
        "# 添加目标目录到 sys.path\n",
        "sys.path.append(目标目录)\n",
        "\n",
        "print(sys.path)\n",
        "!pip check"
      ],
      "metadata": {
        "id": "HUPqZurFv0sA",
        "outputId": "7e958ac0-aa62-4d14-baee-594d118e40f9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['/content/drive/MyDrive/pip-mod']\n",
            "ipython 7.34.0 requires jedi, which is not installed.\n",
            "pygobject 3.42.1 requires pycairo, which is not installed.\n",
            "torch 2.5.1+cu124 has requirement nvidia-cublas-cu12==12.4.5.8; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cublas-cu12 12.5.3.2.\n",
            "torch 2.5.1+cu124 has requirement nvidia-cuda-cupti-cu12==12.4.127; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cuda-cupti-cu12 12.5.82.\n",
            "torch 2.5.1+cu124 has requirement nvidia-cuda-nvrtc-cu12==12.4.127; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cuda-nvrtc-cu12 12.5.82.\n",
            "torch 2.5.1+cu124 has requirement nvidia-cuda-runtime-cu12==12.4.127; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cuda-runtime-cu12 12.5.82.\n",
            "torch 2.5.1+cu124 has requirement nvidia-cudnn-cu12==9.1.0.70; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cudnn-cu12 9.3.0.75.\n",
            "torch 2.5.1+cu124 has requirement nvidia-cufft-cu12==11.2.1.3; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cufft-cu12 11.2.3.61.\n",
            "torch 2.5.1+cu124 has requirement nvidia-curand-cu12==10.3.5.147; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-curand-cu12 10.3.6.82.\n",
            "torch 2.5.1+cu124 has requirement nvidia-cusolver-cu12==11.6.1.9; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cusolver-cu12 11.6.3.83.\n",
            "torch 2.5.1+cu124 has requirement nvidia-cusparse-cu12==12.3.1.170; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cusparse-cu12 12.5.1.3.\n",
            "torch 2.5.1+cu124 has requirement nvidia-nvjitlink-cu12==12.4.127; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-nvjitlink-cu12 12.5.82.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "output_dir = \"/content/drive/MyDrive/ComfyUI/output\"\n",
        "zip_file = \"/content/ComfyUI_output.zip\"  # 指定 ZIP 文件的保存路径和名称\n",
        "\n",
        "# 确保输出目录存在\n",
        "if not os.path.exists(output_dir):\n",
        "    print(f\"错误：目录 {output_dir} 不存在\")\n",
        "else:\n",
        "    # 使用 zip 命令压缩文件\n",
        "    !zip -r \"{zip_file}\" \"{output_dir}\"/*\n",
        "\n",
        "    print(f\"目录 {output_dir} 已压缩到 {zip_file}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lcYZCiI6S4fS",
        "outputId": "a3fbebe6-2b59-42df-b805-fd9477a32e1c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  adding: content/drive/MyDrive/ComfyUI/output/0001ai图2025-02-08 15-00-21.png (deflated 0%)\n",
            "  adding: content/drive/MyDrive/ComfyUI/output/0002ai图2025-02-08 15-00-21.png (deflated 0%)\n",
            "  adding: content/drive/MyDrive/ComfyUI/output/0003ai图2025-02-08 15-00-21.png (deflated 0%)\n",
            "  adding: content/drive/MyDrive/ComfyUI/output/0004ai图2025-02-08 15-00-21.png (deflated 0%)\n",
            "  adding: content/drive/MyDrive/ComfyUI/output/0005ai图2025-02-08 15-03-09.png (deflated 0%)\n",
            "  adding: content/drive/MyDrive/ComfyUI/output/0006ai图2025-02-08 15-03-09.png (deflated 0%)\n",
            "  adding: content/drive/MyDrive/ComfyUI/output/0007ai图2025-02-08 15-03-09.png (deflated 0%)\n",
            "  adding: content/drive/MyDrive/ComfyUI/output/0008ai图2025-02-08 15-03-09.png (deflated 0%)\n",
            "  adding: content/drive/MyDrive/ComfyUI/output/0009ai图2025-02-08 15-09-22.png (deflated 0%)\n",
            "  adding: content/drive/MyDrive/ComfyUI/output/2025-02-08/ (stored 0%)\n",
            "  adding: content/drive/MyDrive/ComfyUI/output/2025-02-08/ComfyUI/ (stored 0%)\n",
            "  adding: content/drive/MyDrive/ComfyUI/output/2025-02-08/0001ComfyUI2025-02-08 14-58-02.png (deflated 0%)\n",
            "  adding: content/drive/MyDrive/ComfyUI/output/2025-02-08/0002ComfyUI2025-02-08 14-58-02.png (deflated 0%)\n",
            "  adding: content/drive/MyDrive/ComfyUI/output/2025-02-08/0003ComfyUI2025-02-08 14-58-02.png (deflated 0%)\n",
            "  adding: content/drive/MyDrive/ComfyUI/output/2025-02-08/0004ComfyUI2025-02-08 14-58-02.png (deflated 0%)\n",
            "  adding: content/drive/MyDrive/ComfyUI/output/2025-02-08 15-19-25/ (stored 0%)\n",
            "  adding: content/drive/MyDrive/ComfyUI/output/2025-02-08 15-19-25/0001-2025-02-08 15-19-25.png (deflated 0%)\n",
            "  adding: content/drive/MyDrive/ComfyUI/output/2025-02-08 15-21-54/ (stored 0%)\n",
            "  adding: content/drive/MyDrive/ComfyUI/output/2025-02-08 15-21-54/0001-2025-02-08 15-21-54.png (deflated 0%)\n",
            "  adding: content/drive/MyDrive/ComfyUI/output/2025-02-08 15-28-10/ (stored 0%)\n",
            "  adding: content/drive/MyDrive/ComfyUI/output/2025-02-08 15-28-10/0001-2025-02-08 15-28-10.png (deflated 0%)\n",
            "  adding: content/drive/MyDrive/ComfyUI/output/2025-02-08 15-28-10/0002-2025-02-08 15-28-10.png (deflated 0%)\n",
            "  adding: content/drive/MyDrive/ComfyUI/output/2025-02-08 15-28-10/0003-2025-02-08 15-28-10.png (deflated 0%)\n",
            "  adding: content/drive/MyDrive/ComfyUI/output/2025-02-08 15-28-10/0004-2025-02-08 15-28-10.png (deflated 0%)\n",
            "  adding: content/drive/MyDrive/ComfyUI/output/2025-02-08 15-31-05/ (stored 0%)\n",
            "  adding: content/drive/MyDrive/ComfyUI/output/2025-02-08 15-31-05/0001-2025-02-08 15-31-05.png (deflated 0%)\n",
            "  adding: content/drive/MyDrive/ComfyUI/output/2025-02-08 15-31-05/0002-2025-02-08 15-31-05.png (deflated 0%)\n",
            "  adding: content/drive/MyDrive/ComfyUI/output/2025-02-08 15-31-05/0003-2025-02-08 15-31-05.png (deflated 0%)\n",
            "  adding: content/drive/MyDrive/ComfyUI/output/2025-02-08 15-31-05/0004-2025-02-08 15-31-05.png (deflated 0%)\n",
            "  adding: content/drive/MyDrive/ComfyUI/output/2025-02-08 15-33-56/ (stored 0%)\n",
            "  adding: content/drive/MyDrive/ComfyUI/output/2025-02-08 15-33-56/0001-2025-02-08 15-33-56.png (deflated 0%)\n",
            "  adding: content/drive/MyDrive/ComfyUI/output/2025-02-08 15-33-56/0002-2025-02-08 15-33-56.png (deflated 0%)\n",
            "  adding: content/drive/MyDrive/ComfyUI/output/2025-02-08 15-33-56/0003-2025-02-08 15-33-56.png (deflated 0%)\n",
            "  adding: content/drive/MyDrive/ComfyUI/output/2025-02-08 15-33-56/0004-2025-02-08 15-33-56.png (deflated 0%)\n",
            "  adding: content/drive/MyDrive/ComfyUI/output/2025-02-08 15-36-46/ (stored 0%)\n",
            "  adding: content/drive/MyDrive/ComfyUI/output/2025-02-08 15-36-46/0001-2025-02-08 15-36-46.png (deflated 0%)\n",
            "  adding: content/drive/MyDrive/ComfyUI/output/2025-02-08 15-36-46/0002-2025-02-08 15-36-46.png (deflated 0%)\n",
            "  adding: content/drive/MyDrive/ComfyUI/output/2025-02-08 15-36-46/0003-2025-02-08 15-36-46.png (deflated 0%)\n",
            "  adding: content/drive/MyDrive/ComfyUI/output/2025-02-08 15-36-46/0004-2025-02-08 15-36-46.png (deflated 0%)\n",
            "  adding: content/drive/MyDrive/ComfyUI/output/2025-02-08 15-39-38/ (stored 0%)\n",
            "  adding: content/drive/MyDrive/ComfyUI/output/2025-02-08 15-39-38/0001-2025-02-08 15-39-38.png (deflated 0%)\n",
            "  adding: content/drive/MyDrive/ComfyUI/output/2025-02-08 15-39-38/0002-2025-02-08 15-39-38.png (deflated 0%)\n",
            "  adding: content/drive/MyDrive/ComfyUI/output/2025-02-08 15-39-38/0003-2025-02-08 15-39-38.png (deflated 0%)\n",
            "  adding: content/drive/MyDrive/ComfyUI/output/2025-02-08 15-39-38/0004-2025-02-08 15-39-38.png (deflated 0%)\n",
            "  adding: content/drive/MyDrive/ComfyUI/output/2025-02-08 15-42-31/ (stored 0%)\n",
            "  adding: content/drive/MyDrive/ComfyUI/output/2025-02-08 15-42-31/0001-2025-02-08 15-42-31.png (deflated 0%)\n",
            "  adding: content/drive/MyDrive/ComfyUI/output/2025-02-08 15-42-31/0002-2025-02-08 15-42-31.png (deflated 0%)\n",
            "  adding: content/drive/MyDrive/ComfyUI/output/2025-02-08 15-42-31/0003-2025-02-08 15-42-31.png (deflated 0%)\n",
            "  adding: content/drive/MyDrive/ComfyUI/output/2025-02-08 15-42-31/0004-2025-02-08 15-42-31.png (deflated 0%)\n",
            "  adding: content/drive/MyDrive/ComfyUI/output/2025-02-08 15-53-28/ (stored 0%)\n",
            "  adding: content/drive/MyDrive/ComfyUI/output/2025-02-08 15-53-28/0001-2025-02-08 15-53-28.png (deflated 0%)\n",
            "  adding: content/drive/MyDrive/ComfyUI/output/2025-02-08 15-53-28/0002-2025-02-08 15-53-28.png (deflated 0%)\n",
            "  adding: content/drive/MyDrive/ComfyUI/output/2025-02-08 15-53-28/0003-2025-02-08 15-53-28.png (deflated 0%)\n",
            "  adding: content/drive/MyDrive/ComfyUI/output/2025-02-08 15-53-28/0004-2025-02-08 15-53-28.png (deflated 0%)\n",
            "  adding: content/drive/MyDrive/ComfyUI/output/2025-02-08 15-56-14/ (stored 0%)\n",
            "  adding: content/drive/MyDrive/ComfyUI/output/2025-02-08 15-56-14/0001-2025-02-08 15-56-14.png (deflated 0%)\n",
            "  adding: content/drive/MyDrive/ComfyUI/output/2025-02-08 15-56-14/0002-2025-02-08 15-56-14.png (deflated 0%)\n",
            "  adding: content/drive/MyDrive/ComfyUI/output/2025-02-08 15-56-14/0003-2025-02-08 15-56-14.png (deflated 0%)\n",
            "  adding: content/drive/MyDrive/ComfyUI/output/2025-02-08 15-56-14/0004-2025-02-08 15-56-14.png (deflated 0%)\n",
            "  adding: content/drive/MyDrive/ComfyUI/output/2025-02-08 15-59-01/ (stored 0%)\n",
            "  adding: content/drive/MyDrive/ComfyUI/output/2025-02-08 15-59-01/0001-2025-02-08 15-59-01.png (deflated 0%)\n",
            "  adding: content/drive/MyDrive/ComfyUI/output/2025-02-08 15-59-01/0002-2025-02-08 15-59-01.png (deflated 0%)\n",
            "  adding: content/drive/MyDrive/ComfyUI/output/2025-02-08 15-59-01/0003-2025-02-08 15-59-01.png (deflated 0%)\n",
            "  adding: content/drive/MyDrive/ComfyUI/output/2025-02-08 15-59-01/0004-2025-02-08 15-59-01.png (deflated 0%)\n",
            "  adding: content/drive/MyDrive/ComfyUI/output/2025-02-08 16-01-53/ (stored 0%)\n",
            "  adding: content/drive/MyDrive/ComfyUI/output/2025-02-08 16-01-53/0001-2025-02-08 16-01-53.png (deflated 0%)\n",
            "  adding: content/drive/MyDrive/ComfyUI/output/2025-02-08 16-01-53/0002-2025-02-08 16-01-53.png (deflated 0%)\n",
            "  adding: content/drive/MyDrive/ComfyUI/output/2025-02-08 16-01-53/0003-2025-02-08 16-01-53.png (deflated 0%)\n",
            "  adding: content/drive/MyDrive/ComfyUI/output/2025-02-08 16-01-53/0004-2025-02-08 16-01-53.png (deflated 0%)\n",
            "  adding: content/drive/MyDrive/ComfyUI/output/ComfyUI_00001_.png (deflated 0%)\n",
            "  adding: content/drive/MyDrive/ComfyUI/output/ComfyUI_00002_.png (deflated 0%)\n",
            "  adding: content/drive/MyDrive/ComfyUI/output/ComfyUI_00003_.png (deflated 0%)\n",
            "  adding: content/drive/MyDrive/ComfyUI/output/ComfyUI_00004_.png (deflated 0%)\n",
            "  adding: content/drive/MyDrive/ComfyUI/output/ComfyUI_00005_.png (deflated 0%)\n",
            "  adding: content/drive/MyDrive/ComfyUI/output/ComfyUI_00006_.png (deflated 0%)\n",
            "  adding: content/drive/MyDrive/ComfyUI/output/ComfyUI_00007_.png (deflated 0%)\n",
            "  adding: content/drive/MyDrive/ComfyUI/output/ComfyUI_00008_.png (deflated 0%)\n",
            "  adding: content/drive/MyDrive/ComfyUI/output/noobaiXLNAIXL_vPred10Version/ (stored 0%)\n",
            "  adding: content/drive/MyDrive/ComfyUI/output/noobaiXLNAIXL_vPred10Version/0001-ComfyUI-2025-02-08 14-49-33.png (deflated 0%)\n",
            "  adding: content/drive/MyDrive/ComfyUI/output/noobaiXLNAIXL_vPred10Version/0002-ComfyUI-2025-02-08 14-49-33.png (deflated 0%)\n",
            "  adding: content/drive/MyDrive/ComfyUI/output/noobaiXLNAIXL_vPred10Version/0003-ComfyUI-2025-02-08 14-49-33.png (deflated 0%)\n",
            "  adding: content/drive/MyDrive/ComfyUI/output/noobaiXLNAIXL_vPred10Version/0004-ComfyUI-2025-02-08 14-49-33.png (deflated 0%)\n",
            "  adding: content/drive/MyDrive/ComfyUI/output/noobaiXLNAIXL_vPred10Version/ComfyUI-euler-5.3-25-2025-02-08 15-11-06-0001.webp (deflated 3%)\n",
            "  adding: content/drive/MyDrive/ComfyUI/output/noobaiXLNAIXL_vPred10Version/0001-ComfyUI-euler-5.3-25-2025-02-08 15-14-31.webp (deflated 3%)\n",
            "  adding: content/drive/MyDrive/ComfyUI/output/_output_images_will_be_put_here (stored 0%)\n",
            "  adding: content/drive/MyDrive/ComfyUI/output/拉菲_00001_.png (deflated 0%)\n",
            "  adding: content/drive/MyDrive/ComfyUI/output/拉菲_00002_.png (deflated 0%)\n",
            "  adding: content/drive/MyDrive/ComfyUI/output/拉菲_00003_.png (deflated 0%)\n",
            "  adding: content/drive/MyDrive/ComfyUI/output/拉菲_00004_.png (deflated 0%)\n",
            "目录 /content/drive/MyDrive/ComfyUI/output 已压缩到 /content/ComfyUI_output.zip\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "os.chdir(\"/content/drive/MyDrive/ComfyUI/custom_nodes\")  # 修改为你的 custom_nodes 目录\n",
        "!ls\n",
        "!git clone https://github.com/ltdrdata/ComfyUI-Manager\n",
        "os.chdir(\"/content/drive/MyDrive/ComfyUI\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IdMP8dltxxvh",
        "outputId": "08f3c54e-53c1-4fb5-c693-4f3523463b61"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "example_node.py.example  __pycache__  websocket_image_save.py\n",
            "Cloning into 'ComfyUI-Manager'...\n",
            "remote: Enumerating objects: 17474, done.\u001b[K\n",
            "remote: Counting objects: 100% (236/236), done.\u001b[K\n",
            "remote: Compressing objects: 100% (84/84), done.\u001b[K\n",
            "remote: Total 17474 (delta 179), reused 160 (delta 152), pack-reused 17238 (from 2)\u001b[K\n",
            "Receiving objects: 100% (17474/17474), 23.02 MiB | 14.24 MiB/s, done.\n",
            "Resolving deltas: 100% (12869/12869), done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# @title 从 Civitai API 下载 模型\n",
        "\n",
        "模型保存路径 = \"/content/ComfyUI/models/checkpoints\"  # @param {type:\"string\"}\n",
        "模型ID = \"833294\"  # @param {type:\"string\"}\n",
        "API密钥 = \"301668c17b1b7ffe7c5c0516f323b9db\"  # @param {type:\"string\"}\n",
        "\n",
        "import os\n",
        "import requests\n",
        "import json\n",
        "from datetime import datetime\n",
        "\n",
        "# 创建模型保存路径\n",
        "os.makedirs(模型保存路径, exist_ok=True)\n",
        "\n",
        "# Civitai API URL (使用模型版本 API)\n",
        "API_URL = f\"https://civitai.com/api/v1/models/{模型ID}\"\n",
        "\n",
        "# 发送 API 请求\n",
        "headers = {\n",
        "    \"Authorization\": f\"Bearer {API密钥}\"\n",
        "}\n",
        "response = requests.get(API_URL, headers=headers)\n",
        "response.raise_for_status()\n",
        "\n",
        "# 获取模型信息\n",
        "model_data = response.json()\n",
        "\n",
        "# 获取所有模型版本\n",
        "model_versions = model_data[\"modelVersions\"]\n",
        "\n",
        "# 按创建日期排序 (从最新到最旧)\n",
        "model_versions.sort(key=lambda x: datetime.fromisoformat(x[\"createdAt\"].replace(\"Z\", \"+00:00\")), reverse=True)\n",
        "\n",
        "# 查找最新版本中的 bf16 文件\n",
        "download_url = None\n",
        "模型文件名 = None\n",
        "for version in model_versions:\n",
        "    for file in version[\"files\"]:\n",
        "        if file[\"type\"] == \"Model\" and file[\"metadata\"] and file[\"metadata\"].get(\"fp\") == \"bf16\":\n",
        "            download_url = file[\"downloadUrl\"]\n",
        "            模型文件名 = file[\"name\"]\n",
        "            break\n",
        "    if download_url:\n",
        "        break\n",
        "\n",
        "if download_url:\n",
        "    # 构建完整的模型文件路径\n",
        "    模型文件完整路径 = os.path.join(模型保存路径, 模型文件名)\n",
        "\n",
        "    print(f\"原始下载链接: {download_url}\")\n",
        "    print(f\"文件名: {模型文件名}\")\n",
        "\n",
        "    # 设置 User-Agent 和 Referer 头部\n",
        "    headers = {\n",
        "        \"Authorization\": f\"Bearer {API密钥}\",\n",
        "        \"User-Agent\": \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36\",  # 模拟 Chrome 浏览器\n",
        "        \"Referer\": \"https://civitai.com/\"  # 模拟来自 Civitai 域名的请求\n",
        "    }\n",
        "\n",
        "    # 使用 HEAD 请求获取重定向后的 URL\n",
        "    try:\n",
        "        redirected_response = requests.head(download_url, allow_redirects=True, headers=headers, timeout=10)  # 添加超时时间\n",
        "        redirected_response.raise_for_status()  # 仅在状态码不是 200-399 时才抛出异常\n",
        "        final_download_url = redirected_response.url\n",
        "        print(f\"重定向后的下载链接: {final_download_url}\")\n",
        "    except requests.exceptions.RequestException as e:\n",
        "        print(f\"获取重定向 URL 失败: {e}\")\n",
        "        final_download_url = redirected_response.url  # 即使请求失败，也尝试从 response.url 获取 URL\n",
        "        print(f\"尝试从 response.url 获取重定向后的下载链接: {final_download_url}\")\n",
        "\n",
        "    if final_download_url:\n",
        "        # 使用 aria2 下载模型\n",
        "        !apt-get install -y aria2\n",
        "        !aria2c --console-log-level=error -c -x 16 -s 16 -k 1M \"{final_download_url}\" -d \"{模型保存路径}\" -o \"{模型文件名}\"\n",
        "\n",
        "        print(f\"模型已下载到: {模型文件完整路径}\")\n",
        "    else:\n",
        "        print(\"无法获取重定向后的下载链接。\")\n",
        "else:\n",
        "    print(\"无法找到任何可下载的模型文件。\")\n",
        "    print(\"请检查模型 ID 是否正确，以及模型是否存在可下载的版本。\")\n",
        "    print(\"请确保您的 API 密钥具有足够的权限。\")\n"
      ],
      "metadata": {
        "id": "zGFONq9hYsvU"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}
{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mrnfqrbl/sd-forge-colab/blob/main/comfyui.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "s-UlIe6iYp0u",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "94d98df7-dbb7-496d-ecf8-2fb6fed32bcf"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Ê≠£Âú®ÊåÇËΩΩ Google ‰∫ëÁõò...\n",
            "/\n",
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "/content/drive/MyDrive\n",
            "/content/drive/MyDrive/ComfyUI\n",
            "-= Ê≠£Âú®ÂÆâË£Ö‰æùËµñÈ°π =-\n",
            "Looking in indexes: https://pypi.org/simple, https://download.pytorch.org/whl/cu121, https://download.pytorch.org/whl/cu118, https://download.pytorch.org/whl/cu117\n",
            "Requirement already satisfied: xformers!=0.0.18 in /usr/local/lib/python3.11/dist-packages (0.0.29.post2)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 1)) (2.6.0+cu118)\n",
            "Requirement already satisfied: torchsde in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 2)) (0.2.6)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 3)) (0.21.0+cu118)\n",
            "Requirement already satisfied: torchaudio in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 4)) (2.6.0+cu118)\n",
            "Requirement already satisfied: numpy>=1.25.0 in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 5)) (1.26.4)\n",
            "Requirement already satisfied: einops in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 6)) (0.8.0)\n",
            "Requirement already satisfied: transformers>=4.28.1 in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 7)) (4.48.2)\n",
            "Requirement already satisfied: tokenizers>=0.13.3 in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 8)) (0.21.0)\n",
            "Requirement already satisfied: sentencepiece in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 9)) (0.2.0)\n",
            "Requirement already satisfied: safetensors>=0.4.2 in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 10)) (0.5.2)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 11)) (3.11.11)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 12)) (6.0.2)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 13)) (11.1.0)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 14)) (1.13.1)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 15)) (4.67.1)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 16)) (5.9.5)\n",
            "Requirement already satisfied: kornia>=0.7.1 in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 19)) (0.8.0)\n",
            "Requirement already satisfied: spandrel in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 20)) (0.4.1)\n",
            "Requirement already satisfied: soundfile in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 21)) (0.13.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch->-r requirements.txt (line 1)) (3.17.0)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.11/dist-packages (from torch->-r requirements.txt (line 1)) (4.12.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch->-r requirements.txt (line 1)) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch->-r requirements.txt (line 1)) (3.1.5)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch->-r requirements.txt (line 1)) (2024.10.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu11==11.8.89 in /usr/local/lib/python3.11/dist-packages (from torch->-r requirements.txt (line 1)) (11.8.89)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu11==11.8.89 in /usr/local/lib/python3.11/dist-packages (from torch->-r requirements.txt (line 1)) (11.8.89)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu11==11.8.87 in /usr/local/lib/python3.11/dist-packages (from torch->-r requirements.txt (line 1)) (11.8.87)\n",
            "Requirement already satisfied: nvidia-cudnn-cu11==9.1.0.70 in /usr/local/lib/python3.11/dist-packages (from torch->-r requirements.txt (line 1)) (9.1.0.70)\n",
            "Requirement already satisfied: nvidia-cublas-cu11==11.11.3.6 in /usr/local/lib/python3.11/dist-packages (from torch->-r requirements.txt (line 1)) (11.11.3.6)\n",
            "Requirement already satisfied: nvidia-cufft-cu11==10.9.0.58 in /usr/local/lib/python3.11/dist-packages (from torch->-r requirements.txt (line 1)) (10.9.0.58)\n",
            "Requirement already satisfied: nvidia-curand-cu11==10.3.0.86 in /usr/local/lib/python3.11/dist-packages (from torch->-r requirements.txt (line 1)) (10.3.0.86)\n",
            "Requirement already satisfied: nvidia-cusolver-cu11==11.4.1.48 in /usr/local/lib/python3.11/dist-packages (from torch->-r requirements.txt (line 1)) (11.4.1.48)\n",
            "Requirement already satisfied: nvidia-cusparse-cu11==11.7.5.86 in /usr/local/lib/python3.11/dist-packages (from torch->-r requirements.txt (line 1)) (11.7.5.86)\n",
            "Requirement already satisfied: nvidia-nccl-cu11==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch->-r requirements.txt (line 1)) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu11==11.8.86 in /usr/local/lib/python3.11/dist-packages (from torch->-r requirements.txt (line 1)) (11.8.86)\n",
            "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch->-r requirements.txt (line 1)) (3.2.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch->-r requirements.txt (line 1)) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch->-r requirements.txt (line 1)) (1.3.0)\n",
            "Requirement already satisfied: trampoline>=0.1.2 in /usr/local/lib/python3.11/dist-packages (from torchsde->-r requirements.txt (line 2)) (0.1.2)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.24.0 in /usr/local/lib/python3.11/dist-packages (from transformers>=4.28.1->-r requirements.txt (line 7)) (0.28.1)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from transformers>=4.28.1->-r requirements.txt (line 7)) (24.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers>=4.28.1->-r requirements.txt (line 7)) (2024.11.6)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from transformers>=4.28.1->-r requirements.txt (line 7)) (2.32.3)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->-r requirements.txt (line 11)) (2.4.4)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp->-r requirements.txt (line 11)) (1.3.2)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->-r requirements.txt (line 11)) (25.1.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp->-r requirements.txt (line 11)) (1.5.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp->-r requirements.txt (line 11)) (6.1.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->-r requirements.txt (line 11)) (0.2.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->-r requirements.txt (line 11)) (1.18.3)\n",
            "Requirement already satisfied: kornia_rs>=0.1.0 in /usr/local/lib/python3.11/dist-packages (from kornia>=0.7.1->-r requirements.txt (line 19)) (0.1.8)\n",
            "Requirement already satisfied: cffi>=1.0 in /usr/local/lib/python3.11/dist-packages (from soundfile->-r requirements.txt (line 21)) (1.17.1)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.11/dist-packages (from cffi>=1.0->soundfile->-r requirements.txt (line 21)) (2.22)\n",
            "Requirement already satisfied: idna>=2.0 in /usr/local/lib/python3.11/dist-packages (from yarl<2.0,>=1.17.0->aiohttp->-r requirements.txt (line 11)) (3.10)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch->-r requirements.txt (line 1)) (3.0.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->transformers>=4.28.1->-r requirements.txt (line 7)) (3.4.1)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->transformers>=4.28.1->-r requirements.txt (line 7)) (1.26.20)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->transformers>=4.28.1->-r requirements.txt (line 7)) (2025.1.31)\n",
            "‰ΩøÁî® Cloudflare Tunnel ËøêË°å ComfyUI\n",
            "--2025-02-08 14:39:55--  https://github.com/cloudflare/cloudflared/releases/latest/download/cloudflared-linux-amd64.deb\n",
            "Resolving github.com (github.com)... 20.205.243.166\n",
            "Connecting to github.com (github.com)|20.205.243.166|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://github.com/cloudflare/cloudflared/releases/download/2025.2.0/cloudflared-linux-amd64.deb [following]\n",
            "--2025-02-08 14:39:55--  https://github.com/cloudflare/cloudflared/releases/download/2025.2.0/cloudflared-linux-amd64.deb\n",
            "Reusing existing connection to github.com:443.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://objects.githubusercontent.com/github-production-release-asset-2e65be/106867604/8176fe8a-cc28-4022-90f5-59d75983238d?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=releaseassetproduction%2F20250208%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20250208T143955Z&X-Amz-Expires=300&X-Amz-Signature=a7fb0237aab169dcfabd3f6b33f4cb2ad9044d1534742fbbda23c5fce7d33e96&X-Amz-SignedHeaders=host&response-content-disposition=attachment%3B%20filename%3Dcloudflared-linux-amd64.deb&response-content-type=application%2Foctet-stream [following]\n",
            "--2025-02-08 14:39:55--  https://objects.githubusercontent.com/github-production-release-asset-2e65be/106867604/8176fe8a-cc28-4022-90f5-59d75983238d?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=releaseassetproduction%2F20250208%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20250208T143955Z&X-Amz-Expires=300&X-Amz-Signature=a7fb0237aab169dcfabd3f6b33f4cb2ad9044d1534742fbbda23c5fce7d33e96&X-Amz-SignedHeaders=host&response-content-disposition=attachment%3B%20filename%3Dcloudflared-linux-amd64.deb&response-content-type=application%2Foctet-stream\n",
            "Resolving objects.githubusercontent.com (objects.githubusercontent.com)... 185.199.110.133, 185.199.109.133, 185.199.111.133, ...\n",
            "Connecting to objects.githubusercontent.com (objects.githubusercontent.com)|185.199.110.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 18543368 (18M) [application/octet-stream]\n",
            "Saving to: ‚Äòcloudflared-linux-amd64.deb‚Äô\n",
            "\n",
            "cloudflared-linux-a 100%[===================>]  17.68M  64.3MB/s    in 0.3s    \n",
            "\n",
            "2025-02-08 14:39:58 (64.3 MB/s) - ‚Äòcloudflared-linux-amd64.deb‚Äô saved [18543368/18543368]\n",
            "\n",
            "(Reading database ... 124930 files and directories currently installed.)\n",
            "Preparing to unpack cloudflared-linux-amd64.deb ...\n",
            "Unpacking cloudflared (2025.2.0) over (2025.2.0) ...\n",
            "Setting up cloudflared (2025.2.0) ...\n",
            "Processing triggers for man-db (2.10.2-1) ...\n",
            "Adding extra search path checkpoints /content/drive/MyDrive/ComfyUI/mx/ckpt\n",
            "Adding extra search path clip /content/drive/MyDrive/ComfyUI/mx/clip/\n",
            "Adding extra search path clip_vision /content/drive/MyDrive/ComfyUI/mx/clip_vision/\n",
            "Adding extra search path configs /content/drive/MyDrive/ComfyUI/mx/configs/\n",
            "Adding extra search path controlnet /content/drive/MyDrive/ComfyUI/mx/controlnet/\n",
            "Adding extra search path diffusion_models /content/drive/MyDrive/ComfyUI/mx/diffusion_models\n",
            "Adding extra search path diffusion_models /content/drive/MyDrive/ComfyUI/mx/unet\n",
            "Adding extra search path embeddings /content/drive/MyDrive/ComfyUI/mx/embeddings/\n",
            "Adding extra search path loras /content/drive/MyDrive/ComfyUI/mx/lora\n",
            "Adding extra search path upscale_models /content/drive/MyDrive/ComfyUI/mx/upscale_models/\n",
            "Adding extra search path vae /content/drive/MyDrive/ComfyUI/mx/vae\n",
            "[START] Security scan\n",
            "[DONE] Security scan\n",
            "## ComfyUI-Manager: installing dependencies done.\n",
            "** ComfyUI startup time: 2025-02-08 14:40:00.931\n",
            "** Platform: Linux\n",
            "** Python version: 3.11.11 (main, Dec  4 2024, 08:55:07) [GCC 11.4.0]\n",
            "** Python executable: /usr/bin/python3\n",
            "** ComfyUI Path: /content/drive/MyDrive/ComfyUI\n",
            "** ComfyUI Base Folder Path: /content/drive/MyDrive/ComfyUI\n",
            "** User directory: /content/drive/MyDrive/ComfyUI/user\n",
            "** ComfyUI-Manager config path: /content/drive/MyDrive/ComfyUI/user/default/ComfyUI-Manager/config.ini\n",
            "** Log path: /content/drive/MyDrive/ComfyUI/user/comfyui.log\n",
            "\n",
            "Prestartup times for custom nodes:\n",
            "   4.0 seconds: /content/drive/MyDrive/ComfyUI/custom_nodes/ComfyUI-Manager\n",
            "\n",
            "Checkpoint files will always be loaded safely.\n",
            "Total VRAM 15095 MB, total RAM 12979 MB\n",
            "pytorch version: 2.6.0+cu118\n",
            "xformers version: 0.0.29.post2\n",
            "Set vram state to: NORMAL_VRAM\n",
            "Device: cuda:0 Tesla T4 : cudaMallocAsync\n",
            "Using xformers attention\n",
            "ComfyUI version: 0.3.14\n",
            "[Prompt Server] web root: /content/drive/MyDrive/ComfyUI/web\n",
            "### Loading: ComfyUI-Manager (V3.17.10)\n",
            "### ComfyUI Version: 0.1.0-2-g1a3c5701 | Released on '2025-02-08'\n",
            "\u001b[92m[üíæ save_image_extended] AVIF   is supported! Woohoo!\u001b[0m\n",
            "\u001b[92m[üíæ save_image_extended] JPEGXL is supported! YeePee!\u001b[0m\n",
            "\u001b[92m[üíæ save_image_extended]\u001b[0m version: 2.83\u001b[0m\n",
            "[ComfyUI-Manager] default cache updated: https://raw.githubusercontent.com/ltdrdata/ComfyUI-Manager/main/model-list.json\n",
            "\n",
            "Import times for custom nodes:\n",
            "   0.0 seconds: /content/drive/MyDrive/ComfyUI/custom_nodes/websocket_image_save.py\n",
            "   0.0 seconds: /content/drive/MyDrive/ComfyUI/custom_nodes/comfyui-filepathcreator\n",
            "   0.0 seconds: /content/drive/MyDrive/ComfyUI/custom_nodes/save-image-extended-comfyui\n",
            "   1.4 seconds: /content/drive/MyDrive/ComfyUI/custom_nodes/ComfyUI-Manager\n",
            "\n",
            "\n",
            "ComfyUI Âä†ËΩΩÂÆåÊàêÔºåÂ∞ùËØïÂêØÂä® cloudflared (Â¶ÇÊûúÂç°‰ΩèÔºåcloudflared ÂèØËÉΩÊúâÈóÆÈ¢ò)\n",
            "\n",
            "[ComfyUI-Manager] default cache updated: https://raw.githubusercontent.com/ltdrdata/ComfyUI-Manager/main/extension-node-map.json\n",
            "[ComfyUI-Manager] default cache updated: https://raw.githubusercontent.com/ltdrdata/ComfyUI-Manager/main/custom-node-list.json\n",
            "[ComfyUI-Manager] default cache updated: https://raw.githubusercontent.com/ltdrdata/ComfyUI-Manager/main/alter-list.json\n",
            "[ComfyUI-Manager] default cache updated: https://raw.githubusercontent.com/ltdrdata/ComfyUI-Manager/main/github-stats.json\n",
            "FETCH ComfyRegistry Data: 5/32\n",
            "ComfyUI ÁöÑËÆøÈóÆÈìæÊé•: https://pierce-descriptions-bbs-concord.trycloudflare.com                                 |\n",
            "FETCH ComfyRegistry Data: 10/32\n",
            "FETCH ComfyRegistry Data: 15/32\n",
            "FETCH ComfyRegistry Data: 20/32\n",
            "FETCH ComfyRegistry Data: 25/32\n",
            "FETCH ComfyRegistry Data: 30/32\n",
            "FETCH ComfyRegistry Data [DONE]\n",
            "[ComfyUI-Manager] default cache updated: https://api.comfy.org/nodes\n",
            "nightly_channel: https://raw.githubusercontent.com/ltdrdata/ComfyUI-Manager/main/remote\n",
            "FETCH DATA from: https://raw.githubusercontent.com/ltdrdata/ComfyUI-Manager/main/custom-node-list.json [DONE]\n",
            "[ComfyUI-Manager] All startup tasks have been completed.\n",
            "FETCH DATA from: /content/drive/MyDrive/ComfyUI/custom_nodes/ComfyUI-Manager/extension-node-map.json [DONE]\n",
            "FETCH DATA from: /content/drive/MyDrive/ComfyUI/custom_nodes/ComfyUI-Manager/extension-node-map.json [DONE]\n",
            "FETCH DATA from: /content/drive/MyDrive/ComfyUI/custom_nodes/ComfyUI-Manager/extension-node-map.json [DONE]\n",
            "FETCH DATA from: /content/drive/MyDrive/ComfyUI/user/default/ComfyUI-Manager/cache/1742899825_extension-node-map.json [DONE]\n",
            "[ComfyUI-Manager] The ComfyRegistry cache update is still in progress, so an outdated cache is being used.\n",
            "nightly_channel: https://raw.githubusercontent.com/ltdrdata/ComfyUI-Manager/main/cache\n",
            "FETCH DATA from: /content/drive/MyDrive/ComfyUI/user/default/ComfyUI-Manager/cache/1514988643_custom-node-list.json [DONE]\n",
            "FETCH DATA from: /content/drive/MyDrive/ComfyUI/user/default/ComfyUI-Manager/cache/746607195_github-stats.json [DONE]\n",
            "FETCH DATA from: /content/drive/MyDrive/ComfyUI/user/default/ComfyUI-Manager/cache/832903789_extras.json [DONE]\n",
            "got prompt\n",
            "model weight dtype torch.float16, manual cast: None\n",
            "model_type V_PREDICTION\n",
            "Using xformers attention in VAE\n",
            "Using xformers attention in VAE\n",
            "VAE load device: cuda:0, offload device: cpu, dtype: torch.float32\n",
            "Requested to load SDXLClipModel\n",
            "loaded completely 9.5367431640625e+25 1560.802734375 True\n",
            "CLIP/text encoder model load device: cuda:0, offload device: cpu, current: cuda:0, dtype: torch.float16\n",
            "loaded diffusion model directly to GPU\n",
            "Requested to load SDXL\n",
            "loaded completely 9.5367431640625e+25 4897.0483474731445 True\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (116 > 77). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (116 > 77). Running this sequence through the model will result in indexing errors\n",
            "Requested to load SDXLClipModel\n",
            "loaded completely 8855.828739929198 1560.802734375 True\n",
            "Requested to load SDXL\n",
            "loaded completely 11513.187393188477 4897.0483474731445 True\n",
            "100% 25/25 [02:22<00:00,  5.70s/it]\n",
            "Requested to load AutoencoderKL\n",
            "loaded completely 1291.7459899902344 319.11416244506836 True\n",
            "Prompt executed in 227.58 seconds\n",
            "got prompt\n",
            "SaveImageExtended 2.83 error: An error occurred while creating the subfolder or saving the image: [Errno 2] No such file or directory: '/content/drive/MyDrive/ComfyUI/output/2025-02-08/ComfyUI/0001/2025-02-08 14-56-18.png'\n",
            "!!! Exception during processing !!! object of type 'NoneType' has no len()\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/drive/MyDrive/ComfyUI/execution.py\", line 327, in execute\n",
            "    output_data, output_ui, has_subgraph = get_output_data(obj, input_data_all, execution_block_cb=execution_block_cb, pre_execute_cb=pre_execute_cb)\n",
            "                                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/drive/MyDrive/ComfyUI/execution.py\", line 232, in get_output_data\n",
            "    output = merge_result_data(results, obj)\n",
            "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/drive/MyDrive/ComfyUI/execution.py\", line 180, in merge_result_data\n",
            "    output_is_list = [False] * len(results[0])\n",
            "                               ^^^^^^^^^^^^^^^\n",
            "TypeError: object of type 'NoneType' has no len()\n",
            "\n",
            "Prompt executed in 0.11 seconds\n",
            "got prompt\n",
            "SaveImageExtended 2.83 error: An error occurred while creating the subfolder or saving the image: [Errno 2] No such file or directory: '/content/drive/MyDrive/ComfyUI/output/2025-02-08/ComfyUI/0001/2025-02-08 14-56-28.png'\n",
            "!!! Exception during processing !!! object of type 'NoneType' has no len()\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/drive/MyDrive/ComfyUI/execution.py\", line 327, in execute\n",
            "    output_data, output_ui, has_subgraph = get_output_data(obj, input_data_all, execution_block_cb=execution_block_cb, pre_execute_cb=pre_execute_cb)\n",
            "                                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/drive/MyDrive/ComfyUI/execution.py\", line 232, in get_output_data\n",
            "    output = merge_result_data(results, obj)\n",
            "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/drive/MyDrive/ComfyUI/execution.py\", line 180, in merge_result_data\n",
            "    output_is_list = [False] * len(results[0])\n",
            "                               ^^^^^^^^^^^^^^^\n",
            "TypeError: object of type 'NoneType' has no len()\n",
            "\n",
            "Prompt executed in 0.08 seconds\n",
            "got prompt\n",
            "SaveImageExtended 2.83 error: An error occurred while creating the subfolder or saving the image: [Errno 2] No such file or directory: '/content/drive/MyDrive/ComfyUI/output/2025-02-08/ComfyUI/0001/2025-02-08 14-56-38.png'\n",
            "!!! Exception during processing !!! object of type 'NoneType' has no len()\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/drive/MyDrive/ComfyUI/execution.py\", line 327, in execute\n",
            "    output_data, output_ui, has_subgraph = get_output_data(obj, input_data_all, execution_block_cb=execution_block_cb, pre_execute_cb=pre_execute_cb)\n",
            "                                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/drive/MyDrive/ComfyUI/execution.py\", line 232, in get_output_data\n",
            "    output = merge_result_data(results, obj)\n",
            "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/drive/MyDrive/ComfyUI/execution.py\", line 180, in merge_result_data\n",
            "    output_is_list = [False] * len(results[0])\n",
            "                               ^^^^^^^^^^^^^^^\n",
            "TypeError: object of type 'NoneType' has no len()\n",
            "\n",
            "Prompt executed in 0.08 seconds\n",
            "got prompt\n",
            "SaveImageExtended 2.83 error: An error occurred while creating the subfolder or saving the image: [Errno 2] No such file or directory: '/content/drive/MyDrive/ComfyUI/output/2025-02-08/ComfyUI/0001/2025-02-08 14-57-54.png'\n",
            "!!! Exception during processing !!! object of type 'NoneType' has no len()\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/drive/MyDrive/ComfyUI/execution.py\", line 327, in execute\n",
            "    output_data, output_ui, has_subgraph = get_output_data(obj, input_data_all, execution_block_cb=execution_block_cb, pre_execute_cb=pre_execute_cb)\n",
            "                                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/drive/MyDrive/ComfyUI/execution.py\", line 232, in get_output_data\n",
            "    output = merge_result_data(results, obj)\n",
            "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/drive/MyDrive/ComfyUI/execution.py\", line 180, in merge_result_data\n",
            "    output_is_list = [False] * len(results[0])\n",
            "                               ^^^^^^^^^^^^^^^\n",
            "TypeError: object of type 'NoneType' has no len()\n",
            "\n",
            "Prompt executed in 0.08 seconds\n",
            "got prompt\n",
            "Prompt executed in 17.79 seconds\n",
            "got prompt\n",
            "Prompt executed in 0.00 seconds\n",
            "got prompt\n",
            "Prompt executed in 0.00 seconds\n",
            "got prompt\n",
            "Prompt executed in 0.01 seconds\n",
            "got prompt\n",
            "Prompt executed in 17.70 seconds\n",
            "got prompt\n",
            "Requested to load SDXL\n",
            "loaded completely 12746.875972747803 4897.0483474731445 True\n",
            "100% 25/25 [02:10<00:00,  5.22s/it]\n",
            "Prompt executed in 164.89 seconds\n",
            "got prompt\n",
            "Requested to load SDXL\n",
            "got prompt\n",
            "loaded completely 13391.675972747802 4897.0483474731445 True\n",
            "100% 25/25 [00:33<00:00,  1.33s/it]\n",
            "Prompt executed in 43.32 seconds\n",
            "got prompt\n",
            "Prompt executed in 0.40 seconds\n",
            "got prompt\n",
            "Requested to load SDXLClipModel\n",
            "loaded completely 11352.140854644775 1560.802734375 True\n",
            "loaded completely 11830.873230743407 4897.0483474731445 True\n",
            "100% 25/25 [00:33<00:00,  1.35s/it]\n",
            "Prompt executed in 40.69 seconds\n",
            "got prompt\n",
            "Prompt executed in 3.67 seconds\n",
            "got prompt\n",
            "Prompt executed in 0.00 seconds\n",
            "got prompt\n",
            "Prompt executed in 0.00 seconds\n",
            "got prompt\n",
            "Prompt executed in 0.00 seconds\n",
            "got prompt\n",
            "loaded completely 13391.675972747802 4897.0483474731445 True\n",
            "100% 25/25 [00:33<00:00,  1.34s/it]\n",
            "Prompt executed in 41.53 seconds\n",
            "got prompt\n",
            "got prompt\n",
            "loaded completely 12746.875972747803 4897.0483474731445 True\n",
            "  0% 0/25 [00:00<?, ?it/s]got prompt\n",
            "  4% 1/25 [00:02<00:55,  2.30s/it]got prompt\n",
            " 52% 13/25 [01:09<01:09,  5.76s/it]got prompt\n",
            "got prompt\n",
            " 72% 18/25 [01:38<00:40,  5.78s/it]got prompt\n",
            "got prompt\n",
            "got prompt\n",
            " 76% 19/25 [01:44<00:34,  5.76s/it]got prompt\n",
            "100% 25/25 [02:18<00:00,  5.54s/it]\n",
            "got prompt\n",
            "got prompt\n",
            "Prompt executed in 170.15 seconds\n",
            "Prompt executed in 0.00 seconds\n",
            "Prompt executed in 0.00 seconds\n",
            "Prompt executed in 0.00 seconds\n",
            "Requested to load SDXLClipModel\n",
            "loaded completely 11352.140854644775 1560.802734375 True\n",
            "loaded completely 11186.073230743408 4897.0483474731445 True\n",
            " 24% 6/25 [00:31<01:49,  5.74s/it]got prompt\n",
            "got prompt\n",
            "100% 25/25 [02:21<00:00,  5.65s/it]\n",
            "Prompt executed in 176.56 seconds\n",
            "Prompt executed in 0.00 seconds\n",
            "Requested to load SDXLClipModel\n",
            "loaded completely 11352.140854644775 1560.802734375 True\n",
            "loaded completely 11186.073230743408 4897.0483474731445 True\n",
            "100% 25/25 [02:16<00:00,  5.46s/it]\n",
            "Prompt executed in 169.22 seconds\n",
            "Prompt executed in 0.00 seconds\n",
            "Prompt executed in 0.00 seconds\n",
            "Prompt executed in 0.00 seconds\n",
            "Requested to load SDXLClipModel\n",
            "loaded completely 11352.140854644775 1560.802734375 True\n",
            "loaded completely 11186.073230743408 4897.0483474731445 True\n",
            "100% 25/25 [02:16<00:00,  5.46s/it]\n",
            "Prompt executed in 166.01 seconds\n",
            "Prompt executed in 0.01 seconds\n",
            "Requested to load SDXLClipModel\n",
            "loaded completely 11352.140854644775 1560.802734375 True\n",
            "loaded completely 11186.073230743408 4897.0483474731445 True\n",
            " 20% 5/25 [00:25<01:51,  5.58s/it]got prompt\n",
            " 24% 6/25 [00:31<01:48,  5.73s/it]got prompt\n",
            " 28% 7/25 [00:37<01:44,  5.79s/it]got prompt\n",
            "got prompt\n",
            " 32% 8/25 [00:43<01:38,  5.80s/it]got prompt\n",
            " 36% 9/25 [00:49<01:32,  5.80s/it]got prompt\n",
            " 40% 10/25 [00:55<01:26,  5.79s/it]got prompt\n",
            " 44% 11/25 [01:00<01:20,  5.76s/it]got prompt\n",
            " 48% 12/25 [01:06<01:14,  5.74s/it]got prompt\n",
            " 52% 13/25 [01:12<01:08,  5.73s/it]got prompt\n",
            " 56% 14/25 [01:17<01:02,  5.71s/it]got prompt\n",
            " 60% 15/25 [01:23<00:57,  5.71s/it]got prompt\n",
            " 64% 16/25 [01:29<00:51,  5.71s/it]got prompt\n",
            " 68% 17/25 [01:34<00:45,  5.72s/it]got prompt\n",
            "100% 25/25 [02:21<00:00,  5.65s/it]\n",
            "Prompt executed in 177.99 seconds\n",
            "Prompt executed in 0.00 seconds\n",
            "Requested to load SDXLClipModel\n",
            "loaded completely 11352.140854644775 1560.802734375 True\n",
            "loaded completely 11186.073230743408 4897.0483474731445 True\n",
            "100% 25/25 [02:16<00:00,  5.46s/it]\n",
            "Prompt executed in 172.17 seconds\n",
            "Prompt executed in 0.00 seconds\n",
            "Prompt executed in 0.00 seconds\n",
            "Prompt executed in 0.00 seconds\n",
            "Prompt executed in 0.00 seconds\n",
            "Prompt executed in 0.00 seconds\n",
            "Prompt executed in 0.00 seconds\n",
            "Prompt executed in 0.00 seconds\n",
            "Prompt executed in 0.00 seconds\n",
            "Prompt executed in 0.00 seconds\n",
            "Prompt executed in 0.00 seconds\n",
            "Prompt executed in 0.00 seconds\n",
            "Prompt executed in 0.00 seconds\n",
            "Prompt executed in 0.00 seconds\n",
            "got prompt\n",
            "Prompt executed in 0.00 seconds\n",
            "got prompt\n",
            "Prompt executed in 0.00 seconds\n",
            "got prompt\n",
            "Requested to load SDXLClipModel\n",
            "loaded completely 11352.140854644775 1560.802734375 True\n",
            "loaded completely 11186.073230743408 4897.0483474731445 True\n",
            "  4% 1/25 [00:02<01:00,  2.50s/it]got prompt\n",
            "  8% 2/25 [00:08<01:42,  4.44s/it]got prompt\n",
            " 12% 3/25 [00:14<01:52,  5.09s/it]got prompt\n",
            " 40% 10/25 [00:53<01:22,  5.51s/it]got prompt\n",
            " 44% 11/25 [00:58<01:16,  5.49s/it]got prompt\n",
            " 76% 19/25 [01:43<00:33,  5.57s/it]got prompt\n",
            " 80% 20/25 [01:48<00:27,  5.59s/it]got prompt\n",
            "100% 25/25 [02:16<00:00,  5.47s/it]\n",
            "Prompt executed in 166.43 seconds\n",
            "Prompt executed in 0.00 seconds\n",
            "Prompt executed in 0.00 seconds\n",
            "Prompt executed in 0.00 seconds\n",
            "Requested to load SDXLClipModel\n",
            "loaded completely 11352.140854644775 1560.802734375 True\n",
            "loaded completely 11186.073230743408 4897.0483474731445 True\n",
            " 12% 3/25 [00:13<01:45,  4.81s/it]got prompt\n",
            " 16% 4/25 [00:19<01:48,  5.15s/it]got prompt\n",
            "100% 25/25 [02:16<00:00,  5.45s/it]\n",
            "Prompt executed in 166.06 seconds\n",
            "Prompt executed in 0.00 seconds\n",
            "Requested to load SDXLClipModel\n",
            "loaded completely 11352.140854644775 1560.802734375 True\n",
            "loaded completely 11186.073230743408 4897.0483474731445 True\n",
            "100% 25/25 [02:16<00:00,  5.45s/it]\n",
            "Prompt executed in 172.05 seconds\n",
            "Requested to load SDXLClipModel\n",
            "loaded completely 11352.140854644775 1560.802734375 True\n",
            "loaded completely 11186.073230743408 4897.0483474731445 True\n",
            "100% 25/25 [02:16<00:00,  5.45s/it]\n",
            "Prompt executed in 165.30 seconds\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/drive/MyDrive/ComfyUI/main.py\", line 300, in <module>\n",
            "    event_loop.run_until_complete(start_all_func())\n",
            "  File \"/usr/lib/python3.11/asyncio/base_events.py\", line 641, in run_until_complete\n",
            "    self.run_forever()\n",
            "  File \"/usr/lib/python3.11/asyncio/base_events.py\", line 608, in run_forever\n",
            "    self._run_once()\n",
            "  File \"/usr/lib/python3.11/asyncio/base_events.py\", line 1898, in _run_once\n",
            "    event_list = self._selector.select(timeout)\n",
            "                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/lib/python3.11/selectors.py\", line 468, in select\n",
            "    fd_event_list = self._selector.poll(timeout, max_ev)\n",
            "                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "KeyboardInterrupt\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/drive/MyDrive/ComfyUI/main.py\", line 302, in <module>\n",
            "    logging.info(\"\\nStopped server\")\n",
            "  File \"/usr/lib/python3.11/logging/__init__.py\", line 2141, in info\n",
            "    root.info(msg, *args, **kwargs)\n",
            "  File \"/usr/lib/python3.11/logging/__init__.py\", line 1489, in info\n",
            "    self._log(INFO, msg, args, **kwargs)\n",
            "  File \"/usr/lib/python3.11/logging/__init__.py\", line 1610, in _log\n",
            "    def _log(self, level, msg, args, exc_info=None, extra=None, stack_info=False,\n",
            "\n",
            "KeyboardInterrupt\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'Ê£ÄÊü•cloudflared_URL' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-2-d5a6cb14909c>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    218\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    219\u001b[0m    \u001b[0;31m# Âú® ComfyUI ÂêØÂä®Âêé 10 ÁßíÂêØÂä® URL Ê£ÄÊü•Á∫øÁ®ã\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 220\u001b[0;31m    \u001b[0mthreading\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mThread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtarget\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mÊ£ÄÊü•cloudflared_URL\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdaemon\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstart\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    221\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    222\u001b[0m \u001b[0;32melif\u001b[0m \u001b[0mËøêË°åÊñπÂºè\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"localtunnel\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'Ê£ÄÊü•cloudflared_URL' is not defined"
          ]
        }
      ],
      "source": [
        " # @title ComfyUI ‰∏ÄÈîÆÂÆâË£ÖËÑöÊú¨ (Google Colab)\n",
        "\n",
        "# @markdown Á°Æ‰øùÊÇ®Â∑≤ËøûÊé•Âà∞ GPU ËøêË°åÊó∂ (ËøêË°åÊó∂ -> Êõ¥ÊîπËøêË°åÊó∂Á±ªÂûã -> GPU)\n",
        "\n",
        "# @markdown **ÁéØÂ¢ÉËÆæÁΩÆ**\n",
        "\n",
        "‰ΩøÁî®_Ë∞∑Ê≠å‰∫ëÁõò = True  # @param {type:\"boolean\"}\n",
        "Êõ¥Êñ∞_ComfyUI = True  # @param {type:\"boolean\"}\n",
        "Â∑•‰ΩúÂå∫ = '/content/ComfyUI'\n",
        "\n",
        "ÈÄâÈ°π = {}\n",
        "ÈÄâÈ°π['‰ΩøÁî®_Ë∞∑Ê≠å‰∫ëÁõò'] = ‰ΩøÁî®_Ë∞∑Ê≠å‰∫ëÁõò\n",
        "ÈÄâÈ°π['Êõ¥Êñ∞_ComfyUI'] = Êõ¥Êñ∞_ComfyUI\n",
        "\n",
        "if ÈÄâÈ°π['‰ΩøÁî®_Ë∞∑Ê≠å‰∫ëÁõò']:\n",
        "    print(\"Ê≠£Âú®ÊåÇËΩΩ Google ‰∫ëÁõò...\")\n",
        "    %cd /\n",
        "\n",
        "    from google.colab import drive\n",
        "    drive.mount('/content/drive')\n",
        "\n",
        "    Â∑•‰ΩúÂå∫ = \"/content/drive/MyDrive/ComfyUI\"\n",
        "    %cd /content/drive/MyDrive\n",
        "\n",
        "![ ! -d $Â∑•‰ΩúÂå∫ ] && echo -= È¶ñÊ¨°ÂÆâË£Ö ComfyUI =- && git clone https://github.com/mrnfqrbl/ComfyUI\n",
        "%cd $Â∑•‰ΩúÂå∫\n",
        "\n",
        "if ÈÄâÈ°π['Êõ¥Êñ∞_ComfyUI']:\n",
        "  # !git remote set-url origin https://github.com/mrnfqrbl/ComfyUI\n",
        "  print(\"-= Ê≠£Âú®Êõ¥Êñ∞ ComfyUI =-\")\n",
        "\n",
        "  !git pull\n",
        "\n",
        "print(\"-= Ê≠£Âú®ÂÆâË£Ö‰æùËµñÈ°π =-\")\n",
        "!pip install xformers!=0.0.18 -r requirements.txt --extra-index-url https://download.pytorch.org/whl/cu121 --extra-index-url https://download.pytorch.org/whl/cu118 --extra-index-url https://download.pytorch.org/whl/cu117\n",
        "\n",
        "\n",
        "\n",
        "# Ê£ÄÊü•ÁÇπ (Checkpoints)\n",
        "\n",
        "# SDXL\n",
        "# Êé®ËçêÂ∑•‰ΩúÊµÅÁ§∫‰æã: https://comfyanonymous.github.io/ComfyUI_examples/sdxl/\n",
        "\n",
        "#!wget -c https://huggingface.co/stabilityai/stable-diffusion-xl-base-1.0/resolve/main/sd_xl_base_1.0.safetensors -P ./models/checkpoints/\n",
        "#!wget -c https://huggingface.co/stabilityai/stable-diffusion-xl-refiner-1.0/resolve/main/sd_xl_refiner_1.0.safetensors -P ./models/checkpoints/\n",
        "\n",
        "# SDXL ReVision\n",
        "#!wget -c https://huggingface.co/comfyanonymous/clip_vision_g/resolve/main/clip_vision_g.safetensors -P ./models/clip_vision/\n",
        "\n",
        "# SD1.5\n",
        "# !wget -c https://huggingface.co/Comfy-Org/stable-diffusion-v1-5-archive/resolve/main/v1-5-pruned-emaonly-fp16.safetensors -P ./models/checkpoints/\n",
        "\n",
        "# SD2\n",
        "#!wget -c https://huggingface.co/stabilityai/stable-diffusion-2-1-base/resolve/main/v2-1_512-ema-pruned.safetensors -P ./models/checkpoints/\n",
        "#!wget -c https://huggingface.co/stabilityai/stable-diffusion-2-1/resolve/main/v2-1_768-ema-pruned.safetensors -P ./models/checkpoints/\n",
        "\n",
        "# ‰∏Ä‰∫õ SD1.5 Âä®Êº´È£éÊ†ºÊ®°Âûã\n",
        "#!wget -c https://huggingface.co/WarriorMama777/OrangeMixs/resolve/main/Models/AbyssOrangeMix2/AbyssOrangeMix2_hard.safetensors -P ./models/checkpoints/\n",
        "#!wget -c https://huggingface.co/WarriorMama777/OrangeMixs/resolve/main/Models/AbyssOrangeMix3/AOM3A1_orangemixs.safetensors -P ./models/checkpoints/\n",
        "#!wget -c https://huggingface.co/WarriorMama777/OrangeMixs/resolve/main/Models/AbyssOrangeMix3/AOM3A3_orangemixs.safetensors -P ./models/checkpoints/\n",
        "#!wget -c https://huggingface.co/Linaqruf/anything-v3.0/resolve/main/anything-v3-fp16-pruned.safetensors -P ./models/checkpoints/\n",
        "\n",
        "# Waifu Diffusion 1.5 (Âä®Êº´È£éÊ†º SD2.x 768-v)\n",
        "#!wget -c https://huggingface.co/waifu-diffusion/wd-1-5-beta3/resolve/main/wd-illusion-fp16.safetensors -P ./models/checkpoints/\n",
        "\n",
        "# unCLIP Ê®°Âûã\n",
        "#!wget -c https://huggingface.co/comfyanonymous/illuminatiDiffusionV1_v11_unCLIP/resolve/main/illuminatiDiffusionV1_v11-unclip-h-fp16.safetensors -P ./models/checkpoints/\n",
        "#!wget -c https://huggingface.co/comfyanonymous/wd-1.5-beta2_unCLIP/resolve/main/wd-1-5-beta2-aesthetic-unclip-h-fp16.safetensors -P ./models/checkpoints/\n",
        "\n",
        "# VAE\n",
        "# !wget -c https://huggingface.co/stabilityai/sd-vae-ft-mse-original/resolve/main/vae-ft-mse-840000-ema-pruned.safetensors -P ./models/vae/\n",
        "#!wget -c https://huggingface.co/WarriorMama777/OrangeMixs/resolve/main/VAEs/orangemix.vae.pt -P ./models/vae/\n",
        "#!wget -c https://huggingface.co/hakurei/waifu-diffusion-v1-4/resolve/main/vae/kl-f8-anime2.ckpt -P ./models/vae/\n",
        "\n",
        "# Loras\n",
        "#!wget -c https://civitai.com/api/download/models/10350 -O ./models/loras/theovercomer8sContrastFix_sd21768.safetensors #theovercomer8sContrastFix SD2.x 768-v\n",
        "#!wget -c https://civitai.com/api/download/models/10638 -O ./models/loras/theovercomer8sContrastFix_sd15.safetensors #theovercomer8sContrastFix SD1.x\n",
        "#!wget -c https://huggingface.co/stabilityai/stable-diffusion-xl-base-1.0/resolve/main/sd_xl_offset_example-lora_1.0.safetensors -P ./models/loras/ #SDXL offset noise lora\n",
        "\n",
        "# T2I-Adapter\n",
        "#!wget -c https://huggingface.co/TencentARC/T2I-Adapter/resolve/main/models/t2iadapter_depth_sd14v1.pth -P ./models/controlnet/\n",
        "#!wget -c https://huggingface.co/TencentARC/T2I-Adapter/resolve/main/models/t2iadapter_seg_sd14v1.pth -P ./models/controlnet/\n",
        "#!wget -c https://huggingface.co/TencentARC/T2I-Adapter/resolve/main/models/t2iadapter_sketch_sd14v1.pth -P ./models/controlnet/\n",
        "#!wget -c https://huggingface.co/TencentARC/T2I-Adapter/resolve/main/models/t2iadapter_keypose_sd14v1.pth -P ./models/controlnet/\n",
        "#!wget -c https://huggingface.co/TencentARC/T2I-Adapter/resolve/main/models/t2iadapter_openpose_sd14v1.pth -P ./models/controlnet/\n",
        "#!wget -c https://huggingface.co/TencentARC/T2I-Adapter/resolve/main/models/t2iadapter_color_sd14v1.pth -P ./models/controlnet/\n",
        "#!wget -c https://huggingface.co/TencentARC/T2I-Adapter/resolve/main/models/t2iadapter_canny_sd14v1.pth -P ./models/controlnet/\n",
        "\n",
        "# T2I Styles Model\n",
        "#!wget -c https://huggingface.co/TencentARC/T2I-Adapter/resolve/main/models/t2iadapter_style_sd14v1.pth -P ./models/style_models/\n",
        "\n",
        "# CLIPVision Ê®°Âûã (styles model ÈúÄË¶Å)\n",
        "#!wget -c https://huggingface.co/openai/clip-vit-large-patch14/resolve/main/pytorch_model.bin -O ./models/clip_vision/clip_vit14.bin\n",
        "\n",
        "# ControlNet\n",
        "#!wget -c https://huggingface.co/comfyanonymous/ControlNet-v1-1_fp16_safetensors/resolve/main/control_v11e_sd15_ip2p_fp16.safetensors -P ./models/controlnet/\n",
        "#!wget -c https://huggingface.co/comfyanonymous/ControlNet-v1-1_fp16_safetensors/resolve/main/control_v11e_sd15_shuffle_fp16.safetensors -P ./models/controlnet/\n",
        "#!wget -c https://huggingface.co/comfyanonymous/ControlNet-v1-1_fp16_safetensors/resolve/main/control_v11p_sd15_canny_fp16.safetensors -P ./models/controlnet/\n",
        "#!wget -c https://huggingface.co/comfyanonymous/ControlNet-v1-1_fp16_safetensors/resolve/main/control_v11f1p_sd15_depth_fp16.safetensors -P ./models/controlnet/\n",
        "#!wget -c https://huggingface.co/comfyanonymous/ControlNet-v1-1_fp16_safetensors/resolve/main/control_v11p_sd15_inpaint_fp16.safetensors -P ./models/controlnet/\n",
        "#!wget -c https://huggingface.co/comfyanonymous/ControlNet-v1-1_fp16_safetensors/resolve/main/control_v11p_sd15_lineart_fp16.safetensors -P ./models/controlnet/\n",
        "#!wget -c https://huggingface.co/comfyanonymous/ControlNet-v1-1_fp16_safetensors/resolve/main/control_v11p_sd15_mlsd_fp16.safetensors -P ./models/controlnet/\n",
        "#!wget -c https://huggingface.co/comfyanonymous/ControlNet-v1-1_fp16_safetensors/resolve/main/control_v11p_sd15_normalbae_fp16.safetensors -P ./models/controlnet/\n",
        "#!wget -c https://huggingface.co/comfyanonymous/ControlNet-v1-1_fp16_safetensors/resolve/main/control_v11p_sd15_openpose_fp16.safetensors -P ./models/controlnet/\n",
        "#!wget -c https://huggingface.co/comfyanonymous/ControlNet-v1-1_fp16_safetensors/resolve/main/control_v11p_sd15_scribble_fp16.safetensors -P ./models/controlnet/\n",
        "#!wget -c https://huggingface.co/comfyanonymous/ControlNet-v1-1_fp16_safetensors/resolve/main/control_v11p_sd15_seg_fp16.safetensors -P ./models/controlnet/\n",
        "#!wget -c https://huggingface.co/comfyanonymous/ControlNet-v1-1_fp16_safetensors/resolve/main/control_v11p_sd15_softedge_fp16.safetensors -P ./models/controlnet/\n",
        "#!wget -c https://huggingface.co/comfyanonymous/ControlNet-v1-1_fp16_safetensors/resolve/main/control_v11p_sd15s2_lineart_anime_fp16.safetensors -P ./models/controlnet/\n",
        "#!wget -c https://huggingface.co/comfyanonymous/ControlNet-v1-1_fp16_safetensors/resolve/main/control_v11u_sd15_tile_fp16.safetensors -P ./models/controlnet/\n",
        "\n",
        "# ControlNet SDXL\n",
        "#!wget -c https://huggingface.co/stabilityai/control-lora/resolve/main/control-LoRAs-rank256/control-lora-canny-rank256.safetensors -P ./models/controlnet/\n",
        "#!wget -c https://huggingface.co/stabilityai/control-lora/resolve/main/control-LoRAs-rank256/control-lora-depth-rank256.safetensors -P ./models/controlnet/\n",
        "#!wget -c https://huggingface.co/stabilityai/control-lora/resolve/main/control-LoRAs-rank256/control-lora-recolor-rank256.safetensors -P ./models/controlnet/\n",
        "#!wget -c https://huggingface.co/stabilityai/control-lora/resolve/main/control-LoRAs-rank256/control-lora-sketch-rank256.safetensors -P ./models/controlnet/\n",
        "\n",
        "# Controlnet Preprocessor nodes by Fannovel16\n",
        "#!cd custom_nodes && git clone https://github.com/Fannovel16/comfy_controlnet_preprocessors; cd comfy_controlnet_preprocessors && python install.py\n",
        "\n",
        "# GLIGEN\n",
        "#!wget -c https://huggingface.co/comfyanonymous/GLIGEN_pruned_safetensors/resolve/main/gligen_sd14_textbox_pruned_fp16.safetensors -P ./models/gligen/\n",
        "\n",
        "# ESRGAN ÊîæÂ§ßÊ®°Âûã\n",
        "#!wget -c https://github.com/xinntao/Real-ESRGAN/releases/download/v0.1.0/RealESRGAN_x4plus.pth -P ./models/upscale_models/\n",
        "#!wget -c https://huggingface.co/sberbank-ai/Real-ESRGAN/resolve/main/RealESRGAN_x2.pth -P ./models/upscale_models/\n",
        "#!wget -c https://huggingface.co/sberbank-ai/Real-ESRGAN/resolve/main/RealESRGAN_x4.pth -P ./models/upscale_models/\n",
        "\n",
        "ÂÆâË£ÖËá™ÂÆö‰πâËäÇÁÇπ=True #@param {type:\"boolean\"}\n",
        "\n",
        "if ÂÆâË£ÖËá™ÂÆö‰πâËäÇÁÇπ:\n",
        "  !echo -= Install custom nodes dependencies =-\n",
        "  !pip install GitPython\n",
        "  !python custom_nodes/ComfyUI-Manager/cm-cli.py restore-dependencies\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# @markdown **ËøêË°å ComfyUI**\n",
        "\n",
        "# @markdown ÈÄâÊã©‰∏ÄÁßçËøêË°å ComfyUI ÁöÑÊñπÂºè\n",
        "\n",
        "ËøêË°åÊñπÂºè = \"Cloudflare Tunnel\" #@param [\"Cloudflare Tunnel\", \"localtunnel\", \"Colab iframe\"]\n",
        "\n",
        "if ËøêË°åÊñπÂºè == \"Cloudflare Tunnel\":\n",
        "\n",
        "    print(\"‰ΩøÁî® Cloudflare Tunnel ËøêË°å ComfyUI\")\n",
        "    !wget -O cloudflared-linux-amd64.deb https://github.com/cloudflare/cloudflared/releases/latest/download/cloudflared-linux-amd64.deb\n",
        "    !dpkg -i cloudflared-linux-amd64.deb\n",
        "\n",
        "    import subprocess\n",
        "    import threading\n",
        "    import time\n",
        "    import socket\n",
        "    import urllib.request\n",
        "\n",
        "    def ÈößÈÅìÁ∫øÁ®ã(Á´ØÂè£):\n",
        "      while True:\n",
        "          time.sleep(0.5)\n",
        "          Â•óÊé•Â≠ó = socket.socket(socket.AF_INET, socket.SOCK_STREAM)\n",
        "          ÁªìÊûú = Â•óÊé•Â≠ó.connect_ex(('127.0.0.1', Á´ØÂè£))\n",
        "          if ÁªìÊûú == 0:\n",
        "            break\n",
        "          Â•óÊé•Â≠ó.close()\n",
        "      print(\"\\nComfyUI Âä†ËΩΩÂÆåÊàêÔºåÂ∞ùËØïÂêØÂä® cloudflared (Â¶ÇÊûúÂç°‰ΩèÔºåcloudflared ÂèØËÉΩÊúâÈóÆÈ¢ò)\\n\")\n",
        "\n",
        "      def ÂêØÂä®cloudflared():\n",
        "        global cloudflared_url  # ‰ΩøÁî®ÂÖ®Â±ÄÂèòÈáèÂ≠òÂÇ® cloudflared URL\n",
        "        cloudflared_url = None\n",
        "        ËøõÁ®ã = subprocess.Popen([\"cloudflared\", \"tunnel\", \"--url\", \"http://127.0.0.1:{}\".format(Á´ØÂè£)], stdout=subprocess.PIPE, stderr=subprocess.PIPE)\n",
        "        for Ë°å in ËøõÁ®ã.stderr:\n",
        "          ÊñáÊú¨ = Ë°å.decode()\n",
        "          if \"trycloudflare.com \" in ÊñáÊú¨:\n",
        "            cloudflared_url = ÊñáÊú¨[ÊñáÊú¨.find(\"http\"):].strip()  # ‰øùÂ≠ò URL Âπ∂ÂéªÈô§È¶ñÂ∞æÁ©∫Ê†º\n",
        "            print(\"ComfyUI ÁöÑËÆøÈóÆÈìæÊé•:\", cloudflared_url)\n",
        "            break\n",
        "        return ËøõÁ®ã\n",
        "\n",
        "      cloudflared_ËøõÁ®ã = ÂêØÂä®cloudflared()  # È¶ñÊ¨°ÂêØÂä® cloudflared\n",
        "      cloudflared_url = None # ÂàùÂßãÂåñ cloudflared_url\n",
        "\n",
        "      def Ê£ÄÊü•cloudflared_URL():\n",
        "        global cloudflared_url\n",
        "        time.sleep(10)  # Á≠âÂæÖ 10 ÁßíÔºåÁ°Æ‰øù cloudflared Âíå ComfyUI ÈÉΩÂêØÂä®ÂÆåÊàê\n",
        "        if cloudflared_url:\n",
        "          try:\n",
        "            # Â∞ùËØïËÆøÈóÆ cloudflared URL\n",
        "            ËØ∑Ê±Ç = urllib.request.Request(cloudflared_url, method=\"HEAD\")\n",
        "            ÂìçÂ∫î = urllib.request.urlopen(ËØ∑Ê±Ç, timeout=5) # ËÆæÁΩÆË∂ÖÊó∂Êó∂Èó¥‰∏∫ 5 Áßí\n",
        "            if ÂìçÂ∫î.status == 200:\n",
        "              print(\"Cloudflare Tunnel URL ÂèØËÆøÈóÆ\")\n",
        "            else:\n",
        "              print(\"Cloudflare Tunnel URL ËÆøÈóÆÂ§±Ë¥•ÔºåÁä∂ÊÄÅÁ†Å:\", ÂìçÂ∫î.status)\n",
        "              cloudflared_ËøõÁ®ã.terminate()  # ÁªàÊ≠¢ÊóßÁöÑ cloudflared ËøõÁ®ã\n",
        "              cloudflared_ËøõÁ®ã = ÂêØÂä®cloudflared()  # ÈáçÊñ∞ÂêØÂä® cloudflared\n",
        "              print(\"Â∑≤ÈáçÊñ∞ÂêØÂä® cloudflaredÔºåÁîüÊàêÊñ∞ÁöÑ URL\")\n",
        "\n",
        "          except urllib.error.URLError as e:\n",
        "            print(\"Cloudflare Tunnel URL ËÆøÈóÆÂ§±Ë¥•:\", e)\n",
        "            cloudflared_ËøõÁ®ã.terminate()  # ÁªàÊ≠¢ÊóßÁöÑ cloudflared ËøõÁ®ã\n",
        "            cloudflared_ËøõÁ®ã = ÂêØÂä®cloudflared()  # ÈáçÊñ∞ÂêØÂä® cloudflared\n",
        "            print(\"Â∑≤ÈáçÊñ∞ÂêØÂä® cloudflaredÔºåÁîüÊàêÊñ∞ÁöÑ URL\")\n",
        "          except Exception as e:\n",
        "            print(\"Ê£ÄÊü• Cloudflare Tunnel URL Êó∂ÂèëÁîüÈîôËØØ:\", e)\n",
        "            cloudflared_ËøõÁ®ã.terminate()  # ÁªàÊ≠¢ÊóßÁöÑ cloudflared ËøõÁ®ã\n",
        "            cloudflared_ËøõÁ®ã = ÂêØÂä®cloudflared()  # ÈáçÊñ∞ÂêØÂä® cloudflared\n",
        "            print(\"Â∑≤ÈáçÊñ∞ÂêØÂä® cloudflaredÔºåÁîüÊàêÊñ∞ÁöÑ URL\")\n",
        "        else:\n",
        "          print(\"Cloudflare Tunnel URL Â∞öÊú™ÁîüÊàêÔºåÁ≠âÂæÖ...\")\n",
        "          cloudflared_ËøõÁ®ã.terminate()  # ÁªàÊ≠¢ÊóßÁöÑ cloudflared ËøõÁ®ã\n",
        "          cloudflared_ËøõÁ®ã = ÂêØÂä®cloudflared()  # ÈáçÊñ∞ÂêØÂä® cloudflared\n",
        "          print(\"Â∑≤ÈáçÊñ∞ÂêØÂä® cloudflaredÔºåÁîüÊàêÊñ∞ÁöÑ URL\")\n",
        "\n",
        "      # Â∞ÜÁ∫øÁ®ãÂêØÂä®ÁßªÂä®Âà∞ ComfyUI ÂêØÂä®‰πãÂêé\n",
        "\n",
        "    threading.Thread(target=ÈößÈÅìÁ∫øÁ®ã, daemon=True, args=(8188,)).start()\n",
        "\n",
        "    !python main.py --dont-print-server\n",
        "\n",
        "    # Âú® ComfyUI ÂêØÂä®Âêé 10 ÁßíÂêØÂä® URL Ê£ÄÊü•Á∫øÁ®ã\n",
        "    threading.Thread(target=Ê£ÄÊü•cloudflared_URL, daemon=True).start()\n",
        "\n",
        "elif ËøêË°åÊñπÂºè == \"localtunnel\":\n",
        "    print(\"‰ΩøÁî® localtunnel ËøêË°å ComfyUI\")\n",
        "    !npm install -g localtunnel\n",
        "\n",
        "    import threading\n",
        "    import time\n",
        "    import socket\n",
        "    import urllib\n",
        "    import subprocess\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "    def ÈößÈÅìÁ∫øÁ®ã(Á´ØÂè£):\n",
        "      while True:\n",
        "          time.sleep(0.5)\n",
        "          Â•óÊé•Â≠ó = socket.socket(socket.AF_INET, socket.SOCK_STREAM)\n",
        "          ÁªìÊûú = Â•óÊé•Â≠ó.connect_ex(('127.0.0.1', Á´ØÂè£))\n",
        "          if ÁªìÊûú == 0:\n",
        "            break\n",
        "          Â•óÊé•Â≠ó.close()\n",
        "      print(\"\\nComfyUI Âä†ËΩΩÂÆåÊàêÔºåÂ∞ùËØïÂêØÂä® localtunnel (Â¶ÇÊûúÂç°‰ΩèÔºålocaltunnel ÂèØËÉΩÊúâÈóÆÈ¢ò)\\n\")\n",
        "\n",
        "      print(\"localtunnel ÁöÑÂØÜÁ†Å/ÁªàÁ´Ø IP:\", urllib.request.urlopen('https://ipv4.icanhazip.com').read().decode('utf8').strip(\"\\n\"))\n",
        "      ËøõÁ®ã = subprocess.Popen([\"lt\", \"--port\", \"{}\".format(Á´ØÂè£)], stdout=subprocess.PIPE)\n",
        "      for Ë°å in ËøõÁ®ã.stdout:\n",
        "        print(Ë°å.decode(), end='')\n",
        "\n",
        "    threading.Thread(target=ÈößÈÅìÁ∫øÁ®ã, daemon=True, args=(8188,)).start()\n",
        "\n",
        "    !python main.py --dont-print-server\n",
        "\n",
        "elif ËøêË°åÊñπÂºè == \"Colab iframe\":\n",
        "    print(\"‰ΩøÁî® Colab iframe ËøêË°å ComfyUI (‰∏çÊé®ËçêÔºåÂèØËÉΩÊó†Ê≥ïÊ≠£Â∏∏Â∑•‰Ωú)\")\n",
        "    import threading\n",
        "    def iframeÁ∫øÁ®ã(Á´ØÂè£):\n",
        "      while True:\n",
        "          time.sleep(0.5)\n",
        "          Â•óÊé•Â≠ó = socket.socket(socket.AF_INET, socket.SOCK_STREAM)\n",
        "          ÁªìÊûú = Â•óÊé•Â≠ó.connect_ex(('127.0.0.1', Á´ØÂè£))\n",
        "          if ÁªìÊûú == 0:\n",
        "            break\n",
        "          Â•óÊé•Â≠ó.close()\n",
        "      from google.colab import output\n",
        "      output.serve_kernel_port_as_iframe(Á´ØÂè£, height=1024)\n",
        "      print(\"Âú®Êñ∞Á™óÂè£‰∏≠ÊâìÂºÄÈìæÊé•:\")\n",
        "      output.serve_kernel_port_as_window(Á´ØÂè£)\n",
        "\n",
        "    threading.Thread(target=iframeÁ∫øÁ®ã, daemon=True, args=(8188,)).start()\n",
        "\n",
        "    !python main.py --dont-print-server\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "import os\n",
        "!pip install torch==2.6.0+cu118 torchvision --index-url https://download.pytorch.org/whl/cu118 --target /content/drive/MyDrive/pip-mod\n",
        "!pip install transformers>=4.28.1 kornia>=0.7.1 spandrel -i https://pypi.tuna.tsinghua.edu.cn/simple --target /content/drive/MyDrive/pip-mod\n"
      ],
      "metadata": {
        "id": "LZW4z0u8jgxw",
        "outputId": "0a66231a-c5a3-41a3-a1c0-65428c1fba2b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "Looking in indexes: https://download.pytorch.org/whl/cu118\n",
            "Collecting torch==2.6.0+cu118\n",
            "  Using cached https://download.pytorch.org/whl/cu118/torch-2.6.0%2Bcu118-cp311-cp311-linux_x86_64.whl.metadata (27 kB)\n",
            "Collecting torchvision\n",
            "  Using cached https://download.pytorch.org/whl/cu118/torchvision-0.21.0%2Bcu118-cp311-cp311-linux_x86_64.whl.metadata (6.1 kB)\n",
            "Collecting filelock (from torch==2.6.0+cu118)\n",
            "  Using cached https://download.pytorch.org/whl/filelock-3.13.1-py3-none-any.whl.metadata (2.8 kB)\n",
            "Collecting typing-extensions>=4.10.0 (from torch==2.6.0+cu118)\n",
            "  Using cached https://download.pytorch.org/whl/typing_extensions-4.12.2-py3-none-any.whl.metadata (3.0 kB)\n",
            "Collecting networkx (from torch==2.6.0+cu118)\n",
            "  Using cached https://download.pytorch.org/whl/networkx-3.3-py3-none-any.whl.metadata (5.1 kB)\n",
            "Collecting jinja2 (from torch==2.6.0+cu118)\n",
            "  Using cached https://download.pytorch.org/whl/Jinja2-3.1.4-py3-none-any.whl.metadata (2.6 kB)\n",
            "Collecting fsspec (from torch==2.6.0+cu118)\n",
            "  Using cached https://download.pytorch.org/whl/fsspec-2024.6.1-py3-none-any.whl.metadata (11 kB)\n",
            "Collecting nvidia-cuda-nvrtc-cu11==11.8.89 (from torch==2.6.0+cu118)\n",
            "  Using cached https://download.pytorch.org/whl/cu118/nvidia_cuda_nvrtc_cu11-11.8.89-py3-none-manylinux1_x86_64.whl (23.2 MB)\n",
            "Collecting nvidia-cuda-runtime-cu11==11.8.89 (from torch==2.6.0+cu118)\n",
            "  Using cached https://download.pytorch.org/whl/cu118/nvidia_cuda_runtime_cu11-11.8.89-py3-none-manylinux1_x86_64.whl (875 kB)\n",
            "Collecting nvidia-cuda-cupti-cu11==11.8.87 (from torch==2.6.0+cu118)\n",
            "  Using cached https://download.pytorch.org/whl/cu118/nvidia_cuda_cupti_cu11-11.8.87-py3-none-manylinux1_x86_64.whl (13.1 MB)\n",
            "Collecting nvidia-cudnn-cu11==9.1.0.70 (from torch==2.6.0+cu118)\n",
            "  Using cached https://download.pytorch.org/whl/cu118/nvidia_cudnn_cu11-9.1.0.70-py3-none-manylinux2014_x86_64.whl (663.9 MB)\n",
            "Collecting nvidia-cublas-cu11==11.11.3.6 (from torch==2.6.0+cu118)\n",
            "  Using cached https://download.pytorch.org/whl/cu118/nvidia_cublas_cu11-11.11.3.6-py3-none-manylinux1_x86_64.whl (417.9 MB)\n",
            "Collecting nvidia-cufft-cu11==10.9.0.58 (from torch==2.6.0+cu118)\n",
            "  Using cached https://download.pytorch.org/whl/cu118/nvidia_cufft_cu11-10.9.0.58-py3-none-manylinux1_x86_64.whl (168.4 MB)\n",
            "Collecting nvidia-curand-cu11==10.3.0.86 (from torch==2.6.0+cu118)\n",
            "  Using cached https://download.pytorch.org/whl/cu118/nvidia_curand_cu11-10.3.0.86-py3-none-manylinux1_x86_64.whl (58.1 MB)\n",
            "Collecting nvidia-cusolver-cu11==11.4.1.48 (from torch==2.6.0+cu118)\n",
            "  Using cached https://download.pytorch.org/whl/cu118/nvidia_cusolver_cu11-11.4.1.48-py3-none-manylinux1_x86_64.whl (128.2 MB)\n",
            "Collecting nvidia-cusparse-cu11==11.7.5.86 (from torch==2.6.0+cu118)\n",
            "  Using cached https://download.pytorch.org/whl/cu118/nvidia_cusparse_cu11-11.7.5.86-py3-none-manylinux1_x86_64.whl (204.1 MB)\n",
            "Collecting nvidia-nccl-cu11==2.21.5 (from torch==2.6.0+cu118)\n",
            "  Using cached https://download.pytorch.org/whl/cu118/nvidia_nccl_cu11-2.21.5-py3-none-manylinux2014_x86_64.whl (147.8 MB)\n",
            "Collecting nvidia-nvtx-cu11==11.8.86 (from torch==2.6.0+cu118)\n",
            "  Using cached https://download.pytorch.org/whl/cu118/nvidia_nvtx_cu11-11.8.86-py3-none-manylinux1_x86_64.whl (99 kB)\n",
            "Collecting triton==3.2.0 (from torch==2.6.0+cu118)\n",
            "  Using cached https://download.pytorch.org/whl/triton-3.2.0-cp311-cp311-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (1.4 kB)\n",
            "Collecting sympy==1.13.1 (from torch==2.6.0+cu118)\n",
            "  Using cached https://download.pytorch.org/whl/sympy-1.13.1-py3-none-any.whl (6.2 MB)\n",
            "Collecting mpmath<1.4,>=1.1.0 (from sympy==1.13.1->torch==2.6.0+cu118)\n",
            "  Using cached https://download.pytorch.org/whl/mpmath-1.3.0-py3-none-any.whl (536 kB)\n",
            "Collecting numpy (from torchvision)\n",
            "  Using cached https://download.pytorch.org/whl/numpy-2.1.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (60 kB)\n",
            "Collecting pillow!=8.3.*,>=5.3.0 (from torchvision)\n",
            "  Using cached https://download.pytorch.org/whl/pillow-11.0.0-cp311-cp311-manylinux_2_28_x86_64.whl.metadata (9.1 kB)\n",
            "Collecting MarkupSafe>=2.0 (from jinja2->torch==2.6.0+cu118)\n",
            "  Using cached https://download.pytorch.org/whl/MarkupSafe-2.1.5-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (28 kB)\n",
            "Using cached https://download.pytorch.org/whl/cu118/torch-2.6.0%2Bcu118-cp311-cp311-linux_x86_64.whl (848.7 MB)\n",
            "Using cached https://download.pytorch.org/whl/triton-3.2.0-cp311-cp311-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (166.7 MB)\n",
            "Using cached https://download.pytorch.org/whl/cu118/torchvision-0.21.0%2Bcu118-cp311-cp311-linux_x86_64.whl (6.5 MB)\n",
            "Using cached https://download.pytorch.org/whl/pillow-11.0.0-cp311-cp311-manylinux_2_28_x86_64.whl (4.4 MB)\n",
            "Using cached https://download.pytorch.org/whl/typing_extensions-4.12.2-py3-none-any.whl (37 kB)\n",
            "Using cached https://download.pytorch.org/whl/filelock-3.13.1-py3-none-any.whl (11 kB)\n",
            "Using cached https://download.pytorch.org/whl/fsspec-2024.6.1-py3-none-any.whl (177 kB)\n",
            "Using cached https://download.pytorch.org/whl/Jinja2-3.1.4-py3-none-any.whl (133 kB)\n",
            "Using cached https://download.pytorch.org/whl/networkx-3.3-py3-none-any.whl (1.7 MB)\n",
            "Using cached https://download.pytorch.org/whl/numpy-2.1.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (16.3 MB)\n",
            "Installing collected packages: triton, mpmath, typing-extensions, sympy, pillow, nvidia-nvtx-cu11, nvidia-nccl-cu11, nvidia-cusparse-cu11, nvidia-curand-cu11, nvidia-cufft-cu11, nvidia-cuda-runtime-cu11, nvidia-cuda-nvrtc-cu11, nvidia-cuda-cupti-cu11, nvidia-cublas-cu11, numpy, networkx, MarkupSafe, fsspec, filelock, nvidia-cusolver-cu11, nvidia-cudnn-cu11, jinja2, torch, torchvision\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "pytensor 2.26.4 requires filelock>=3.15, but you have filelock 3.13.1 which is incompatible.\n",
            "pytensor 2.26.4 requires numpy<2,>=1.17.0, but you have numpy 2.1.2 which is incompatible.\n",
            "langchain 0.3.17 requires numpy<2,>=1.22.4; python_version < \"3.12\", but you have numpy 2.1.2 which is incompatible.\n",
            "gcsfs 2024.10.0 requires fsspec==2024.10.0, but you have fsspec 2024.6.1 which is incompatible.\n",
            "gensim 4.3.3 requires numpy<2.0,>=1.18.5, but you have numpy 2.1.2 which is incompatible.\n",
            "tensorflow 2.18.0 requires numpy<2.1.0,>=1.26.0, but you have numpy 2.1.2 which is incompatible.\n",
            "torchaudio 2.5.1+cu124 requires torch==2.5.1, but you have torch 2.6.0+cu118 which is incompatible.\n",
            "thinc 8.2.5 requires numpy<2.0.0,>=1.19.0; python_version >= \"3.9\", but you have numpy 2.1.2 which is incompatible.\n",
            "fastai 2.7.18 requires torch<2.6,>=1.10, but you have torch 2.6.0+cu118 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed MarkupSafe-2.1.5 filelock-3.13.1 fsspec-2024.6.1 jinja2-3.1.4 mpmath-1.3.0 networkx-3.3 numpy-2.1.2 nvidia-cublas-cu11-11.11.3.6 nvidia-cuda-cupti-cu11-11.8.87 nvidia-cuda-nvrtc-cu11-11.8.89 nvidia-cuda-runtime-cu11-11.8.89 nvidia-cudnn-cu11-9.1.0.70 nvidia-cufft-cu11-10.9.0.58 nvidia-curand-cu11-10.3.0.86 nvidia-cusolver-cu11-11.4.1.48 nvidia-cusparse-cu11-11.7.5.86 nvidia-nccl-cu11-2.21.5 nvidia-nvtx-cu11-11.8.86 pillow-11.0.0 sympy-1.13.1 torch-2.6.0+cu118 torchvision-0.21.0+cu118 triton-3.2.0 typing-extensions-4.12.2\n",
            "\u001b[33mWARNING: Target directory /content/drive/MyDrive/pip-mod/jinja2 already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n",
            "\u001b[0m\u001b[33mWARNING: Target directory /content/drive/MyDrive/pip-mod/filelock already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n",
            "\u001b[0m\u001b[33mWARNING: Target directory /content/drive/MyDrive/pip-mod/isympy.py already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n",
            "\u001b[0m\u001b[33mWARNING: Target directory /content/drive/MyDrive/pip-mod/nvidia_cusolver_cu11-11.4.1.48.dist-info already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n",
            "\u001b[0m\u001b[33mWARNING: Target directory /content/drive/MyDrive/pip-mod/nvidia_curand_cu11-10.3.0.86.dist-info already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n",
            "\u001b[0m\u001b[33mWARNING: Target directory /content/drive/MyDrive/pip-mod/pillow.libs already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n",
            "\u001b[0m\u001b[33mWARNING: Target directory /content/drive/MyDrive/pip-mod/triton already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n",
            "\u001b[0m\u001b[33mWARNING: Target directory /content/drive/MyDrive/pip-mod/PIL already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n",
            "\u001b[0m\u001b[33mWARNING: Target directory /content/drive/MyDrive/pip-mod/nvidia_cuda_cupti_cu11-11.8.87.dist-info already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n",
            "\u001b[0m\u001b[33mWARNING: Target directory /content/drive/MyDrive/pip-mod/mpmath already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n",
            "\u001b[0m\u001b[33mWARNING: Target directory /content/drive/MyDrive/pip-mod/nvidia_cudnn_cu11-9.1.0.70.dist-info already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n",
            "\u001b[0m\u001b[33mWARNING: Target directory /content/drive/MyDrive/pip-mod/torchvision-0.21.0+cu118.dist-info already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n",
            "\u001b[0m\u001b[33mWARNING: Target directory /content/drive/MyDrive/pip-mod/torchvision already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n",
            "\u001b[0m\u001b[33mWARNING: Target directory /content/drive/MyDrive/pip-mod/nvidia_cusparse_cu11-11.7.5.86.dist-info already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n",
            "\u001b[0m\u001b[33mWARNING: Target directory /content/drive/MyDrive/pip-mod/triton-3.2.0.dist-info already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n",
            "\u001b[0m\u001b[33mWARNING: Target directory /content/drive/MyDrive/pip-mod/torchgen already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n",
            "\u001b[0m\u001b[33mWARNING: Target directory /content/drive/MyDrive/pip-mod/fsspec already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n",
            "\u001b[0m\u001b[33mWARNING: Target directory /content/drive/MyDrive/pip-mod/jinja2-3.1.4.dist-info already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n",
            "\u001b[0m\u001b[33mWARNING: Target directory /content/drive/MyDrive/pip-mod/sympy-1.13.1.dist-info already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n",
            "\u001b[0m\u001b[33mWARNING: Target directory /content/drive/MyDrive/pip-mod/nvidia_cufft_cu11-10.9.0.58.dist-info already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n",
            "\u001b[0m\u001b[33mWARNING: Target directory /content/drive/MyDrive/pip-mod/markupsafe already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n",
            "\u001b[0m\u001b[33mWARNING: Target directory /content/drive/MyDrive/pip-mod/networkx-3.3.dist-info already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n",
            "\u001b[0m\u001b[33mWARNING: Target directory /content/drive/MyDrive/pip-mod/sympy already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n",
            "\u001b[0m\u001b[33mWARNING: Target directory /content/drive/MyDrive/pip-mod/fsspec-2024.6.1.dist-info already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n",
            "\u001b[0m\u001b[33mWARNING: Target directory /content/drive/MyDrive/pip-mod/MarkupSafe-2.1.5.dist-info already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n",
            "\u001b[0m\u001b[33mWARNING: Target directory /content/drive/MyDrive/pip-mod/nvidia_cuda_runtime_cu11-11.8.89.dist-info already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n",
            "\u001b[0m\u001b[33mWARNING: Target directory /content/drive/MyDrive/pip-mod/torchvision.libs already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n",
            "\u001b[0m\u001b[33mWARNING: Target directory /content/drive/MyDrive/pip-mod/typing_extensions.py already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n",
            "\u001b[0m\u001b[33mWARNING: Target directory /content/drive/MyDrive/pip-mod/typing_extensions-4.12.2.dist-info already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n",
            "\u001b[0m\u001b[33mWARNING: Target directory /content/drive/MyDrive/pip-mod/numpy-2.1.2.dist-info already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n",
            "\u001b[0m\u001b[33mWARNING: Target directory /content/drive/MyDrive/pip-mod/nvidia_nvtx_cu11-11.8.86.dist-info already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n",
            "\u001b[0m\u001b[33mWARNING: Target directory /content/drive/MyDrive/pip-mod/functorch already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n",
            "\u001b[0m\u001b[33mWARNING: Target directory /content/drive/MyDrive/pip-mod/nvidia already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n",
            "\u001b[0m\u001b[33mWARNING: Target directory /content/drive/MyDrive/pip-mod/numpy.libs already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n",
            "\u001b[0m\u001b[33mWARNING: Target directory /content/drive/MyDrive/pip-mod/nvidia_nccl_cu11-2.21.5.dist-info already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n",
            "\u001b[0m\u001b[33mWARNING: Target directory /content/drive/MyDrive/pip-mod/numpy already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n",
            "\u001b[0m\u001b[33mWARNING: Target directory /content/drive/MyDrive/pip-mod/__pycache__ already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n",
            "\u001b[0m\u001b[33mWARNING: Target directory /content/drive/MyDrive/pip-mod/filelock-3.13.1.dist-info already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n",
            "\u001b[0m\u001b[33mWARNING: Target directory /content/drive/MyDrive/pip-mod/mpmath-1.3.0.dist-info already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n",
            "\u001b[0m\u001b[33mWARNING: Target directory /content/drive/MyDrive/pip-mod/networkx already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n",
            "\u001b[0m\u001b[33mWARNING: Target directory /content/drive/MyDrive/pip-mod/pillow-11.0.0.dist-info already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n",
            "\u001b[0m\u001b[33mWARNING: Target directory /content/drive/MyDrive/pip-mod/torch-2.6.0+cu118.dist-info already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n",
            "\u001b[0m\u001b[33mWARNING: Target directory /content/drive/MyDrive/pip-mod/nvidia_cublas_cu11-11.11.3.6.dist-info already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n",
            "\u001b[0m\u001b[33mWARNING: Target directory /content/drive/MyDrive/pip-mod/nvidia_cuda_nvrtc_cu11-11.8.89.dist-info already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n",
            "\u001b[0m\u001b[33mWARNING: Target directory /content/drive/MyDrive/pip-mod/torch already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n",
            "\u001b[0m\u001b[33mWARNING: Target directory /content/drive/MyDrive/pip-mod/bin already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n",
            "\u001b[0m\u001b[33mWARNING: Target directory /content/drive/MyDrive/pip-mod/share already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n",
            "\u001b[0m\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "pytensor 2.26.4 requires numpy<2,>=1.17.0, but you have numpy 2.2.2 which is incompatible.\n",
            "langchain 0.3.17 requires numpy<2,>=1.22.4; python_version < \"3.12\", but you have numpy 2.2.2 which is incompatible.\n",
            "gcsfs 2024.10.0 requires fsspec==2024.10.0, but you have fsspec 2025.2.0 which is incompatible.\n",
            "gensim 4.3.3 requires numpy<2.0,>=1.18.5, but you have numpy 2.2.2 which is incompatible.\n",
            "numba 0.61.0 requires numpy<2.2,>=1.24, but you have numpy 2.2.2 which is incompatible.\n",
            "tensorflow 2.18.0 requires numpy<2.1.0,>=1.26.0, but you have numpy 2.2.2 which is incompatible.\n",
            "torchaudio 2.5.1+cu124 requires torch==2.5.1, but you have torch 2.6.0 which is incompatible.\n",
            "thinc 8.2.5 requires numpy<2.0.0,>=1.19.0; python_version >= \"3.9\", but you have numpy 2.2.2 which is incompatible.\n",
            "fastai 2.7.18 requires torch<2.6,>=1.10, but you have torch 2.6.0 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0m\u001b[33mWARNING: Target directory /content/drive/MyDrive/pip-mod/jinja2 already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n",
            "\u001b[0m\u001b[33mWARNING: Target directory /content/drive/MyDrive/pip-mod/filelock already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n",
            "\u001b[0m\u001b[33mWARNING: Target directory /content/drive/MyDrive/pip-mod/isympy.py already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n",
            "\u001b[0m\u001b[33mWARNING: Target directory /content/drive/MyDrive/pip-mod/pillow.libs already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n",
            "\u001b[0m\u001b[33mWARNING: Target directory /content/drive/MyDrive/pip-mod/triton already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n",
            "\u001b[0m\u001b[33mWARNING: Target directory /content/drive/MyDrive/pip-mod/PIL already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n",
            "\u001b[0m\u001b[33mWARNING: Target directory /content/drive/MyDrive/pip-mod/mpmath already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n",
            "\u001b[0m\u001b[33mWARNING: Target directory /content/drive/MyDrive/pip-mod/torchvision already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n",
            "\u001b[0m\u001b[33mWARNING: Target directory /content/drive/MyDrive/pip-mod/triton-3.2.0.dist-info already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n",
            "\u001b[0m\u001b[33mWARNING: Target directory /content/drive/MyDrive/pip-mod/torchgen already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n",
            "\u001b[0m\u001b[33mWARNING: Target directory /content/drive/MyDrive/pip-mod/fsspec already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n",
            "\u001b[0m\u001b[33mWARNING: Target directory /content/drive/MyDrive/pip-mod/sympy-1.13.1.dist-info already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n",
            "\u001b[0m\u001b[33mWARNING: Target directory /content/drive/MyDrive/pip-mod/markupsafe already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n",
            "\u001b[0m\u001b[33mWARNING: Target directory /content/drive/MyDrive/pip-mod/sympy already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n",
            "\u001b[0m\u001b[33mWARNING: Target directory /content/drive/MyDrive/pip-mod/torchvision.libs already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n",
            "\u001b[0m\u001b[33mWARNING: Target directory /content/drive/MyDrive/pip-mod/typing_extensions.py already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n",
            "\u001b[0m\u001b[33mWARNING: Target directory /content/drive/MyDrive/pip-mod/typing_extensions-4.12.2.dist-info already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n",
            "\u001b[0m\u001b[33mWARNING: Target directory /content/drive/MyDrive/pip-mod/functorch already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n",
            "\u001b[0m\u001b[33mWARNING: Target directory /content/drive/MyDrive/pip-mod/nvidia already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n",
            "\u001b[0m\u001b[33mWARNING: Target directory /content/drive/MyDrive/pip-mod/numpy.libs already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n",
            "\u001b[0m\u001b[33mWARNING: Target directory /content/drive/MyDrive/pip-mod/numpy already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n",
            "\u001b[0m\u001b[33mWARNING: Target directory /content/drive/MyDrive/pip-mod/__pycache__ already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n",
            "\u001b[0m\u001b[33mWARNING: Target directory /content/drive/MyDrive/pip-mod/mpmath-1.3.0.dist-info already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n",
            "\u001b[0m\u001b[33mWARNING: Target directory /content/drive/MyDrive/pip-mod/networkx already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n",
            "\u001b[0m\u001b[33mWARNING: Target directory /content/drive/MyDrive/pip-mod/torch already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n",
            "\u001b[0m\u001b[33mWARNING: Target directory /content/drive/MyDrive/pip-mod/bin already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n",
            "\u001b[0m\u001b[33mWARNING: Target directory /content/drive/MyDrive/pip-mod/share already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n",
            "\u001b[0m"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import sys\n",
        "\n",
        "ÁõÆÊ†áÁõÆÂΩï = \"/content/drive/MyDrive/pip-mod\"\n",
        "\n",
        "# Ê∏ÖÁ©∫ sys.path\n",
        "sys.path = []\n",
        "\n",
        "# Ê∑ªÂä†ÁõÆÊ†áÁõÆÂΩïÂà∞ sys.path\n",
        "sys.path.append(ÁõÆÊ†áÁõÆÂΩï)\n",
        "\n",
        "print(sys.path)\n",
        "!pip check"
      ],
      "metadata": {
        "id": "HUPqZurFv0sA",
        "outputId": "7e958ac0-aa62-4d14-baee-594d118e40f9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['/content/drive/MyDrive/pip-mod']\n",
            "ipython 7.34.0 requires jedi, which is not installed.\n",
            "pygobject 3.42.1 requires pycairo, which is not installed.\n",
            "torch 2.5.1+cu124 has requirement nvidia-cublas-cu12==12.4.5.8; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cublas-cu12 12.5.3.2.\n",
            "torch 2.5.1+cu124 has requirement nvidia-cuda-cupti-cu12==12.4.127; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cuda-cupti-cu12 12.5.82.\n",
            "torch 2.5.1+cu124 has requirement nvidia-cuda-nvrtc-cu12==12.4.127; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cuda-nvrtc-cu12 12.5.82.\n",
            "torch 2.5.1+cu124 has requirement nvidia-cuda-runtime-cu12==12.4.127; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cuda-runtime-cu12 12.5.82.\n",
            "torch 2.5.1+cu124 has requirement nvidia-cudnn-cu12==9.1.0.70; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cudnn-cu12 9.3.0.75.\n",
            "torch 2.5.1+cu124 has requirement nvidia-cufft-cu12==11.2.1.3; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cufft-cu12 11.2.3.61.\n",
            "torch 2.5.1+cu124 has requirement nvidia-curand-cu12==10.3.5.147; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-curand-cu12 10.3.6.82.\n",
            "torch 2.5.1+cu124 has requirement nvidia-cusolver-cu12==11.6.1.9; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cusolver-cu12 11.6.3.83.\n",
            "torch 2.5.1+cu124 has requirement nvidia-cusparse-cu12==12.3.1.170; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cusparse-cu12 12.5.1.3.\n",
            "torch 2.5.1+cu124 has requirement nvidia-nvjitlink-cu12==12.4.127; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-nvjitlink-cu12 12.5.82.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "output_dir = \"/content/drive/MyDrive/ComfyUI/output\"\n",
        "zip_file = \"/content/ComfyUI_output.zip\"  # ÊåáÂÆö ZIP Êñá‰ª∂ÁöÑ‰øùÂ≠òË∑ØÂæÑÂíåÂêçÁß∞\n",
        "\n",
        "# Á°Æ‰øùËæìÂá∫ÁõÆÂΩïÂ≠òÂú®\n",
        "if not os.path.exists(output_dir):\n",
        "    print(f\"ÈîôËØØÔºöÁõÆÂΩï {output_dir} ‰∏çÂ≠òÂú®\")\n",
        "else:\n",
        "    # ‰ΩøÁî® zip ÂëΩ‰ª§ÂéãÁº©Êñá‰ª∂\n",
        "    !zip -r \"{zip_file}\" \"{output_dir}\"/*\n",
        "\n",
        "    print(f\"ÁõÆÂΩï {output_dir} Â∑≤ÂéãÁº©Âà∞ {zip_file}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lcYZCiI6S4fS",
        "outputId": "a3fbebe6-2b59-42df-b805-fd9477a32e1c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  adding: content/drive/MyDrive/ComfyUI/output/0001aiÂõæ2025-02-08 15-00-21.png (deflated 0%)\n",
            "  adding: content/drive/MyDrive/ComfyUI/output/0002aiÂõæ2025-02-08 15-00-21.png (deflated 0%)\n",
            "  adding: content/drive/MyDrive/ComfyUI/output/0003aiÂõæ2025-02-08 15-00-21.png (deflated 0%)\n",
            "  adding: content/drive/MyDrive/ComfyUI/output/0004aiÂõæ2025-02-08 15-00-21.png (deflated 0%)\n",
            "  adding: content/drive/MyDrive/ComfyUI/output/0005aiÂõæ2025-02-08 15-03-09.png (deflated 0%)\n",
            "  adding: content/drive/MyDrive/ComfyUI/output/0006aiÂõæ2025-02-08 15-03-09.png (deflated 0%)\n",
            "  adding: content/drive/MyDrive/ComfyUI/output/0007aiÂõæ2025-02-08 15-03-09.png (deflated 0%)\n",
            "  adding: content/drive/MyDrive/ComfyUI/output/0008aiÂõæ2025-02-08 15-03-09.png (deflated 0%)\n",
            "  adding: content/drive/MyDrive/ComfyUI/output/0009aiÂõæ2025-02-08 15-09-22.png (deflated 0%)\n",
            "  adding: content/drive/MyDrive/ComfyUI/output/2025-02-08/ (stored 0%)\n",
            "  adding: content/drive/MyDrive/ComfyUI/output/2025-02-08/ComfyUI/ (stored 0%)\n",
            "  adding: content/drive/MyDrive/ComfyUI/output/2025-02-08/0001ComfyUI2025-02-08 14-58-02.png (deflated 0%)\n",
            "  adding: content/drive/MyDrive/ComfyUI/output/2025-02-08/0002ComfyUI2025-02-08 14-58-02.png (deflated 0%)\n",
            "  adding: content/drive/MyDrive/ComfyUI/output/2025-02-08/0003ComfyUI2025-02-08 14-58-02.png (deflated 0%)\n",
            "  adding: content/drive/MyDrive/ComfyUI/output/2025-02-08/0004ComfyUI2025-02-08 14-58-02.png (deflated 0%)\n",
            "  adding: content/drive/MyDrive/ComfyUI/output/2025-02-08 15-19-25/ (stored 0%)\n",
            "  adding: content/drive/MyDrive/ComfyUI/output/2025-02-08 15-19-25/0001-2025-02-08 15-19-25.png (deflated 0%)\n",
            "  adding: content/drive/MyDrive/ComfyUI/output/2025-02-08 15-21-54/ (stored 0%)\n",
            "  adding: content/drive/MyDrive/ComfyUI/output/2025-02-08 15-21-54/0001-2025-02-08 15-21-54.png (deflated 0%)\n",
            "  adding: content/drive/MyDrive/ComfyUI/output/2025-02-08 15-28-10/ (stored 0%)\n",
            "  adding: content/drive/MyDrive/ComfyUI/output/2025-02-08 15-28-10/0001-2025-02-08 15-28-10.png (deflated 0%)\n",
            "  adding: content/drive/MyDrive/ComfyUI/output/2025-02-08 15-28-10/0002-2025-02-08 15-28-10.png (deflated 0%)\n",
            "  adding: content/drive/MyDrive/ComfyUI/output/2025-02-08 15-28-10/0003-2025-02-08 15-28-10.png (deflated 0%)\n",
            "  adding: content/drive/MyDrive/ComfyUI/output/2025-02-08 15-28-10/0004-2025-02-08 15-28-10.png (deflated 0%)\n",
            "  adding: content/drive/MyDrive/ComfyUI/output/2025-02-08 15-31-05/ (stored 0%)\n",
            "  adding: content/drive/MyDrive/ComfyUI/output/2025-02-08 15-31-05/0001-2025-02-08 15-31-05.png (deflated 0%)\n",
            "  adding: content/drive/MyDrive/ComfyUI/output/2025-02-08 15-31-05/0002-2025-02-08 15-31-05.png (deflated 0%)\n",
            "  adding: content/drive/MyDrive/ComfyUI/output/2025-02-08 15-31-05/0003-2025-02-08 15-31-05.png (deflated 0%)\n",
            "  adding: content/drive/MyDrive/ComfyUI/output/2025-02-08 15-31-05/0004-2025-02-08 15-31-05.png (deflated 0%)\n",
            "  adding: content/drive/MyDrive/ComfyUI/output/2025-02-08 15-33-56/ (stored 0%)\n",
            "  adding: content/drive/MyDrive/ComfyUI/output/2025-02-08 15-33-56/0001-2025-02-08 15-33-56.png (deflated 0%)\n",
            "  adding: content/drive/MyDrive/ComfyUI/output/2025-02-08 15-33-56/0002-2025-02-08 15-33-56.png (deflated 0%)\n",
            "  adding: content/drive/MyDrive/ComfyUI/output/2025-02-08 15-33-56/0003-2025-02-08 15-33-56.png (deflated 0%)\n",
            "  adding: content/drive/MyDrive/ComfyUI/output/2025-02-08 15-33-56/0004-2025-02-08 15-33-56.png (deflated 0%)\n",
            "  adding: content/drive/MyDrive/ComfyUI/output/2025-02-08 15-36-46/ (stored 0%)\n",
            "  adding: content/drive/MyDrive/ComfyUI/output/2025-02-08 15-36-46/0001-2025-02-08 15-36-46.png (deflated 0%)\n",
            "  adding: content/drive/MyDrive/ComfyUI/output/2025-02-08 15-36-46/0002-2025-02-08 15-36-46.png (deflated 0%)\n",
            "  adding: content/drive/MyDrive/ComfyUI/output/2025-02-08 15-36-46/0003-2025-02-08 15-36-46.png (deflated 0%)\n",
            "  adding: content/drive/MyDrive/ComfyUI/output/2025-02-08 15-36-46/0004-2025-02-08 15-36-46.png (deflated 0%)\n",
            "  adding: content/drive/MyDrive/ComfyUI/output/2025-02-08 15-39-38/ (stored 0%)\n",
            "  adding: content/drive/MyDrive/ComfyUI/output/2025-02-08 15-39-38/0001-2025-02-08 15-39-38.png (deflated 0%)\n",
            "  adding: content/drive/MyDrive/ComfyUI/output/2025-02-08 15-39-38/0002-2025-02-08 15-39-38.png (deflated 0%)\n",
            "  adding: content/drive/MyDrive/ComfyUI/output/2025-02-08 15-39-38/0003-2025-02-08 15-39-38.png (deflated 0%)\n",
            "  adding: content/drive/MyDrive/ComfyUI/output/2025-02-08 15-39-38/0004-2025-02-08 15-39-38.png (deflated 0%)\n",
            "  adding: content/drive/MyDrive/ComfyUI/output/2025-02-08 15-42-31/ (stored 0%)\n",
            "  adding: content/drive/MyDrive/ComfyUI/output/2025-02-08 15-42-31/0001-2025-02-08 15-42-31.png (deflated 0%)\n",
            "  adding: content/drive/MyDrive/ComfyUI/output/2025-02-08 15-42-31/0002-2025-02-08 15-42-31.png (deflated 0%)\n",
            "  adding: content/drive/MyDrive/ComfyUI/output/2025-02-08 15-42-31/0003-2025-02-08 15-42-31.png (deflated 0%)\n",
            "  adding: content/drive/MyDrive/ComfyUI/output/2025-02-08 15-42-31/0004-2025-02-08 15-42-31.png (deflated 0%)\n",
            "  adding: content/drive/MyDrive/ComfyUI/output/2025-02-08 15-53-28/ (stored 0%)\n",
            "  adding: content/drive/MyDrive/ComfyUI/output/2025-02-08 15-53-28/0001-2025-02-08 15-53-28.png (deflated 0%)\n",
            "  adding: content/drive/MyDrive/ComfyUI/output/2025-02-08 15-53-28/0002-2025-02-08 15-53-28.png (deflated 0%)\n",
            "  adding: content/drive/MyDrive/ComfyUI/output/2025-02-08 15-53-28/0003-2025-02-08 15-53-28.png (deflated 0%)\n",
            "  adding: content/drive/MyDrive/ComfyUI/output/2025-02-08 15-53-28/0004-2025-02-08 15-53-28.png (deflated 0%)\n",
            "  adding: content/drive/MyDrive/ComfyUI/output/2025-02-08 15-56-14/ (stored 0%)\n",
            "  adding: content/drive/MyDrive/ComfyUI/output/2025-02-08 15-56-14/0001-2025-02-08 15-56-14.png (deflated 0%)\n",
            "  adding: content/drive/MyDrive/ComfyUI/output/2025-02-08 15-56-14/0002-2025-02-08 15-56-14.png (deflated 0%)\n",
            "  adding: content/drive/MyDrive/ComfyUI/output/2025-02-08 15-56-14/0003-2025-02-08 15-56-14.png (deflated 0%)\n",
            "  adding: content/drive/MyDrive/ComfyUI/output/2025-02-08 15-56-14/0004-2025-02-08 15-56-14.png (deflated 0%)\n",
            "  adding: content/drive/MyDrive/ComfyUI/output/2025-02-08 15-59-01/ (stored 0%)\n",
            "  adding: content/drive/MyDrive/ComfyUI/output/2025-02-08 15-59-01/0001-2025-02-08 15-59-01.png (deflated 0%)\n",
            "  adding: content/drive/MyDrive/ComfyUI/output/2025-02-08 15-59-01/0002-2025-02-08 15-59-01.png (deflated 0%)\n",
            "  adding: content/drive/MyDrive/ComfyUI/output/2025-02-08 15-59-01/0003-2025-02-08 15-59-01.png (deflated 0%)\n",
            "  adding: content/drive/MyDrive/ComfyUI/output/2025-02-08 15-59-01/0004-2025-02-08 15-59-01.png (deflated 0%)\n",
            "  adding: content/drive/MyDrive/ComfyUI/output/2025-02-08 16-01-53/ (stored 0%)\n",
            "  adding: content/drive/MyDrive/ComfyUI/output/2025-02-08 16-01-53/0001-2025-02-08 16-01-53.png (deflated 0%)\n",
            "  adding: content/drive/MyDrive/ComfyUI/output/2025-02-08 16-01-53/0002-2025-02-08 16-01-53.png (deflated 0%)\n",
            "  adding: content/drive/MyDrive/ComfyUI/output/2025-02-08 16-01-53/0003-2025-02-08 16-01-53.png (deflated 0%)\n",
            "  adding: content/drive/MyDrive/ComfyUI/output/2025-02-08 16-01-53/0004-2025-02-08 16-01-53.png (deflated 0%)\n",
            "  adding: content/drive/MyDrive/ComfyUI/output/ComfyUI_00001_.png (deflated 0%)\n",
            "  adding: content/drive/MyDrive/ComfyUI/output/ComfyUI_00002_.png (deflated 0%)\n",
            "  adding: content/drive/MyDrive/ComfyUI/output/ComfyUI_00003_.png (deflated 0%)\n",
            "  adding: content/drive/MyDrive/ComfyUI/output/ComfyUI_00004_.png (deflated 0%)\n",
            "  adding: content/drive/MyDrive/ComfyUI/output/ComfyUI_00005_.png (deflated 0%)\n",
            "  adding: content/drive/MyDrive/ComfyUI/output/ComfyUI_00006_.png (deflated 0%)\n",
            "  adding: content/drive/MyDrive/ComfyUI/output/ComfyUI_00007_.png (deflated 0%)\n",
            "  adding: content/drive/MyDrive/ComfyUI/output/ComfyUI_00008_.png (deflated 0%)\n",
            "  adding: content/drive/MyDrive/ComfyUI/output/noobaiXLNAIXL_vPred10Version/ (stored 0%)\n",
            "  adding: content/drive/MyDrive/ComfyUI/output/noobaiXLNAIXL_vPred10Version/0001-ComfyUI-2025-02-08 14-49-33.png (deflated 0%)\n",
            "  adding: content/drive/MyDrive/ComfyUI/output/noobaiXLNAIXL_vPred10Version/0002-ComfyUI-2025-02-08 14-49-33.png (deflated 0%)\n",
            "  adding: content/drive/MyDrive/ComfyUI/output/noobaiXLNAIXL_vPred10Version/0003-ComfyUI-2025-02-08 14-49-33.png (deflated 0%)\n",
            "  adding: content/drive/MyDrive/ComfyUI/output/noobaiXLNAIXL_vPred10Version/0004-ComfyUI-2025-02-08 14-49-33.png (deflated 0%)\n",
            "  adding: content/drive/MyDrive/ComfyUI/output/noobaiXLNAIXL_vPred10Version/ComfyUI-euler-5.3-25-2025-02-08 15-11-06-0001.webp (deflated 3%)\n",
            "  adding: content/drive/MyDrive/ComfyUI/output/noobaiXLNAIXL_vPred10Version/0001-ComfyUI-euler-5.3-25-2025-02-08 15-14-31.webp (deflated 3%)\n",
            "  adding: content/drive/MyDrive/ComfyUI/output/_output_images_will_be_put_here (stored 0%)\n",
            "  adding: content/drive/MyDrive/ComfyUI/output/ÊãâËè≤_00001_.png (deflated 0%)\n",
            "  adding: content/drive/MyDrive/ComfyUI/output/ÊãâËè≤_00002_.png (deflated 0%)\n",
            "  adding: content/drive/MyDrive/ComfyUI/output/ÊãâËè≤_00003_.png (deflated 0%)\n",
            "  adding: content/drive/MyDrive/ComfyUI/output/ÊãâËè≤_00004_.png (deflated 0%)\n",
            "ÁõÆÂΩï /content/drive/MyDrive/ComfyUI/output Â∑≤ÂéãÁº©Âà∞ /content/ComfyUI_output.zip\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "os.chdir(\"/content/drive/MyDrive/ComfyUI/custom_nodes\")  # ‰øÆÊîπ‰∏∫‰Ω†ÁöÑ custom_nodes ÁõÆÂΩï\n",
        "!ls\n",
        "!git clone https://github.com/ltdrdata/ComfyUI-Manager\n",
        "os.chdir(\"/content/drive/MyDrive/ComfyUI\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IdMP8dltxxvh",
        "outputId": "08f3c54e-53c1-4fb5-c693-4f3523463b61"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "example_node.py.example  __pycache__  websocket_image_save.py\n",
            "Cloning into 'ComfyUI-Manager'...\n",
            "remote: Enumerating objects: 17474, done.\u001b[K\n",
            "remote: Counting objects: 100% (236/236), done.\u001b[K\n",
            "remote: Compressing objects: 100% (84/84), done.\u001b[K\n",
            "remote: Total 17474 (delta 179), reused 160 (delta 152), pack-reused 17238 (from 2)\u001b[K\n",
            "Receiving objects: 100% (17474/17474), 23.02 MiB | 14.24 MiB/s, done.\n",
            "Resolving deltas: 100% (12869/12869), done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# @title ‰ªé Civitai API ‰∏ãËΩΩ Ê®°Âûã\n",
        "\n",
        "Ê®°Âûã‰øùÂ≠òË∑ØÂæÑ = \"/content/ComfyUI/models/checkpoints\"  # @param {type:\"string\"}\n",
        "Ê®°ÂûãID = \"833294\"  # @param {type:\"string\"}\n",
        "APIÂØÜÈí• = \"301668c17b1b7ffe7c5c0516f323b9db\"  # @param {type:\"string\"}\n",
        "\n",
        "import os\n",
        "import requests\n",
        "import json\n",
        "from datetime import datetime\n",
        "\n",
        "# ÂàõÂª∫Ê®°Âûã‰øùÂ≠òË∑ØÂæÑ\n",
        "os.makedirs(Ê®°Âûã‰øùÂ≠òË∑ØÂæÑ, exist_ok=True)\n",
        "\n",
        "# Civitai API URL (‰ΩøÁî®Ê®°ÂûãÁâàÊú¨ API)\n",
        "API_URL = f\"https://civitai.com/api/v1/models/{Ê®°ÂûãID}\"\n",
        "\n",
        "# ÂèëÈÄÅ API ËØ∑Ê±Ç\n",
        "headers = {\n",
        "    \"Authorization\": f\"Bearer {APIÂØÜÈí•}\"\n",
        "}\n",
        "response = requests.get(API_URL, headers=headers)\n",
        "response.raise_for_status()\n",
        "\n",
        "# Ëé∑ÂèñÊ®°Âûã‰ø°ÊÅØ\n",
        "model_data = response.json()\n",
        "\n",
        "# Ëé∑ÂèñÊâÄÊúâÊ®°ÂûãÁâàÊú¨\n",
        "model_versions = model_data[\"modelVersions\"]\n",
        "\n",
        "# ÊåâÂàõÂª∫Êó•ÊúüÊéíÂ∫è (‰ªéÊúÄÊñ∞Âà∞ÊúÄÊóß)\n",
        "model_versions.sort(key=lambda x: datetime.fromisoformat(x[\"createdAt\"].replace(\"Z\", \"+00:00\")), reverse=True)\n",
        "\n",
        "# Êü•ÊâæÊúÄÊñ∞ÁâàÊú¨‰∏≠ÁöÑ bf16 Êñá‰ª∂\n",
        "download_url = None\n",
        "Ê®°ÂûãÊñá‰ª∂Âêç = None\n",
        "for version in model_versions:\n",
        "    for file in version[\"files\"]:\n",
        "        if file[\"type\"] == \"Model\" and file[\"metadata\"] and file[\"metadata\"].get(\"fp\") == \"bf16\":\n",
        "            download_url = file[\"downloadUrl\"]\n",
        "            Ê®°ÂûãÊñá‰ª∂Âêç = file[\"name\"]\n",
        "            break\n",
        "    if download_url:\n",
        "        break\n",
        "\n",
        "if download_url:\n",
        "    # ÊûÑÂª∫ÂÆåÊï¥ÁöÑÊ®°ÂûãÊñá‰ª∂Ë∑ØÂæÑ\n",
        "    Ê®°ÂûãÊñá‰ª∂ÂÆåÊï¥Ë∑ØÂæÑ = os.path.join(Ê®°Âûã‰øùÂ≠òË∑ØÂæÑ, Ê®°ÂûãÊñá‰ª∂Âêç)\n",
        "\n",
        "    print(f\"ÂéüÂßã‰∏ãËΩΩÈìæÊé•: {download_url}\")\n",
        "    print(f\"Êñá‰ª∂Âêç: {Ê®°ÂûãÊñá‰ª∂Âêç}\")\n",
        "\n",
        "    # ËÆæÁΩÆ User-Agent Âíå Referer Â§¥ÈÉ®\n",
        "    headers = {\n",
        "        \"Authorization\": f\"Bearer {APIÂØÜÈí•}\",\n",
        "        \"User-Agent\": \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36\",  # Ê®°Êãü Chrome ÊµèËßàÂô®\n",
        "        \"Referer\": \"https://civitai.com/\"  # Ê®°ÊãüÊù•Ëá™ Civitai ÂüüÂêçÁöÑËØ∑Ê±Ç\n",
        "    }\n",
        "\n",
        "    # ‰ΩøÁî® HEAD ËØ∑Ê±ÇËé∑ÂèñÈáçÂÆöÂêëÂêéÁöÑ URL\n",
        "    try:\n",
        "        redirected_response = requests.head(download_url, allow_redirects=True, headers=headers, timeout=10)  # Ê∑ªÂä†Ë∂ÖÊó∂Êó∂Èó¥\n",
        "        redirected_response.raise_for_status()  # ‰ªÖÂú®Áä∂ÊÄÅÁ†Å‰∏çÊòØ 200-399 Êó∂ÊâçÊäõÂá∫ÂºÇÂ∏∏\n",
        "        final_download_url = redirected_response.url\n",
        "        print(f\"ÈáçÂÆöÂêëÂêéÁöÑ‰∏ãËΩΩÈìæÊé•: {final_download_url}\")\n",
        "    except requests.exceptions.RequestException as e:\n",
        "        print(f\"Ëé∑ÂèñÈáçÂÆöÂêë URL Â§±Ë¥•: {e}\")\n",
        "        final_download_url = redirected_response.url  # Âç≥‰ΩøËØ∑Ê±ÇÂ§±Ë¥•Ôºå‰πüÂ∞ùËØï‰ªé response.url Ëé∑Âèñ URL\n",
        "        print(f\"Â∞ùËØï‰ªé response.url Ëé∑ÂèñÈáçÂÆöÂêëÂêéÁöÑ‰∏ãËΩΩÈìæÊé•: {final_download_url}\")\n",
        "\n",
        "    if final_download_url:\n",
        "        # ‰ΩøÁî® aria2 ‰∏ãËΩΩÊ®°Âûã\n",
        "        !apt-get install -y aria2\n",
        "        !aria2c --console-log-level=error -c -x 16 -s 16 -k 1M \"{final_download_url}\" -d \"{Ê®°Âûã‰øùÂ≠òË∑ØÂæÑ}\" -o \"{Ê®°ÂûãÊñá‰ª∂Âêç}\"\n",
        "\n",
        "        print(f\"Ê®°ÂûãÂ∑≤‰∏ãËΩΩÂà∞: {Ê®°ÂûãÊñá‰ª∂ÂÆåÊï¥Ë∑ØÂæÑ}\")\n",
        "    else:\n",
        "        print(\"Êó†Ê≥ïËé∑ÂèñÈáçÂÆöÂêëÂêéÁöÑ‰∏ãËΩΩÈìæÊé•„ÄÇ\")\n",
        "else:\n",
        "    print(\"Êó†Ê≥ïÊâæÂà∞‰ªª‰ΩïÂèØ‰∏ãËΩΩÁöÑÊ®°ÂûãÊñá‰ª∂„ÄÇ\")\n",
        "    print(\"ËØ∑Ê£ÄÊü•Ê®°Âûã ID ÊòØÂê¶Ê≠£Á°ÆÔºå‰ª•ÂèäÊ®°ÂûãÊòØÂê¶Â≠òÂú®ÂèØ‰∏ãËΩΩÁöÑÁâàÊú¨„ÄÇ\")\n",
        "    print(\"ËØ∑Á°Æ‰øùÊÇ®ÁöÑ API ÂØÜÈí•ÂÖ∑ÊúâË∂≥Â§üÁöÑÊùÉÈôê„ÄÇ\")\n"
      ],
      "metadata": {
        "id": "zGFONq9hYsvU"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}
{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mrnfqrbl/sd-forge-colab/blob/main/comfyui.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "s-UlIe6iYp0u",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f5840387-f910-4f84-9712-98baf6f865cd"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "正在挂载 Google 云盘...\n",
            "/\n",
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "/content/drive/MyDrive\n",
            "/content/drive/MyDrive/ComfyUI\n",
            "-= 正在更新 ComfyUI =-\n",
            "Already up to date.\n",
            "-= 正在安装依赖项 =-\n",
            "Looking in indexes: https://pypi.org/simple, https://download.pytorch.org/whl/cu121, https://download.pytorch.org/whl/cu118, https://download.pytorch.org/whl/cu117\n",
            "Collecting xformers!=0.0.18\n",
            "  Downloading https://download.pytorch.org/whl/cu118/xformers-0.0.29.post2-cp311-cp311-manylinux_2_28_x86_64.whl.metadata (1.0 kB)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 1)) (2.5.1+cu124)\n",
            "Collecting torchsde (from -r requirements.txt (line 2))\n",
            "  Downloading torchsde-0.2.6-py3-none-any.whl.metadata (5.3 kB)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 3)) (0.20.1+cu124)\n",
            "Requirement already satisfied: torchaudio in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 4)) (2.5.1+cu124)\n",
            "Requirement already satisfied: numpy>=1.25.0 in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 5)) (1.26.4)\n",
            "Requirement already satisfied: einops in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 6)) (0.8.0)\n",
            "Requirement already satisfied: transformers>=4.28.1 in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 7)) (4.48.2)\n",
            "Requirement already satisfied: tokenizers>=0.13.3 in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 8)) (0.21.0)\n",
            "Requirement already satisfied: sentencepiece in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 9)) (0.2.0)\n",
            "Requirement already satisfied: safetensors>=0.4.2 in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 10)) (0.5.2)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 11)) (3.11.11)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 12)) (6.0.2)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 13)) (11.1.0)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 14)) (1.13.1)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 15)) (4.67.1)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 16)) (5.9.5)\n",
            "Collecting kornia>=0.7.1 (from -r requirements.txt (line 19))\n",
            "  Downloading kornia-0.8.0-py2.py3-none-any.whl.metadata (17 kB)\n",
            "Collecting spandrel (from -r requirements.txt (line 20))\n",
            "  Downloading spandrel-0.4.1-py3-none-any.whl.metadata (15 kB)\n",
            "Requirement already satisfied: soundfile in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 21)) (0.13.1)\n",
            "Collecting torch (from -r requirements.txt (line 1))\n",
            "  Downloading https://download.pytorch.org/whl/cu118/torch-2.6.0%2Bcu118-cp311-cp311-linux_x86_64.whl.metadata (27 kB)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch->-r requirements.txt (line 1)) (3.17.0)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.11/dist-packages (from torch->-r requirements.txt (line 1)) (4.12.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch->-r requirements.txt (line 1)) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch->-r requirements.txt (line 1)) (3.1.5)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch->-r requirements.txt (line 1)) (2024.10.0)\n",
            "Collecting nvidia-cuda-nvrtc-cu11==11.8.89 (from torch->-r requirements.txt (line 1))\n",
            "  Downloading nvidia_cuda_nvrtc_cu11-11.8.89-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-runtime-cu11==11.8.89 (from torch->-r requirements.txt (line 1))\n",
            "  Downloading nvidia_cuda_runtime_cu11-11.8.89-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-cupti-cu11==11.8.87 (from torch->-r requirements.txt (line 1))\n",
            "  Downloading nvidia_cuda_cupti_cu11-11.8.87-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cudnn-cu11==9.1.0.70 (from torch->-r requirements.txt (line 1))\n",
            "  Downloading https://download.pytorch.org/whl/cu118/nvidia_cudnn_cu11-9.1.0.70-py3-none-manylinux2014_x86_64.whl (663.9 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m663.9/663.9 MB\u001b[0m \u001b[31m1.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cublas-cu11==11.11.3.6 (from torch->-r requirements.txt (line 1))\n",
            "  Downloading nvidia_cublas_cu11-11.11.3.6-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cufft-cu11==10.9.0.58 (from torch->-r requirements.txt (line 1))\n",
            "  Downloading nvidia_cufft_cu11-10.9.0.58-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-curand-cu11==10.3.0.86 (from torch->-r requirements.txt (line 1))\n",
            "  Downloading nvidia_curand_cu11-10.3.0.86-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cusolver-cu11==11.4.1.48 (from torch->-r requirements.txt (line 1))\n",
            "  Downloading nvidia_cusolver_cu11-11.4.1.48-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cusparse-cu11==11.7.5.86 (from torch->-r requirements.txt (line 1))\n",
            "  Downloading nvidia_cusparse_cu11-11.7.5.86-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-nccl-cu11==2.21.5 (from torch->-r requirements.txt (line 1))\n",
            "  Downloading https://download.pytorch.org/whl/cu118/nvidia_nccl_cu11-2.21.5-py3-none-manylinux2014_x86_64.whl (147.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m147.8/147.8 MB\u001b[0m \u001b[31m6.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-nvtx-cu11==11.8.86 (from torch->-r requirements.txt (line 1))\n",
            "  Downloading nvidia_nvtx_cu11-11.8.86-py3-none-manylinux2014_x86_64.whl.metadata (1.7 kB)\n",
            "Collecting triton==3.2.0 (from torch->-r requirements.txt (line 1))\n",
            "  Downloading https://download.pytorch.org/whl/triton-3.2.0-cp311-cp311-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (1.4 kB)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch->-r requirements.txt (line 1)) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch->-r requirements.txt (line 1)) (1.3.0)\n"
          ]
        }
      ],
      "source": [
        " # @title ComfyUI 一键安装脚本 (Google Colab)\n",
        "\n",
        "# @markdown 确保您已连接到 GPU 运行时 (运行时 -> 更改运行时类型 -> GPU)\n",
        "\n",
        "# @markdown **环境设置**\n",
        "\n",
        "使用_谷歌云盘 = True  # @param {type:\"boolean\"}\n",
        "更新_ComfyUI = False  # @param {type:\"boolean\"}\n",
        "工作区 = '/content/ComfyUI'\n",
        "\n",
        "选项 = {}\n",
        "选项['使用_谷歌云盘'] = 使用_谷歌云盘\n",
        "选项['更新_ComfyUI'] = 更新_ComfyUI\n",
        "\n",
        "if 选项['使用_谷歌云盘']:\n",
        "    print(\"正在挂载 Google 云盘...\")\n",
        "    %cd /\n",
        "\n",
        "    from google.colab import drive\n",
        "    drive.mount('/content/drive')\n",
        "\n",
        "    工作区 = \"/content/drive/MyDrive/ComfyUI\"\n",
        "    %cd /content/drive/MyDrive\n",
        "\n",
        "![ ! -d $工作区 ] && echo -= 首次安装 ComfyUI =- && git clone https://github.com/mrnfqrbl/ComfyUI\n",
        "%cd $工作区\n",
        "\n",
        "if 选项['更新_ComfyUI']:\n",
        "  # !git remote set-url origin https://github.com/mrnfqrbl/ComfyUI\n",
        "  print(\"-= 正在更新 ComfyUI =-\")\n",
        "\n",
        "  !git pull\n",
        "\n",
        "print(\"-= 正在安装依赖项 =-\")\n",
        "!pip install xformers!=0.0.18 -r requirements.txt --extra-index-url https://download.pytorch.org/whl/cu121 --extra-index-url https://download.pytorch.org/whl/cu118 --extra-index-url https://download.pytorch.org/whl/cu117\n",
        "\n",
        "\n",
        "\n",
        "# 检查点 (Checkpoints)\n",
        "\n",
        "# SDXL\n",
        "# 推荐工作流示例: https://comfyanonymous.github.io/ComfyUI_examples/sdxl/\n",
        "\n",
        "#!wget -c https://huggingface.co/stabilityai/stable-diffusion-xl-base-1.0/resolve/main/sd_xl_base_1.0.safetensors -P ./models/checkpoints/\n",
        "#!wget -c https://huggingface.co/stabilityai/stable-diffusion-xl-refiner-1.0/resolve/main/sd_xl_refiner_1.0.safetensors -P ./models/checkpoints/\n",
        "\n",
        "# SDXL ReVision\n",
        "#!wget -c https://huggingface.co/comfyanonymous/clip_vision_g/resolve/main/clip_vision_g.safetensors -P ./models/clip_vision/\n",
        "\n",
        "# SD1.5\n",
        "# !wget -c https://huggingface.co/Comfy-Org/stable-diffusion-v1-5-archive/resolve/main/v1-5-pruned-emaonly-fp16.safetensors -P ./models/checkpoints/\n",
        "\n",
        "# SD2\n",
        "#!wget -c https://huggingface.co/stabilityai/stable-diffusion-2-1-base/resolve/main/v2-1_512-ema-pruned.safetensors -P ./models/checkpoints/\n",
        "#!wget -c https://huggingface.co/stabilityai/stable-diffusion-2-1/resolve/main/v2-1_768-ema-pruned.safetensors -P ./models/checkpoints/\n",
        "\n",
        "# 一些 SD1.5 动漫风格模型\n",
        "#!wget -c https://huggingface.co/WarriorMama777/OrangeMixs/resolve/main/Models/AbyssOrangeMix2/AbyssOrangeMix2_hard.safetensors -P ./models/checkpoints/\n",
        "#!wget -c https://huggingface.co/WarriorMama777/OrangeMixs/resolve/main/Models/AbyssOrangeMix3/AOM3A1_orangemixs.safetensors -P ./models/checkpoints/\n",
        "#!wget -c https://huggingface.co/WarriorMama777/OrangeMixs/resolve/main/Models/AbyssOrangeMix3/AOM3A3_orangemixs.safetensors -P ./models/checkpoints/\n",
        "#!wget -c https://huggingface.co/Linaqruf/anything-v3.0/resolve/main/anything-v3-fp16-pruned.safetensors -P ./models/checkpoints/\n",
        "\n",
        "# Waifu Diffusion 1.5 (动漫风格 SD2.x 768-v)\n",
        "#!wget -c https://huggingface.co/waifu-diffusion/wd-1-5-beta3/resolve/main/wd-illusion-fp16.safetensors -P ./models/checkpoints/\n",
        "\n",
        "# unCLIP 模型\n",
        "#!wget -c https://huggingface.co/comfyanonymous/illuminatiDiffusionV1_v11_unCLIP/resolve/main/illuminatiDiffusionV1_v11-unclip-h-fp16.safetensors -P ./models/checkpoints/\n",
        "#!wget -c https://huggingface.co/comfyanonymous/wd-1.5-beta2_unCLIP/resolve/main/wd-1-5-beta2-aesthetic-unclip-h-fp16.safetensors -P ./models/checkpoints/\n",
        "\n",
        "# VAE\n",
        "# !wget -c https://huggingface.co/stabilityai/sd-vae-ft-mse-original/resolve/main/vae-ft-mse-840000-ema-pruned.safetensors -P ./models/vae/\n",
        "#!wget -c https://huggingface.co/WarriorMama777/OrangeMixs/resolve/main/VAEs/orangemix.vae.pt -P ./models/vae/\n",
        "#!wget -c https://huggingface.co/hakurei/waifu-diffusion-v1-4/resolve/main/vae/kl-f8-anime2.ckpt -P ./models/vae/\n",
        "\n",
        "# Loras\n",
        "#!wget -c https://civitai.com/api/download/models/10350 -O ./models/loras/theovercomer8sContrastFix_sd21768.safetensors #theovercomer8sContrastFix SD2.x 768-v\n",
        "#!wget -c https://civitai.com/api/download/models/10638 -O ./models/loras/theovercomer8sContrastFix_sd15.safetensors #theovercomer8sContrastFix SD1.x\n",
        "#!wget -c https://huggingface.co/stabilityai/stable-diffusion-xl-base-1.0/resolve/main/sd_xl_offset_example-lora_1.0.safetensors -P ./models/loras/ #SDXL offset noise lora\n",
        "\n",
        "# T2I-Adapter\n",
        "#!wget -c https://huggingface.co/TencentARC/T2I-Adapter/resolve/main/models/t2iadapter_depth_sd14v1.pth -P ./models/controlnet/\n",
        "#!wget -c https://huggingface.co/TencentARC/T2I-Adapter/resolve/main/models/t2iadapter_seg_sd14v1.pth -P ./models/controlnet/\n",
        "#!wget -c https://huggingface.co/TencentARC/T2I-Adapter/resolve/main/models/t2iadapter_sketch_sd14v1.pth -P ./models/controlnet/\n",
        "#!wget -c https://huggingface.co/TencentARC/T2I-Adapter/resolve/main/models/t2iadapter_keypose_sd14v1.pth -P ./models/controlnet/\n",
        "#!wget -c https://huggingface.co/TencentARC/T2I-Adapter/resolve/main/models/t2iadapter_openpose_sd14v1.pth -P ./models/controlnet/\n",
        "#!wget -c https://huggingface.co/TencentARC/T2I-Adapter/resolve/main/models/t2iadapter_color_sd14v1.pth -P ./models/controlnet/\n",
        "#!wget -c https://huggingface.co/TencentARC/T2I-Adapter/resolve/main/models/t2iadapter_canny_sd14v1.pth -P ./models/controlnet/\n",
        "\n",
        "# T2I Styles Model\n",
        "#!wget -c https://huggingface.co/TencentARC/T2I-Adapter/resolve/main/models/t2iadapter_style_sd14v1.pth -P ./models/style_models/\n",
        "\n",
        "# CLIPVision 模型 (styles model 需要)\n",
        "#!wget -c https://huggingface.co/openai/clip-vit-large-patch14/resolve/main/pytorch_model.bin -O ./models/clip_vision/clip_vit14.bin\n",
        "\n",
        "# ControlNet\n",
        "#!wget -c https://huggingface.co/comfyanonymous/ControlNet-v1-1_fp16_safetensors/resolve/main/control_v11e_sd15_ip2p_fp16.safetensors -P ./models/controlnet/\n",
        "#!wget -c https://huggingface.co/comfyanonymous/ControlNet-v1-1_fp16_safetensors/resolve/main/control_v11e_sd15_shuffle_fp16.safetensors -P ./models/controlnet/\n",
        "#!wget -c https://huggingface.co/comfyanonymous/ControlNet-v1-1_fp16_safetensors/resolve/main/control_v11p_sd15_canny_fp16.safetensors -P ./models/controlnet/\n",
        "#!wget -c https://huggingface.co/comfyanonymous/ControlNet-v1-1_fp16_safetensors/resolve/main/control_v11f1p_sd15_depth_fp16.safetensors -P ./models/controlnet/\n",
        "#!wget -c https://huggingface.co/comfyanonymous/ControlNet-v1-1_fp16_safetensors/resolve/main/control_v11p_sd15_inpaint_fp16.safetensors -P ./models/controlnet/\n",
        "#!wget -c https://huggingface.co/comfyanonymous/ControlNet-v1-1_fp16_safetensors/resolve/main/control_v11p_sd15_lineart_fp16.safetensors -P ./models/controlnet/\n",
        "#!wget -c https://huggingface.co/comfyanonymous/ControlNet-v1-1_fp16_safetensors/resolve/main/control_v11p_sd15_mlsd_fp16.safetensors -P ./models/controlnet/\n",
        "#!wget -c https://huggingface.co/comfyanonymous/ControlNet-v1-1_fp16_safetensors/resolve/main/control_v11p_sd15_normalbae_fp16.safetensors -P ./models/controlnet/\n",
        "#!wget -c https://huggingface.co/comfyanonymous/ControlNet-v1-1_fp16_safetensors/resolve/main/control_v11p_sd15_openpose_fp16.safetensors -P ./models/controlnet/\n",
        "#!wget -c https://huggingface.co/comfyanonymous/ControlNet-v1-1_fp16_safetensors/resolve/main/control_v11p_sd15_scribble_fp16.safetensors -P ./models/controlnet/\n",
        "#!wget -c https://huggingface.co/comfyanonymous/ControlNet-v1-1_fp16_safetensors/resolve/main/control_v11p_sd15_seg_fp16.safetensors -P ./models/controlnet/\n",
        "#!wget -c https://huggingface.co/comfyanonymous/ControlNet-v1-1_fp16_safetensors/resolve/main/control_v11p_sd15_softedge_fp16.safetensors -P ./models/controlnet/\n",
        "#!wget -c https://huggingface.co/comfyanonymous/ControlNet-v1-1_fp16_safetensors/resolve/main/control_v11p_sd15s2_lineart_anime_fp16.safetensors -P ./models/controlnet/\n",
        "#!wget -c https://huggingface.co/comfyanonymous/ControlNet-v1-1_fp16_safetensors/resolve/main/control_v11u_sd15_tile_fp16.safetensors -P ./models/controlnet/\n",
        "\n",
        "# ControlNet SDXL\n",
        "#!wget -c https://huggingface.co/stabilityai/control-lora/resolve/main/control-LoRAs-rank256/control-lora-canny-rank256.safetensors -P ./models/controlnet/\n",
        "#!wget -c https://huggingface.co/stabilityai/control-lora/resolve/main/control-LoRAs-rank256/control-lora-depth-rank256.safetensors -P ./models/controlnet/\n",
        "#!wget -c https://huggingface.co/stabilityai/control-lora/resolve/main/control-LoRAs-rank256/control-lora-recolor-rank256.safetensors -P ./models/controlnet/\n",
        "#!wget -c https://huggingface.co/stabilityai/control-lora/resolve/main/control-LoRAs-rank256/control-lora-sketch-rank256.safetensors -P ./models/controlnet/\n",
        "\n",
        "# Controlnet Preprocessor nodes by Fannovel16\n",
        "#!cd custom_nodes && git clone https://github.com/Fannovel16/comfy_controlnet_preprocessors; cd comfy_controlnet_preprocessors && python install.py\n",
        "\n",
        "# GLIGEN\n",
        "#!wget -c https://huggingface.co/comfyanonymous/GLIGEN_pruned_safetensors/resolve/main/gligen_sd14_textbox_pruned_fp16.safetensors -P ./models/gligen/\n",
        "\n",
        "# ESRGAN 放大模型\n",
        "#!wget -c https://github.com/xinntao/Real-ESRGAN/releases/download/v0.1.0/RealESRGAN_x4plus.pth -P ./models/upscale_models/\n",
        "#!wget -c https://huggingface.co/sberbank-ai/Real-ESRGAN/resolve/main/RealESRGAN_x2.pth -P ./models/upscale_models/\n",
        "#!wget -c https://huggingface.co/sberbank-ai/Real-ESRGAN/resolve/main/RealESRGAN_x4.pth -P ./models/upscale_models/\n",
        "\n",
        "安装自定义节点=True #@param {type:\"boolean\"}\n",
        "\n",
        "if 安装自定义节点:\n",
        "  !echo -= Install custom nodes dependencies =-\n",
        "  !pip install GitPython\n",
        "  !python custom_nodes/ComfyUI-Manager/cm-cli.py restore-dependencies\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# @markdown **运行 ComfyUI**\n",
        "\n",
        "# @markdown 选择一种运行 ComfyUI 的方式\n",
        "\n",
        "运行方式 = \"Cloudflare Tunnel\" #@param [\"Cloudflare Tunnel\", \"localtunnel\", \"Colab iframe\"]\n",
        "\n",
        "if 运行方式 == \"Cloudflare Tunnel\":\n",
        "\n",
        "    print(\"使用 Cloudflare Tunnel 运行 ComfyUI\")\n",
        "    !wget -O cloudflared-linux-amd64.deb https://github.com/cloudflare/cloudflared/releases/latest/download/cloudflared-linux-amd64.deb\n",
        "    !dpkg -i cloudflared-linux-amd64.deb\n",
        "\n",
        "    import subprocess\n",
        "    import threading\n",
        "    import time\n",
        "    import socket\n",
        "    import urllib.request\n",
        "\n",
        "    def 隧道线程(端口):\n",
        "      while True:\n",
        "          time.sleep(0.5)\n",
        "          套接字 = socket.socket(socket.AF_INET, socket.SOCK_STREAM)\n",
        "          结果 = 套接字.connect_ex(('127.0.0.1', 端口))\n",
        "          if 结果 == 0:\n",
        "            break\n",
        "          套接字.close()\n",
        "      print(\"\\nComfyUI 加载完成，尝试启动 cloudflared (如果卡住，cloudflared 可能有问题)\\n\")\n",
        "\n",
        "      def 启动cloudflared():\n",
        "        global cloudflared_url  # 使用全局变量存储 cloudflared URL\n",
        "        cloudflared_url = None\n",
        "        进程 = subprocess.Popen([\"cloudflared\", \"tunnel\", \"--url\", \"http://127.0.0.1:{}\".format(端口)], stdout=subprocess.PIPE, stderr=subprocess.PIPE)\n",
        "        for 行 in 进程.stderr:\n",
        "          文本 = 行.decode()\n",
        "          if \"trycloudflare.com \" in 文本:\n",
        "            cloudflared_url = 文本[文本.find(\"http\"):].strip()  # 保存 URL 并去除首尾空格\n",
        "            print(\"ComfyUI 的访问链接:\", cloudflared_url)\n",
        "            break\n",
        "        return 进程\n",
        "\n",
        "      cloudflared_进程 = 启动cloudflared()  # 首次启动 cloudflared\n",
        "      cloudflared_url = None # 初始化 cloudflared_url\n",
        "\n",
        "      def 检查cloudflared_URL():\n",
        "        global cloudflared_url\n",
        "        time.sleep(10)  # 等待 10 秒，确保 cloudflared 和 ComfyUI 都启动完成\n",
        "        if cloudflared_url:\n",
        "          try:\n",
        "            # 尝试访问 cloudflared URL\n",
        "            请求 = urllib.request.Request(cloudflared_url, method=\"HEAD\")\n",
        "            响应 = urllib.request.urlopen(请求, timeout=5) # 设置超时时间为 5 秒\n",
        "            if 响应.status == 200:\n",
        "              print(\"Cloudflare Tunnel URL 可访问\")\n",
        "            else:\n",
        "              print(\"Cloudflare Tunnel URL 访问失败，状态码:\", 响应.status)\n",
        "              cloudflared_进程.terminate()  # 终止旧的 cloudflared 进程\n",
        "              cloudflared_进程 = 启动cloudflared()  # 重新启动 cloudflared\n",
        "              print(\"已重新启动 cloudflared，生成新的 URL\")\n",
        "\n",
        "          except urllib.error.URLError as e:\n",
        "            print(\"Cloudflare Tunnel URL 访问失败:\", e)\n",
        "            cloudflared_进程.terminate()  # 终止旧的 cloudflared 进程\n",
        "            cloudflared_进程 = 启动cloudflared()  # 重新启动 cloudflared\n",
        "            print(\"已重新启动 cloudflared，生成新的 URL\")\n",
        "          except Exception as e:\n",
        "            print(\"检查 Cloudflare Tunnel URL 时发生错误:\", e)\n",
        "            cloudflared_进程.terminate()  # 终止旧的 cloudflared 进程\n",
        "            cloudflared_进程 = 启动cloudflared()  # 重新启动 cloudflared\n",
        "            print(\"已重新启动 cloudflared，生成新的 URL\")\n",
        "        else:\n",
        "          print(\"Cloudflare Tunnel URL 尚未生成，等待...\")\n",
        "          cloudflared_进程.terminate()  # 终止旧的 cloudflared 进程\n",
        "          cloudflared_进程 = 启动cloudflared()  # 重新启动 cloudflared\n",
        "          print(\"已重新启动 cloudflared，生成新的 URL\")\n",
        "\n",
        "      # 将线程启动移动到 ComfyUI 启动之后\n",
        "\n",
        "    threading.Thread(target=隧道线程, daemon=True, args=(8188,)).start()\n",
        "\n",
        "    !python main.py --dont-print-server\n",
        "\n",
        "    # 在 ComfyUI 启动后 10 秒启动 URL 检查线程\n",
        "    threading.Thread(target=检查cloudflared_URL, daemon=True).start()\n",
        "\n",
        "elif 运行方式 == \"localtunnel\":\n",
        "    print(\"使用 localtunnel 运行 ComfyUI\")\n",
        "    !npm install -g localtunnel\n",
        "\n",
        "    import threading\n",
        "    import time\n",
        "    import socket\n",
        "    import urllib\n",
        "    import subprocess\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "    def 隧道线程(端口):\n",
        "      while True:\n",
        "          time.sleep(0.5)\n",
        "          套接字 = socket.socket(socket.AF_INET, socket.SOCK_STREAM)\n",
        "          结果 = 套接字.connect_ex(('127.0.0.1', 端口))\n",
        "          if 结果 == 0:\n",
        "            break\n",
        "          套接字.close()\n",
        "      print(\"\\nComfyUI 加载完成，尝试启动 localtunnel (如果卡住，localtunnel 可能有问题)\\n\")\n",
        "\n",
        "      print(\"localtunnel 的密码/终端 IP:\", urllib.request.urlopen('https://ipv4.icanhazip.com').read().decode('utf8').strip(\"\\n\"))\n",
        "      进程 = subprocess.Popen([\"lt\", \"--port\", \"{}\".format(端口)], stdout=subprocess.PIPE)\n",
        "      for 行 in 进程.stdout:\n",
        "        print(行.decode(), end='')\n",
        "\n",
        "    threading.Thread(target=隧道线程, daemon=True, args=(8188,)).start()\n",
        "\n",
        "    !python main.py --dont-print-server\n",
        "\n",
        "elif 运行方式 == \"Colab iframe\":\n",
        "    print(\"使用 Colab iframe 运行 ComfyUI (不推荐，可能无法正常工作)\")\n",
        "    import threading\n",
        "    def iframe线程(端口):\n",
        "      while True:\n",
        "          time.sleep(0.5)\n",
        "          套接字 = socket.socket(socket.AF_INET, socket.SOCK_STREAM)\n",
        "          结果 = 套接字.connect_ex(('127.0.0.1', 端口))\n",
        "          if 结果 == 0:\n",
        "            break\n",
        "          套接字.close()\n",
        "      from google.colab import output\n",
        "      output.serve_kernel_port_as_iframe(端口, height=1024)\n",
        "      print(\"在新窗口中打开链接:\")\n",
        "      output.serve_kernel_port_as_window(端口)\n",
        "\n",
        "    threading.Thread(target=iframe线程, daemon=True, args=(8188,)).start()\n",
        "\n",
        "    !python main.py --dont-print-server\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "os.chdir(\"/content/drive/MyDrive/ComfyUI/custom_nodes\")  # 修改为你的 custom_nodes 目录\n",
        "!ls\n",
        "!git clone https://github.com/ltdrdata/ComfyUI-Manager\n",
        "os.chdir(\"/content/drive/MyDrive/ComfyUI\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IdMP8dltxxvh",
        "outputId": "08f3c54e-53c1-4fb5-c693-4f3523463b61"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "example_node.py.example  __pycache__  websocket_image_save.py\n",
            "Cloning into 'ComfyUI-Manager'...\n",
            "remote: Enumerating objects: 17474, done.\u001b[K\n",
            "remote: Counting objects: 100% (236/236), done.\u001b[K\n",
            "remote: Compressing objects: 100% (84/84), done.\u001b[K\n",
            "remote: Total 17474 (delta 179), reused 160 (delta 152), pack-reused 17238 (from 2)\u001b[K\n",
            "Receiving objects: 100% (17474/17474), 23.02 MiB | 14.24 MiB/s, done.\n",
            "Resolving deltas: 100% (12869/12869), done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# @title 从 Civitai API 下载 模型\n",
        "\n",
        "模型保存路径 = \"/content/ComfyUI/models/checkpoints\"  # @param {type:\"string\"}\n",
        "模型ID = \"833294\"  # @param {type:\"string\"}\n",
        "API密钥 = \"301668c17b1b7ffe7c5c0516f323b9db\"  # @param {type:\"string\"}\n",
        "\n",
        "import os\n",
        "import requests\n",
        "import json\n",
        "from datetime import datetime\n",
        "\n",
        "# 创建模型保存路径\n",
        "os.makedirs(模型保存路径, exist_ok=True)\n",
        "\n",
        "# Civitai API URL (使用模型版本 API)\n",
        "API_URL = f\"https://civitai.com/api/v1/models/{模型ID}\"\n",
        "\n",
        "# 发送 API 请求\n",
        "headers = {\n",
        "    \"Authorization\": f\"Bearer {API密钥}\"\n",
        "}\n",
        "response = requests.get(API_URL, headers=headers)\n",
        "response.raise_for_status()\n",
        "\n",
        "# 获取模型信息\n",
        "model_data = response.json()\n",
        "\n",
        "# 获取所有模型版本\n",
        "model_versions = model_data[\"modelVersions\"]\n",
        "\n",
        "# 按创建日期排序 (从最新到最旧)\n",
        "model_versions.sort(key=lambda x: datetime.fromisoformat(x[\"createdAt\"].replace(\"Z\", \"+00:00\")), reverse=True)\n",
        "\n",
        "# 查找最新版本中的 bf16 文件\n",
        "download_url = None\n",
        "模型文件名 = None\n",
        "for version in model_versions:\n",
        "    for file in version[\"files\"]:\n",
        "        if file[\"type\"] == \"Model\" and file[\"metadata\"] and file[\"metadata\"].get(\"fp\") == \"bf16\":\n",
        "            download_url = file[\"downloadUrl\"]\n",
        "            模型文件名 = file[\"name\"]\n",
        "            break\n",
        "    if download_url:\n",
        "        break\n",
        "\n",
        "if download_url:\n",
        "    # 构建完整的模型文件路径\n",
        "    模型文件完整路径 = os.path.join(模型保存路径, 模型文件名)\n",
        "\n",
        "    print(f\"原始下载链接: {download_url}\")\n",
        "    print(f\"文件名: {模型文件名}\")\n",
        "\n",
        "    # 设置 User-Agent 和 Referer 头部\n",
        "    headers = {\n",
        "        \"Authorization\": f\"Bearer {API密钥}\",\n",
        "        \"User-Agent\": \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36\",  # 模拟 Chrome 浏览器\n",
        "        \"Referer\": \"https://civitai.com/\"  # 模拟来自 Civitai 域名的请求\n",
        "    }\n",
        "\n",
        "    # 使用 HEAD 请求获取重定向后的 URL\n",
        "    try:\n",
        "        redirected_response = requests.head(download_url, allow_redirects=True, headers=headers, timeout=10)  # 添加超时时间\n",
        "        redirected_response.raise_for_status()  # 仅在状态码不是 200-399 时才抛出异常\n",
        "        final_download_url = redirected_response.url\n",
        "        print(f\"重定向后的下载链接: {final_download_url}\")\n",
        "    except requests.exceptions.RequestException as e:\n",
        "        print(f\"获取重定向 URL 失败: {e}\")\n",
        "        final_download_url = redirected_response.url  # 即使请求失败，也尝试从 response.url 获取 URL\n",
        "        print(f\"尝试从 response.url 获取重定向后的下载链接: {final_download_url}\")\n",
        "\n",
        "    if final_download_url:\n",
        "        # 使用 aria2 下载模型\n",
        "        !apt-get install -y aria2\n",
        "        !aria2c --console-log-level=error -c -x 16 -s 16 -k 1M \"{final_download_url}\" -d \"{模型保存路径}\" -o \"{模型文件名}\"\n",
        "\n",
        "        print(f\"模型已下载到: {模型文件完整路径}\")\n",
        "    else:\n",
        "        print(\"无法获取重定向后的下载链接。\")\n",
        "else:\n",
        "    print(\"无法找到任何可下载的模型文件。\")\n",
        "    print(\"请检查模型 ID 是否正确，以及模型是否存在可下载的版本。\")\n",
        "    print(\"请确保您的 API 密钥具有足够的权限。\")\n"
      ],
      "metadata": {
        "id": "zGFONq9hYsvU"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}
{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mrnfqrbl/sd-forge-colab/blob/main/SD.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "ÂÖàÂÆâË£ÖÂú®ÂêØÂä®"
      ],
      "metadata": {
        "id": "gUbrWaBgNzmH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "IqmZ4ZVeN2yr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@title üëá 1.ÂêØÂä®SDwebui-frogeÔºÅ\n",
        "#Ê≠§ÂçïÂÖÉÊ†ºÔºåÊØèÊ¨°ËøûÊé•colabÈÉΩÈúÄË¶ÅËøêË°å‰∏ÄÊ¨°Ôºõ‰ΩúÁî®ÊòØÔºåÂÆâË£ÖËøêË°åÁéØÂ¢ÉÂπ∂ÂêØÂä®SDwebui„ÄÇ\n",
        "# ËÆæÁΩÆËôöÊãüÁéØÂ¢ÉÁöÑ pip Âíå python Ë∑ØÂæÑ\n",
        "import binascii\n",
        "sdw = binascii.a2b_uu(\"6<W1A8FQE+61I9F9U<VEO;BUW96)U:0``\").decode('utf-8')\n",
        "print(f\"ËøôÊòØ sdw: {sdw}\")  # ËæìÂá∫ sdw ÂèòÈáè\n",
        "w = binascii.a2b_uu(\"(<V0M=V5B=6D`\").decode('utf-8')\n",
        "print(f\"ËøôÊòØ w: {w}\")  # ËæìÂá∫ w ÂèòÈáè\n",
        "\n",
        "webui_dir = f'/content/{sdw}'  # SDWebUI Êñá‰ª∂ÁõÆÂΩï\n",
        "gwebui_dir = f'/content/drive/MyDrive/{sdw}'  # Google Drive ‰∏äÁöÑ Web UI ÁõÆÂΩï\n",
        "saa = sdw + \"-assets\"  # ËµÑ‰∫ßÁõÆÂΩï\n",
        "# ÂØºÂÖ•ÂøÖË¶ÅÁöÑÂ∫ìÔºågoogle colabÁöÑÊéàÊùÉÔºåAPI ÊúçÂä°Á≠âÂäüËÉΩ\n",
        "from google.colab import drive, auth\n",
        "from googleapiclient.discovery import build\n",
        "from googleapiclient.errors import HttpError\n",
        "import os\n",
        "\n",
        "# ÊåÇËΩΩ Google Drive\n",
        "# Âà§Êñ≠ /content/drive ÊòØÂê¶Â≠òÂú®ÔºåÂ¶ÇÊûú‰∏çÂ≠òÂú®ÂàôÊåÇËΩΩ Google Drive\n",
        "if not os.path.exists('/content/drive'):\n",
        "    drive.mount('/content/drive')  # ÊåÇËΩΩ Google Drive\n",
        "drive_dir='/content/drive'\n",
        "\n",
        "# Ê£ÄÊü• GPU ÊòØÂê¶ÂèØÁî®Ôºå‰∏ç‰ΩøÁî® GPU ‰ºöÂØºËá¥‰∏Ä‰∫õÈîôËØØ\n",
        "import tensorflow as tf\n",
        "print(\"TensorFlow ÁâàÊú¨:\", tf.__version__)\n",
        "if tf.test.gpu_device_name():\n",
        "    print(\"GPU ÂèØÁî®\")  # Â¶ÇÊûú GPU ÂèØÁî®ÔºåËæìÂá∫‚ÄúGPU ÂèØÁî®‚Äù\n",
        "else:\n",
        "    print(\"GPU ‰∏çÂèØÁî®\")\n",
        "    raise Exception(\"\\nÊ≤°Êúâ‰ΩøÁî®GPUÔºåËØ∑Âú®‰ª£Á†ÅÊâßË°åÁ®ãÂ∫è-Êõ¥ÊîπËøêË°åÊó∂Á±ªÂûã-ËÆæÁΩÆ‰∏∫GPUÔºÅ\\nÂ¶ÇÊûú‰∏çËÉΩ‰ΩøÁî®GPUÔºåÂª∫ËÆÆÊõ¥Êç¢Ë¥¶Âè∑ÔºÅ\")  # ÊäõÂá∫ÂºÇÂ∏∏\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# ‰∏ãËΩΩÊåáÂÆöÊèí‰ª∂Âà∞ÊåáÂÆöÁõÆÂΩï\n",
        "# ÊâπÈáèÂÖãÈöÜ‰ªìÂ∫ìÂà∞ÊåáÂÆöË∑ØÂæÑ\n",
        "# ÂÆö‰πâ‰ªìÂ∫ì URL ÂàóË°®\n",
        "repos = (\n",
        "    \"https://github.com/gutris1/sd-hub\",\n",
        "    \"https://github.com/Physton/sd-webui-prompt-all-in-one\",\n",
        "    \"https://github.com/picobyte/stable-diffusion-webui-wd14-tagger\",\n",
        "    \"https://github.com/hanamizuki-ai/stable-diffusion-webui-localization-zh_Hans\"\n",
        ")\n",
        "\n",
        "# Á°Æ‰øùÁõÆÊ†áË∑ØÂæÑÂ≠òÂú®\n",
        "!mkdir -p {gwebui_dir}/extensions\n",
        "\n",
        "# ÈÅçÂéÜ‰ªìÂ∫ìÂàóË°®Âπ∂ËøõË°åÂÖãÈöÜ\n",
        "for repo in repos:\n",
        "    # ‰ªé URL ÊèêÂèñ‰ªìÂ∫ìÂêçÁß∞ÔºàÂç≥ URL ÊúÄÂêé‰∏ÄÈÉ®ÂàÜÔºâ\n",
        "    repo_name = !basename {repo}\n",
        "    repo_name = repo_name[0]\n",
        "\n",
        "    # Âä®ÊÄÅÊûÑÂª∫ÂÖãÈöÜË∑ØÂæÑ\n",
        "    target_path = f\"{gwebui_dir}/extensions/{repo_name}\"\n",
        "\n",
        "    # Ê£ÄÊü•ÁõÆÊ†áË∑ØÂæÑÊòØÂê¶Â≠òÂú®\n",
        "    if os.path.exists(target_path):\n",
        "        print(f\"Ê®°Âùó {repo_name} Â∑≤Â≠òÂú®ÔºåË∑≥ËøáÂÖãÈöÜ„ÄÇ\")\n",
        "    else:\n",
        "        # ÂÖãÈöÜ‰ªìÂ∫ìÂà∞ÊåáÂÆöË∑ØÂæÑ\n",
        "        print(f\"ÂÆâË£ÖÊ®°Âùó: {repo_name}\")\n",
        "        !git clone --depth 1 {repo} {target_path}\n",
        "# # ÈìæÊé• Stable Diffusion Ê®°ÂûãÊñá‰ª∂Â§πÂà∞ webui_dir ‰∏ã\n",
        "# !test -d {webui_dir}/models/Stable-diffusion && test -d {gwebui_dir}/models/Stable-diffusion && ln -sf {gwebui_dir}/models/Stable-diffusion {webui_dir}/models/Stable-diffusion\n",
        "# # ËÆæÂÆö Stable Diffusion Ê®°ÂûãÊñá‰ª∂Â§πÁöÑË∑ØÂæÑ\n",
        "# model_dir = os.path.join(webui_dir, 'models', 'Stable-diffusion')\n",
        "# gmodel_dir = os.path.join(gwebui_dir, 'models', 'Stable-diffusion')\n",
        "\n",
        "# # ÈìæÊé• Lora Ê®°ÂûãÊñá‰ª∂Â§πÂà∞ webui_dir ‰∏ã\n",
        "# !test -d {webui_dir}/models/Lora && test -d {gwebui_dir}/models/Lora && ln -sf {gwebui_dir}/models/Lora {webui_dir}/models/Lora\n",
        "# # ËÆæÂÆö Lora Ê®°ÂûãÊñá‰ª∂Â§πÁöÑË∑ØÂæÑ\n",
        "# Lora_dir = os.path.join(gwebui_dir, 'models', 'Lora')\n",
        "# gLora_dir = os.path.join(gwebui_dir, 'models', 'Lora')\n",
        "\n",
        "# ËÆæÁΩÆÂêØÂä®ÂèÇÊï∞ÔºåÂåÖÊã¨ÂêØÁî® API„ÄÅÁ¶ÅÁî®ÂÆâÂÖ® pickle„ÄÅÁ¶ÅÁî®ÊéßÂà∂Âè∞ËøõÂ∫¶Êù°Á≠â\n",
        "\n",
        "\n",
        "wise=\"--share \\\n",
        "--api \\\n",
        "--disable-safe-unpickle \\\n",
        "--enable-insecure-extension-access \\\n",
        "--no-download-sd-model \\\n",
        "--no-half-vae \\\n",
        "--opt-sdp-attention \\\n",
        "--disable-console-progressbars \\\n",
        "--theme dark \\\n",
        "--skip-google-blockly \\\n",
        "--skip-version-check \\\n",
        "--disable-model-loading-ram-optimization \\\n",
        "--opt-sub-quad-attention \\\n",
        "--loglevel DEBUG \\\n",
        "--lowram \\\n",
        "--gradio-queue \\\n",
        "--opt-split-attention\"\n",
        "#--max-batch-count 8 \\\n",
        "try:\n",
        "    git_v = !git --version\n",
        "    git_v = git_v[0].split(\" \")[2]  # Extract version number\n",
        "\n",
        "    if git_v < \"2.47.1\":\n",
        "        print(\"ÂÆâË£Ögit\")\n",
        "        !add-apt-repository ppa:git-core/ppa -y\n",
        "        !apt -y install git\n",
        "        !apt -y install --only-upgrade git\n",
        "        print(\"gitÂ∑≤ÂÆâË£Ö\")\n",
        "        !git --version\n",
        "    else:\n",
        "        print(\"gitÂ∑≤ÂÆâË£ÖË∑≥Ëøá\")\n",
        "except IndexError:\n",
        "    print(\"gitÊú™ÂÆâË£ÖÔºåÊ≠£Âú®ÂÆâË£Ö...\")\n",
        "    !add-apt-repository ppa:git-core/ppa -y\n",
        "    !apt -y install git\n",
        "    print(\"gitÂ∑≤ÂÆâË£Ö\")\n",
        "    !git --version\n",
        "# ÂêØÂä® Web UI\n",
        "#!python launch.py $wise --ckpt-dir {model_dir} --lora-dir {Lora_dir}\n",
        "!python {gwebui_dir}/launch.py $wise\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "rEffjWbcN3dY",
        "outputId": "f81267fa-6c20-4bac-94a9-04f184e3ecaa",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ËøôÊòØ sdw: stable-diffusion-webui\n",
            "ËøôÊòØ w: sd-webui\n",
            "TensorFlow ÁâàÊú¨: 2.17.1\n",
            "GPU ÂèØÁî®\n",
            "Ê®°Âùó sd-hub Â∑≤Â≠òÂú®ÔºåË∑≥ËøáÂÖãÈöÜ„ÄÇ\n",
            "Ê®°Âùó sd-webui-prompt-all-in-one Â∑≤Â≠òÂú®ÔºåË∑≥ËøáÂÖãÈöÜ„ÄÇ\n",
            "Ê®°Âùó stable-diffusion-webui-wd14-tagger Â∑≤Â≠òÂú®ÔºåË∑≥ËøáÂÖãÈöÜ„ÄÇ\n",
            "Ê®°Âùó stable-diffusion-webui-localization-zh_Hans Â∑≤Â≠òÂú®ÔºåË∑≥ËøáÂÖãÈöÜ„ÄÇ\n",
            "gitÂ∑≤ÂÆâË£ÖË∑≥Ëøá\n",
            "Python 3.10.12 (main, Nov  6 2024, 20:22:13) [GCC 11.4.0]\n",
            "Version: f2.0.1v1.10.1-previous-635-gf53307881\n",
            "Commit hash: f53307881bfd824dbdce6ac0d4bba04d9a74ab36\n",
            "Installing requirements\n",
            "2025-01-12 16:59:49 DEBUG [root] Installing put extensions here.txt\n",
            "2025-01-12 16:59:49 DEBUG [root] Installing sd-webui-prompt-all-in-one\n",
            "2025-01-12 16:59:49 DEBUG [root] Installing sd-hub\n",
            "2025-01-12 16:59:53 DEBUG [root] Installing stable-diffusion-webui-wd14-tagger\n",
            "loading WD14-tagger reqs from /content/drive/MyDrive/stable-diffusion-webui/extensions/stable-diffusion-webui-wd14-tagger/requirements.txt\n",
            "Checking WD14-tagger requirements.\n",
            "2025-01-12 17:00:05 DEBUG [root] Installing stable-diffusion-webui-chinese\n",
            "2025-01-12 17:00:05 DEBUG [root] Installing stable-diffusion-webui-localization-zh_Hans\n",
            "2025-01-12 17:00:05 DEBUG [root] Installing forge_preprocessor_marigold\n",
            "2025-01-12 17:00:05 DEBUG [root] Installing forge_space_sapiens_normal\n",
            "2025-01-12 17:00:05 DEBUG [root] Installing forge_space_geowizard\n",
            "2025-01-12 17:00:05 DEBUG [root] Installing forge_space_iclight\n",
            "2025-01-12 17:00:05 DEBUG [root] Installing forge_space_example\n",
            "2025-01-12 17:00:05 DEBUG [root] Installing forge_preprocessor_normalbae\n",
            "2025-01-12 17:00:06 DEBUG [root] Installing sd_forge_lora\n",
            "2025-01-12 17:00:06 DEBUG [root] Installing forge_preprocessor_recolor\n",
            "2025-01-12 17:00:06 DEBUG [root] Installing forge_legacy_preprocessors\n",
            "Legacy Preprocessor init warning: Unable to install insightface automatically. Please try run `pip install insightface` manually.\n",
            "2025-01-12 17:00:06 DEBUG [root] Installing soft-inpainting\n",
            "2025-01-12 17:00:06 DEBUG [root] Installing sd_forge_fooocus_inpaint\n",
            "2025-01-12 17:00:06 DEBUG [root] Installing prompt-bracket-checker\n",
            "2025-01-12 17:00:06 DEBUG [root] Installing forge_space_photo_maker_v2\n",
            "2025-01-12 17:00:06 DEBUG [root] Installing mobile\n",
            "2025-01-12 17:00:06 DEBUG [root] Installing forge_space_animagine_xl_31\n",
            "2025-01-12 17:00:06 DEBUG [root] Installing extra-options-section\n",
            "2025-01-12 17:00:06 DEBUG [root] Installing sd_forge_perturbed_attention\n",
            "2025-01-12 17:00:06 DEBUG [root] Installing forge_preprocessor_revision\n",
            "2025-01-12 17:00:06 DEBUG [root] Installing sd_forge_freeu\n",
            "2025-01-12 17:00:06 DEBUG [root] Installing sd_forge_neveroom\n",
            "2025-01-12 17:00:06 DEBUG [root] Installing forge_space_idm_vton\n",
            "2025-01-12 17:00:06 DEBUG [root] Installing sd_forge_kohya_hrfix\n",
            "2025-01-12 17:00:06 DEBUG [root] Installing sd_forge_controlnet\n",
            "2025-01-12 17:00:06 DEBUG [root] Installing forge_preprocessor_tile\n",
            "2025-01-12 17:00:06 DEBUG [root] Installing forge_preprocessor_reference\n",
            "2025-01-12 17:00:06 DEBUG [root] Installing sd_forge_latent_modifier\n",
            "2025-01-12 17:00:06 DEBUG [root] Installing sd_forge_ipadapter\n",
            "2025-01-12 17:00:06 DEBUG [root] Installing forge_preprocessor_inpaint\n",
            "2025-01-12 17:00:06 DEBUG [root] Installing forge_space_birefnet\n",
            "2025-01-12 17:00:06 DEBUG [root] Installing forge_space_illusion_diffusion\n",
            "2025-01-12 17:00:06 DEBUG [root] Installing forge_space_florence_2\n",
            "2025-01-12 17:00:06 DEBUG [root] Installing SwinIR\n",
            "2025-01-12 17:00:06 DEBUG [root] Installing sd_forge_controlllite\n",
            "2025-01-12 17:00:06 DEBUG [root] Installing sd_forge_stylealign\n",
            "2025-01-12 17:00:06 DEBUG [root] Installing sd_forge_sag\n",
            "2025-01-12 17:00:06 DEBUG [root] Installing sd_forge_dynamic_thresholding\n",
            "2025-01-12 17:00:06 DEBUG [root] Installing sd_forge_multidiffusion\n",
            "2025-01-12 17:00:06 DEBUG [root] Installing ScuNET\n",
            "Launching Web UI with arguments: --share --api --disable-safe-unpickle --enable-insecure-extension-access --no-download-sd-model --no-half-vae --opt-sdp-attention --disable-console-progressbars --theme dark --skip-google-blockly --skip-version-check --disable-model-loading-ram-optimization --opt-sub-quad-attention --loglevel DEBUG --lowram --gradio-queue --opt-split-attention\n",
            "2025-01-12 17:00:08 DEBUG [pydot] pydot initializing\n",
            "2025-01-12 17:00:08 DEBUG [pydot] pydot 3.0.4\n",
            "2025-01-12 17:00:08 DEBUG [pydot.dot_parser] pydot dot_parser module initializing\n",
            "2025-01-12 17:00:08 DEBUG [pydot.core] pydot core module initializing\n",
            "Total VRAM 15102 MB, total RAM 12979 MB\n",
            "pytorch version: 2.5.1+cu121\n",
            "Set vram state to: NORMAL_VRAM\n",
            "Device: cuda:0 Tesla T4 : native\n",
            "VAE dtype preferences: [torch.float32] -> torch.float32\n",
            "CUDA Using Stream: False\n",
            "2025-01-12 17:00:10 DEBUG [httpx] load_ssl_context verify=True cert=None trust_env=True http2=False\n",
            "2025-01-12 17:00:10 DEBUG [httpx] load_verify_locations cafile='/usr/local/lib/python3.10/dist-packages/certifi/cacert.pem'\n",
            "2025-01-12 17:00:11 DEBUG [httpx] load_ssl_context verify=True cert=None trust_env=True http2=False\n",
            "2025-01-12 17:00:11 DEBUG [httpx] load_verify_locations cafile='/usr/local/lib/python3.10/dist-packages/certifi/cacert.pem'\n",
            "2025-01-12 17:00:11 DEBUG [httpx] load_ssl_context verify=True cert=None trust_env=True http2=False\n",
            "2025-01-12 17:00:11 DEBUG [httpx] load_verify_locations cafile='/usr/local/lib/python3.10/dist-packages/certifi/cacert.pem'\n",
            "2025-01-12 17:00:11 DEBUG [bitsandbytes.cextension] Loading bitsandbytes native library from: /usr/local/lib/python3.10/dist-packages/bitsandbytes/libbitsandbytes_cuda121.so\n",
            "2025-01-12 17:00:15.182318: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:485] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "2025-01-12 17:00:15.429286: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:8454] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "2025-01-12 17:00:15.502575: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1452] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "2025-01-12 17:00:17 DEBUG [tensorflow] Falling back to TensorFlow client; we recommended you install the Cloud TPU client directly with pip install cloud-tpu-client.\n",
            "2025-01-12 17:00:17.669836: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "2025-01-12 17:00:17 DEBUG [h5py._conv] Creating converter from 7 to 5\n",
            "2025-01-12 17:00:17 DEBUG [h5py._conv] Creating converter from 5 to 7\n",
            "2025-01-12 17:00:17 DEBUG [h5py._conv] Creating converter from 7 to 5\n",
            "2025-01-12 17:00:17 DEBUG [h5py._conv] Creating converter from 5 to 7\n",
            "2025-01-12 17:00:18 DEBUG [jax._src.path] etils.epath found. Using etils.epath for file I/O.\n",
            "2025-01-12 17:00:20 INFO [numexpr.utils] NumExpr defaulting to 2 threads.\n",
            "2025-01-12 17:00:20 DEBUG [git.cmd] Popen(['git', 'version'], cwd=/content, universal_newlines=False, shell=None, istream=None)\n",
            "2025-01-12 17:00:20 DEBUG [git.cmd] Popen(['git', 'version'], cwd=/content, universal_newlines=False, shell=None, istream=None)\n",
            "2025-01-12 17:00:20 DEBUG [wandb.docker.auth] Trying paths: ['/root/.docker/config.json', '/root/.dockercfg']\n",
            "2025-01-12 17:00:20 DEBUG [wandb.docker.auth] No config file found\n",
            "Using pytorch cross attention\n",
            "Using pytorch attention for VAE\n",
            "2025-01-12 17:00:22 DEBUG [PIL.Image] Importing BlpImagePlugin\n",
            "2025-01-12 17:00:22 DEBUG [PIL.Image] Importing BmpImagePlugin\n",
            "2025-01-12 17:00:22 DEBUG [PIL.Image] Importing BufrStubImagePlugin\n",
            "2025-01-12 17:00:22 DEBUG [PIL.Image] Importing CurImagePlugin\n",
            "2025-01-12 17:00:22 DEBUG [PIL.Image] Importing DcxImagePlugin\n",
            "2025-01-12 17:00:22 DEBUG [PIL.Image] Importing DdsImagePlugin\n",
            "2025-01-12 17:00:22 DEBUG [PIL.Image] Importing EpsImagePlugin\n",
            "2025-01-12 17:00:22 DEBUG [PIL.Image] Importing FitsImagePlugin\n",
            "2025-01-12 17:00:22 DEBUG [PIL.Image] Importing FitsStubImagePlugin\n",
            "2025-01-12 17:00:22 DEBUG [PIL.Image] Importing FliImagePlugin\n",
            "2025-01-12 17:00:22 DEBUG [PIL.Image] Importing FpxImagePlugin\n",
            "2025-01-12 17:00:22 DEBUG [PIL.Image] Image: failed to import FpxImagePlugin: No module named 'olefile'\n",
            "2025-01-12 17:00:22 DEBUG [PIL.Image] Importing FtexImagePlugin\n",
            "2025-01-12 17:00:22 DEBUG [PIL.Image] Importing GbrImagePlugin\n",
            "2025-01-12 17:00:22 DEBUG [PIL.Image] Importing GifImagePlugin\n",
            "2025-01-12 17:00:22 DEBUG [PIL.Image] Importing GribStubImagePlugin\n",
            "2025-01-12 17:00:22 DEBUG [PIL.Image] Importing Hdf5StubImagePlugin\n",
            "2025-01-12 17:00:22 DEBUG [PIL.Image] Importing IcnsImagePlugin\n",
            "2025-01-12 17:00:22 DEBUG [PIL.Image] Importing IcoImagePlugin\n",
            "2025-01-12 17:00:22 DEBUG [PIL.Image] Importing ImImagePlugin\n",
            "2025-01-12 17:00:22 DEBUG [PIL.Image] Importing ImtImagePlugin\n",
            "2025-01-12 17:00:22 DEBUG [PIL.Image] Importing IptcImagePlugin\n",
            "2025-01-12 17:00:22 DEBUG [PIL.Image] Importing JpegImagePlugin\n",
            "2025-01-12 17:00:22 DEBUG [PIL.Image] Importing Jpeg2KImagePlugin\n",
            "2025-01-12 17:00:22 DEBUG [PIL.Image] Importing McIdasImagePlugin\n",
            "2025-01-12 17:00:22 DEBUG [PIL.Image] Importing MicImagePlugin\n",
            "2025-01-12 17:00:22 DEBUG [PIL.Image] Image: failed to import MicImagePlugin: No module named 'olefile'\n",
            "2025-01-12 17:00:22 DEBUG [PIL.Image] Importing MpegImagePlugin\n",
            "2025-01-12 17:00:22 DEBUG [PIL.Image] Importing MpoImagePlugin\n",
            "2025-01-12 17:00:22 DEBUG [PIL.Image] Importing MspImagePlugin\n",
            "2025-01-12 17:00:22 DEBUG [PIL.Image] Importing PalmImagePlugin\n",
            "2025-01-12 17:00:22 DEBUG [PIL.Image] Importing PcdImagePlugin\n",
            "2025-01-12 17:00:22 DEBUG [PIL.Image] Importing PcxImagePlugin\n",
            "2025-01-12 17:00:22 DEBUG [PIL.Image] Importing PdfImagePlugin\n",
            "2025-01-12 17:00:22 DEBUG [PIL.Image] Importing PixarImagePlugin\n",
            "2025-01-12 17:00:22 DEBUG [PIL.Image] Importing PngImagePlugin\n",
            "2025-01-12 17:00:22 DEBUG [PIL.Image] Importing PpmImagePlugin\n",
            "2025-01-12 17:00:22 DEBUG [PIL.Image] Importing PsdImagePlugin\n",
            "2025-01-12 17:00:22 DEBUG [PIL.Image] Importing QoiImagePlugin\n",
            "2025-01-12 17:00:22 DEBUG [PIL.Image] Importing SgiImagePlugin\n",
            "2025-01-12 17:00:22 DEBUG [PIL.Image] Importing SpiderImagePlugin\n",
            "2025-01-12 17:00:22 DEBUG [PIL.Image] Importing SunImagePlugin\n",
            "2025-01-12 17:00:22 DEBUG [PIL.Image] Importing TgaImagePlugin\n",
            "2025-01-12 17:00:22 DEBUG [PIL.Image] Importing TiffImagePlugin\n",
            "2025-01-12 17:00:22 DEBUG [PIL.Image] Importing WebPImagePlugin\n",
            "2025-01-12 17:00:22 DEBUG [PIL.Image] Importing WmfImagePlugin\n",
            "2025-01-12 17:00:22 DEBUG [PIL.Image] Importing XbmImagePlugin\n",
            "2025-01-12 17:00:22 DEBUG [PIL.Image] Importing XpmImagePlugin\n",
            "2025-01-12 17:00:22 DEBUG [PIL.Image] Importing XVThumbImagePlugin\n",
            "2025-01-12 17:00:26 DEBUG [matplotlib] matplotlib data path: /usr/local/lib/python3.10/dist-packages/matplotlib/mpl-data\n",
            "2025-01-12 17:00:26 DEBUG [matplotlib] CONFIGDIR=/root/.config/matplotlib\n",
            "2025-01-12 17:00:26 DEBUG [matplotlib] interactive is False\n",
            "2025-01-12 17:00:26 DEBUG [matplotlib] platform is linux\n",
            "2025-01-12 17:00:26 DEBUG [matplotlib] CACHEDIR=/root/.cache/matplotlib\n",
            "2025-01-12 17:00:26 DEBUG [matplotlib.font_manager] Using fontManager instance from /root/.cache/matplotlib/fontlist-v390.json\n",
            "ControlNet preprocessor location: /content/drive/MyDrive/stable-diffusion-webui/models/ControlNetPreprocessor\n",
            "\u001b[38;5;208m‚ñ∂\u001b[0m SD-Hub: \u001b[38;5;39mv5.6.1\u001b[0m\n",
            "sd-webui-prompt-all-in-one background API service started successfully.\n",
            "== WD14 tagger /gpu:0, uname_result(system='Linux', node='0737671adf3a', release='6.1.85+', version='#1 SMP PREEMPT_DYNAMIC Thu Jun 27 21:05:47 UTC 2024', machine='x86_64') ==\n",
            "2025-01-12 17:00:39 DEBUG [asyncio] Using selector: EpollSelector\n",
            "2025-01-12 17:00:41,243 - ControlNet - \u001b[0;32mINFO\u001b[0m - ControlNet UI callback registered.\n",
            "/content/drive/MyDrive/stable-diffusion-webui/extensions/stable-diffusion-webui-wd14-tagger/tagger/ui.py:232: GradioDeprecationWarning: unexpected argument for HTML: interactive\n",
            "  info = gr.HTML(\n",
            "Model selected: {'checkpoint_info': {'filename': '/content/drive/MyDrive/stable-diffusion-webui/models/Stable-diffusion/noobaiXLNAIXL_vPred06Version.safetensors', 'hash': '25dc06a8'}, 'additional_modules': [], 'unet_storage_dtype': None}\n",
            "Using online LoRAs in FP16: False\n",
            "2025-01-12 17:00:45 DEBUG [asyncio] Using selector: EpollSelector\n",
            "Running on local URL:  http://127.0.0.1:7860\n",
            "2025-01-12 17:00:45 DEBUG [httpx] load_ssl_context verify=None cert=None trust_env=True http2=False\n",
            "2025-01-12 17:00:45 INFO [httpx] HTTP Request: GET http://127.0.0.1:7860/startup-events \"HTTP/1.1 200 OK\"\n",
            "2025-01-12 17:00:45 DEBUG [botocore.hooks] Changing event name from creating-client-class.iot-data to creating-client-class.iot-data-plane\n",
            "2025-01-12 17:00:45 DEBUG [botocore.hooks] Changing event name from before-call.apigateway to before-call.api-gateway\n",
            "2025-01-12 17:00:45 DEBUG [botocore.hooks] Changing event name from request-created.machinelearning.Predict to request-created.machine-learning.Predict\n",
            "2025-01-12 17:00:45 DEBUG [botocore.hooks] Changing event name from before-parameter-build.autoscaling.CreateLaunchConfiguration to before-parameter-build.auto-scaling.CreateLaunchConfiguration\n",
            "2025-01-12 17:00:45 DEBUG [botocore.hooks] Changing event name from before-parameter-build.route53 to before-parameter-build.route-53\n",
            "2025-01-12 17:00:45 DEBUG [botocore.hooks] Changing event name from request-created.cloudsearchdomain.Search to request-created.cloudsearch-domain.Search\n",
            "2025-01-12 17:00:45 DEBUG [botocore.hooks] Changing event name from docs.*.autoscaling.CreateLaunchConfiguration.complete-section to docs.*.auto-scaling.CreateLaunchConfiguration.complete-section\n",
            "2025-01-12 17:00:45 DEBUG [botocore.hooks] Changing event name from before-parameter-build.logs.CreateExportTask to before-parameter-build.cloudwatch-logs.CreateExportTask\n",
            "2025-01-12 17:00:45 DEBUG [botocore.hooks] Changing event name from docs.*.logs.CreateExportTask.complete-section to docs.*.cloudwatch-logs.CreateExportTask.complete-section\n",
            "2025-01-12 17:00:45 DEBUG [botocore.hooks] Changing event name from before-parameter-build.cloudsearchdomain.Search to before-parameter-build.cloudsearch-domain.Search\n",
            "2025-01-12 17:00:45 DEBUG [botocore.hooks] Changing event name from docs.*.cloudsearchdomain.Search.complete-section to docs.*.cloudsearch-domain.Search.complete-section\n",
            "2025-01-12 17:00:45 DEBUG [botocore.utils] IMDS ENDPOINT: http://169.254.169.254/\n",
            "2025-01-12 17:00:45 DEBUG [botocore.credentials] Looking for credentials via: env\n",
            "2025-01-12 17:00:45 DEBUG [botocore.credentials] Looking for credentials via: assume-role\n",
            "2025-01-12 17:00:45 DEBUG [botocore.credentials] Looking for credentials via: assume-role-with-web-identity\n",
            "2025-01-12 17:00:45 DEBUG [botocore.credentials] Looking for credentials via: sso\n",
            "2025-01-12 17:00:45 DEBUG [botocore.credentials] Looking for credentials via: shared-credentials-file\n",
            "2025-01-12 17:00:45 DEBUG [botocore.credentials] Looking for credentials via: custom-process\n",
            "2025-01-12 17:00:45 DEBUG [botocore.credentials] Looking for credentials via: config-file\n",
            "2025-01-12 17:00:45 DEBUG [botocore.credentials] Looking for credentials via: ec2-credentials-file\n",
            "2025-01-12 17:00:45 DEBUG [botocore.credentials] Looking for credentials via: boto-config\n",
            "2025-01-12 17:00:45 DEBUG [botocore.credentials] Looking for credentials via: container-role\n",
            "2025-01-12 17:00:45 DEBUG [botocore.credentials] Looking for credentials via: iam-role\n",
            "2025-01-12 17:00:45 DEBUG [urllib3.connectionpool] Starting new HTTP connection (1): 169.254.169.254:80\n",
            "2025-01-12 17:00:45 DEBUG [urllib3.connectionpool] http://169.254.169.254:80 \"PUT /latest/api/token HTTP/1.1\" 400 1\n",
            "2025-01-12 17:00:45 DEBUG [botocore.utils] Bad IMDS request: <botocore.awsrequest.AWSRequest object at 0x7b63c0a5fee0>\n",
            "2025-01-12 17:00:45 DEBUG [botocore.loaders] Loading JSON file: /usr/local/lib/python3.10/dist-packages/botocore/data/endpoints.json\n",
            "2025-01-12 17:00:45 DEBUG [botocore.loaders] Loading JSON file: /usr/local/lib/python3.10/dist-packages/botocore/data/sdk-default-configuration.json\n",
            "2025-01-12 17:00:45 DEBUG [botocore.hooks] Event choose-service-name: calling handler <function handle_service_name_alias at 0x7b6450fbb0a0>\n",
            "2025-01-12 17:00:45 DEBUG [botocore.loaders] Loading JSON file: /usr/local/lib/python3.10/dist-packages/botocore/data/sts/2011-06-15/service-2.json.gz\n",
            "2025-01-12 17:00:45 DEBUG [botocore.loaders] Loading JSON file: /usr/local/lib/python3.10/dist-packages/botocore/data/sts/2011-06-15/endpoint-rule-set-1.json.gz\n",
            "2025-01-12 17:00:45 DEBUG [botocore.loaders] Loading JSON file: /usr/local/lib/python3.10/dist-packages/botocore/data/partitions.json\n",
            "2025-01-12 17:00:45 DEBUG [botocore.hooks] Event creating-client-class.sts: calling handler <function add_generate_presigned_url at 0x7b645031f760>\n",
            "2025-01-12 17:00:45 DEBUG [botocore.configprovider] Looking for endpoint for sts via: environment_service\n",
            "2025-01-12 17:00:45 DEBUG [botocore.configprovider] Looking for endpoint for sts via: environment_global\n",
            "2025-01-12 17:00:45 DEBUG [botocore.configprovider] Looking for endpoint for sts via: config_service\n",
            "2025-01-12 17:00:45 DEBUG [botocore.configprovider] Looking for endpoint for sts via: config_global\n",
            "2025-01-12 17:00:45 DEBUG [botocore.configprovider] No configured endpoint found.\n",
            "2025-01-12 17:00:45 DEBUG [botocore.endpoint] Setting sts timeout as (60, 60)\n",
            "2025-01-12 17:00:45 DEBUG [botocore.loaders] Loading JSON file: /usr/local/lib/python3.10/dist-packages/botocore/data/_retry.json\n",
            "2025-01-12 17:00:45 DEBUG [botocore.client] Registering retry handlers for service: sts\n",
            "2025-01-12 17:00:45 DEBUG [botocore.hooks] Event before-parameter-build.sts.GetCallerIdentity: calling handler <function generate_idempotent_uuid at 0x7b64501b32e0>\n",
            "2025-01-12 17:00:45 DEBUG [botocore.regions] Calling endpoint provider with parameters: {'Region': 'aws-global', 'UseDualStack': False, 'UseFIPS': False, 'UseGlobalEndpoint': True}\n",
            "2025-01-12 17:00:45 DEBUG [botocore.regions] Endpoint provider result: https://sts.amazonaws.com\n",
            "2025-01-12 17:00:45 DEBUG [botocore.regions] Selecting from endpoint provider's list of auth schemes: \"sigv4\". User selected auth scheme is: \"None\"\n",
            "2025-01-12 17:00:45 DEBUG [botocore.regions] Selected auth type \"v4\" as \"v4\" with signing context params: {'region': 'us-east-1', 'signing_name': 'sts'}\n",
            "2025-01-12 17:00:45 DEBUG [botocore.hooks] Event before-call.sts.GetCallerIdentity: calling handler <function add_recursion_detection_header at 0x7b64501b2ef0>\n",
            "2025-01-12 17:00:45 DEBUG [botocore.hooks] Event before-call.sts.GetCallerIdentity: calling handler <function add_query_compatibility_header at 0x7b64501dd990>\n",
            "2025-01-12 17:00:45 DEBUG [botocore.hooks] Event before-call.sts.GetCallerIdentity: calling handler <function inject_api_version_header_if_needed at 0x7b64501dcb80>\n",
            "2025-01-12 17:00:45 DEBUG [botocore.endpoint] Making request for OperationModel(name=GetCallerIdentity) with params: {'url_path': '/', 'query_string': '', 'method': 'POST', 'headers': {'Content-Type': 'application/x-www-form-urlencoded; charset=utf-8', 'User-Agent': 'Boto3/1.35.97 md/Botocore#1.35.97 ua/2.0 os/linux#6.1.85+ md/arch#x86_64 lang/python#3.10.12 md/pyimpl#CPython cfg/retry-mode#legacy Botocore/1.35.97'}, 'body': {'Action': 'GetCallerIdentity', 'Version': '2011-06-15'}, 'url': 'https://sts.amazonaws.com/', 'context': {'client_region': 'aws-global', 'client_config': <botocore.config.Config object at 0x7b63c0a5f520>, 'has_streaming_input': False, 'auth_type': 'v4', 'unsigned_payload': None, 'signing': {'region': 'us-east-1', 'signing_name': 'sts'}, 'endpoint_properties': {'authSchemes': [{'name': 'sigv4', 'signingName': 'sts', 'signingRegion': 'us-east-1'}]}}}\n",
            "2025-01-12 17:00:45 DEBUG [botocore.hooks] Event request-created.sts.GetCallerIdentity: calling handler <bound method RequestSigner.handler of <botocore.signers.RequestSigner object at 0x7b63c0a5c820>>\n",
            "2025-01-12 17:00:45 DEBUG [botocore.hooks] Event choose-signer.sts.GetCallerIdentity: calling handler <function set_operation_specific_signer at 0x7b64501b3130>\n",
            "2025-01-12 17:00:45 DEBUG [httpx] load_ssl_context verify=False cert=None trust_env=True http2=False\n",
            "2025-01-12 17:00:46 INFO [httpx] HTTP Request: HEAD http://127.0.0.1:7860/ \"HTTP/1.1 200 OK\"\n",
            "2025-01-12 17:00:46 DEBUG [httpx] load_ssl_context verify=True cert=None trust_env=True http2=False\n",
            "2025-01-12 17:00:46 DEBUG [httpx] load_verify_locations cafile='/usr/local/lib/python3.10/dist-packages/certifi/cacert.pem'\n",
            "2025-01-12 17:00:47 INFO [httpx] HTTP Request: GET https://api.gradio.app/v2/tunnel-request \"HTTP/1.1 200 OK\"\n",
            "Running on public URL: https://60184188c831943285.gradio.live\n",
            "\n",
            "This share link expires in 72 hours. For free permanent hosting and GPU upgrades, run `gradio deploy` from Terminal to deploy to Spaces (https://huggingface.co/spaces)\n",
            "Startup time: 74.0s (prepare environment: 29.9s, launcher: 0.7s, import torch: 20.8s, initialize shared: 0.5s, other imports: 2.2s, list SD models: 1.4s, load scripts: 6.8s, create ui: 4.7s, gradio launch: 3.7s, add APIs: 1.6s, app_started_callback: 1.4s).\n",
            "2025-01-12 17:03:51 DEBUG [matplotlib.pyplot] Loaded backend agg version v2.2.\n",
            "2025-01-12 17:03:51 DEBUG [matplotlib.pyplot] Loaded backend module://ipykernel.pylab.backend_inline version unknown.\n",
            "2025-01-12 17:03:51 DEBUG [matplotlib.pyplot] Loaded backend agg version v2.2.\n",
            "2025-01-12 17:03:51 DEBUG [matplotlib.pyplot] Loaded backend module://ipykernel.pylab.backend_inline version unknown.\n",
            "2025-01-12 17:03:51 DEBUG [matplotlib.pyplot] Loaded backend agg version v2.2.\n",
            "Environment vars changed: {'stream': False, 'inference_memory': 1024.0, 'pin_shared_memory': False}\n",
            "[GPU Setting] You will use 93.22% GPU memory (14078.00 MB) to load weights, and use 6.78% GPU memory (1024.00 MB) to do matrix computation.\n",
            "2025-01-12 17:03:51 DEBUG [git.cmd] Popen(['git', 'remote', 'get-url', '--all', 'origin'], cwd=/content/drive/MyDrive/stable-diffusion-webui, universal_newlines=False, shell=None, istream=None)\n",
            "2025-01-12 17:03:51 DEBUG [git.cmd] Popen(['git', 'cat-file', '--batch-check'], cwd=/content/drive/MyDrive/stable-diffusion-webui, universal_newlines=False, shell=None, istream=<valid stream>)\n",
            "2025-01-12 17:03:51 DEBUG [git.cmd] Popen(['git', 'cat-file', '--batch'], cwd=/content/drive/MyDrive/stable-diffusion-webui, universal_newlines=False, shell=None, istream=<valid stream>)\n",
            "2025-01-12 17:03:51 DEBUG [git.cmd] Popen(['git', 'remote', 'get-url', '--all', 'origin'], cwd=/content/drive/MyDrive/stable-diffusion-webui, universal_newlines=False, shell=None, istream=None)\n",
            "2025-01-12 17:03:51 DEBUG [git.cmd] Popen(['git', 'cat-file', '--batch-check'], cwd=/content/drive/MyDrive/stable-diffusion-webui, universal_newlines=False, shell=None, istream=<valid stream>)\n",
            "2025-01-12 17:03:51 DEBUG [git.cmd] Popen(['git', 'cat-file', '--batch'], cwd=/content/drive/MyDrive/stable-diffusion-webui, universal_newlines=False, shell=None, istream=<valid stream>)\n",
            "2025-01-12 17:05:22 INFO [modules.shared_state] Starting job task(njwwmq70tnigyzx)\n",
            "Loading Model: {'checkpoint_info': {'filename': '/content/drive/MyDrive/stable-diffusion-webui/models/Stable-diffusion/noobaiXLNAIXL_vPred06Version.safetensors', 'hash': '25dc06a8'}, 'additional_modules': [], 'unet_storage_dtype': None}\n",
            "[Unload] Trying to free all memory for cuda:0 with 0 models keep loaded ... Done.\n",
            "StateDict Keys: {'unet': 1680, 'vae': 248, 'text_encoder': 196, 'text_encoder_2': 518, 'ignore': 0}\n",
            "Working with z of shape (1, 4, 32, 32) = 4096 dimensions.\n",
            "K-Model Created: {'storage_dtype': torch.float16, 'computation_dtype': torch.float16}\n",
            "Model loaded in 47.4s (unload existing model: 0.6s, forge model load: 46.9s).\n",
            "/content/drive/MyDrive/stable-diffusion-webui/modules_forge/patch_basic.py:38: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  result = original_loader(*args, **kwargs)\n",
            "[LORA] Loaded /content/drive/MyDrive/stable-diffusion-webui/models/Lora/lora-mrnf/Ender_Lilies_.safetensors for KModel-UNet with 722 keys at weight 1.0 (skipped 0 keys) with on_the_fly = False\n",
            "[LORA] Loaded /content/drive/MyDrive/stable-diffusion-webui/models/Lora/lora-mrnf/Ender_Lilies_.safetensors for KModel-CLIP with 264 keys at weight 1.0 (skipped 0 keys) with on_the_fly = False\n",
            "[Unload] Trying to free 3051.58 MB for cuda:0 with 0 models keep loaded ... Done.\n",
            "[Memory Management] Target: JointTextEncoder, Free GPU: 9879.66 MB, Model Require: 1559.68 MB, Previously Loaded: 0.00 MB, Inference Require: 1024.00 MB, Remaining: 7295.98 MB, All loaded to GPU.\n",
            "Moving model(s) has taken 2.04 seconds\n",
            "[Unload] Trying to free 1024.00 MB for cuda:0 with 1 models keep loaded ... Current free memory is 8083.06 MB ... Done.\n",
            "[Unload] Trying to free 2856.18 MB for cuda:0 with 0 models keep loaded ... Current free memory is 8080.94 MB ... Done.\n",
            "[Memory Management] Target: KModel, Free GPU: 8080.94 MB, Model Require: 0.00 MB, Previously Loaded: 4897.05 MB, Inference Require: 1024.00 MB, Remaining: 7056.94 MB, All loaded to GPU.\n",
            "Moving model(s) has taken 3.48 seconds\n",
            "100% 20/20 [00:16<00:00,  1.24it/s]\n",
            "[Unload] Trying to free 8820.57 MB for cuda:0 with 0 models keep loaded ... Current free memory is 8084.07 MB ... Unload model JointTextEncoder Current free memory is 9844.68 MB ... Done.\n",
            "[Memory Management] Target: IntegratedAutoencoderKL, Free GPU: 9844.68 MB, Model Require: 319.11 MB, Previously Loaded: 0.00 MB, Inference Require: 1024.00 MB, Remaining: 8501.57 MB, All loaded to GPU.\n",
            "Moving model(s) has taken 2.08 seconds\n",
            "2025-01-12 17:06:39 INFO [modules.shared_state] Ending job task(njwwmq70tnigyzx) (77.52 seconds)\n",
            "2025-01-12 17:13:33 INFO [modules.shared_state] Starting job task(f6xrvuvozbp3o1i)\n",
            "[Unload] Trying to free 3302.87 MB for cuda:0 with 0 models keep loaded ... Current free memory is 9520.68 MB ... Done.\n",
            "[Memory Management] Target: JointTextEncoder, Free GPU: 9520.68 MB, Model Require: 1752.98 MB, Previously Loaded: 0.00 MB, Inference Require: 1024.00 MB, Remaining: 6743.70 MB, All loaded to GPU.\n",
            "Moving model(s) has taken 0.95 seconds\n",
            "[Unload] Trying to free 1024.00 MB for cuda:0 with 1 models keep loaded ... Current free memory is 7758.19 MB ... Done.\n",
            "[Unload] Trying to free 1264.64 MB for cuda:0 with 1 models keep loaded ... Current free memory is 7756.06 MB ... Done.\n",
            "100% 20/20 [00:14<00:00,  1.34it/s]\n",
            "[Unload] Trying to free 8405.72 MB for cuda:0 with 1 models keep loaded ... Current free memory is 7755.58 MB ... Unload model JointTextEncoder Current free memory is 9516.81 MB ... Done.\n",
            "Memory cleanup has taken 1.84 seconds\n",
            "[Unload] Trying to free 1264.64 MB for cuda:0 with 1 models keep loaded ... Current free memory is 9516.81 MB ... Done.\n",
            "100% 20/20 [00:15<00:00,  1.30it/s]\n",
            "[Unload] Trying to free 8405.72 MB for cuda:0 with 1 models keep loaded ... Current free memory is 9516.33 MB ... Done.\n",
            "[Unload] Trying to free 1264.64 MB for cuda:0 with 1 models keep loaded ... Current free memory is 9516.33 MB ... Done.\n",
            "100% 20/20 [00:15<00:00,  1.27it/s]\n",
            "[Unload] Trying to free 8405.72 MB for cuda:0 with 1 models keep loaded ... Current free memory is 9515.84 MB ... Done.\n",
            "[Unload] Trying to free 1264.64 MB for cuda:0 with 1 models keep loaded ... Current free memory is 9515.84 MB ... Done.\n",
            "100% 20/20 [00:15<00:00,  1.30it/s]\n",
            "[Unload] Trying to free 8405.72 MB for cuda:0 with 1 models keep loaded ... Current free memory is 9513.36 MB ... Done.\n",
            "[Unload] Trying to free 1264.64 MB for cuda:0 with 1 models keep loaded ... Current free memory is 9513.36 MB ... Done.\n",
            "100% 20/20 [00:15<00:00,  1.31it/s]\n",
            "[Unload] Trying to free 8405.72 MB for cuda:0 with 1 models keep loaded ... Current free memory is 9512.88 MB ... Done.\n",
            "[Unload] Trying to free 1264.64 MB for cuda:0 with 1 models keep loaded ... Current free memory is 9512.88 MB ... Done.\n",
            "100% 20/20 [00:15<00:00,  1.31it/s]\n",
            "[Unload] Trying to free 8405.72 MB for cuda:0 with 1 models keep loaded ... Current free memory is 9513.36 MB ... Done.\n",
            "[Unload] Trying to free 1264.64 MB for cuda:0 with 1 models keep loaded ... Current free memory is 9513.36 MB ... Done.\n",
            "100% 20/20 [00:15<00:00,  1.30it/s]\n",
            "[Unload] Trying to free 8405.72 MB for cuda:0 with 1 models keep loaded ... Current free memory is 9512.88 MB ... Done.\n",
            "[Unload] Trying to free 1264.64 MB for cuda:0 with 1 models keep loaded ... Current free memory is 9512.88 MB ... Done.\n",
            "100% 20/20 [00:15<00:00,  1.30it/s]\n",
            "[Unload] Trying to free 8405.72 MB for cuda:0 with 1 models keep loaded ... Current free memory is 9512.40 MB ... Done.\n",
            "[Unload] Trying to free 1264.64 MB for cuda:0 with 1 models keep loaded ... Current free memory is 9512.40 MB ... Done.\n",
            " 65% 13/20 [00:09<00:05,  1.31it/s]"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title üëá 1.ÂÆâË£ÖSDwebui-frogeÂà∞Ë∞∑Ê≠å‰∫ëÁõòÔºÅ\n",
        "# ËØ•ËÑöÊú¨‰ºöÂ∞Ü Forge ‰ªìÂ∫ì‰Ωú‰∏∫‰∏ªÈ°πÁõÆÔºåË¶ÜÁõñÂéü WebUI ÁõÆÂΩï\n",
        "\n",
        "import os\n",
        "import binascii\n",
        "\n",
        "# ËøêË°åÊó∂ÁéØÂ¢ÉËÆæÁΩÆ\n",
        "%cd /content\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# ÁºñËß£Á†ÅÂ≠óËäÇ‰∏≤ÔºàÈÄöËøá uu ÁºñÁ†ÅÁöÑÂ≠óÁ¨¶‰∏≤Ëß£Á†ÅÔºâ\n",
        "sdw = binascii.a2b_uu(\"6<W1A8FQE+61I9F9U<VEO;BUW96)U:0``\").decode('utf-8')  # Ëé∑Âèñ WebUI ÁöÑÊñá‰ª∂Â§πÂêçÁß∞\n",
        "webui_dir = f'/content/{sdw}'  # WebUI Â≠òÂÇ®ÁõÆÂΩï\n",
        "gwebui_dir = f'/content/drive/MyDrive/{sdw}'  # Google Drive ‰∏äÁöÑ WebUI ÁõÆÂΩï\n",
        "%env PYTHONDONTWRITEBYTECODE=1  # Èò≤Ê≠¢ÂÜôÂÖ• pyc Êñá‰ª∂\n",
        "print(\"ÂÖãÈöÜ Forge WebUI ‰∏ªÁ®ãÂ∫è...\")\n",
        "# stable-diffusion-webui-forge ‰ªìÂ∫ìÁöÑ URL\n",
        "repo_forge = \"https://github.com/lllyasviel/stable-diffusion-webui-forge.git\"  # stable-diffusion-webui-forge ‰ªìÂ∫ìÁöÑ URL\n",
        "\n",
        "# Ê£ÄÊü•ÂΩìÂâçÁõÆÂΩïÊòØÂê¶ÊòØ Git ‰ªìÂ∫ì\n",
        "if os.path.exists(webui_dir) and os.path.isdir(os.path.join(webui_dir, '.git')):\n",
        "    print(f\"{webui_dir} ÊòØ‰∏Ä‰∏™ÊúâÊïàÁöÑ Git ‰ªìÂ∫ìÔºåÂáÜÂ§áÂàáÊç¢Âà∞ stable-diffusion-webui-forge ‰ªìÂ∫ì...\")\n",
        "\n",
        "    # ‰øÆÊîπËøúÁ®ã‰ªìÂ∫ìÂú∞ÂùÄ‰∏∫ stable-diffusion-webui-forge ‰ªìÂ∫ì\n",
        "    !cd {webui_dir} && git remote remove origin  # ÁßªÈô§ÂΩìÂâçÁöÑËøúÁ®ã‰ªìÂ∫ìÈÖçÁΩÆ\n",
        "    !cd {webui_dir} && git remote add origin {repo_forge}  # Ê∑ªÂä† stable-diffusion-webui-forge ‰Ωú‰∏∫Êñ∞ÁöÑËøúÁ®ã‰ªìÂ∫ì\n",
        "\n",
        "    # ÊãâÂèñ stable-diffusion-webui-forge ‰ªìÂ∫ìÁöÑÂÜÖÂÆπ\n",
        "    print(\"ÊãâÂèñ stable-diffusion-webui-forge ‰ªìÂ∫ìÁöÑÊúÄÊñ∞ÂÜÖÂÆπ...\")\n",
        "    !cd {webui_dir} && git pull origin main  # ‰ªéÊñ∞ÁöÑ‰ªìÂ∫ìÊãâÂèñÊúÄÊñ∞ÁöÑ‰ª£Á†Å\n",
        "    !rsync -avq {webui_dir}/ {gwebui_dir}/\n",
        "\n",
        "\n",
        "    print(f\"{webui_dir} Â∑≤ÊàêÂäüÊõ¥Êñ∞‰∏∫ stable-diffusion-webui-forge ‰ªìÂ∫ìÁöÑÂÜÖÂÆπ„ÄÇ\")\n",
        "else:\n",
        "    print(f\"{webui_dir} ‰∏çÊòØ‰∏Ä‰∏™ÊúâÊïàÁöÑ Git ‰ªìÂ∫ìÔºåÂáÜÂ§áÂÖãÈöÜ stable-diffusion-webui-forge ‰ªìÂ∫ì...\")\n",
        "    !git clone -q --branch main {repo_forge} {webui_dir}  # ÂÖãÈöÜ stable-diffusion-webui-forge Âà∞ÊåáÂÆöÁõÆÂΩï\n",
        "    !rsync -avq {webui_dir}/ {gwebui_dir}/\n",
        "\n",
        "    print(\"ÂÖãÈöÜ\")\n",
        "# ÂÆåÊàêÂêéËæìÂá∫ÊèêÁ§∫\n",
        "print(\"Forge WebUI ÂÆâË£ÖÂíåÊõ¥Êñ∞ÂÆåÊàê„ÄÇÂèØ‰ª•Âú® Google Drive ‰∏≠ÊâæÂà∞Âπ∂ÂêØÂä® WebUI„ÄÇ\")\n"
      ],
      "metadata": {
        "id": "RBmqVVYuOBWd",
        "outputId": "ed443ef1-e6e1-467c-eed7-16567c86fd77",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content\n",
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "env: PYTHONDONTWRITEBYTECODE=1  # Èò≤Ê≠¢ÂÜôÂÖ• pyc Êñá‰ª∂\n",
            "ÂÖãÈöÜ Forge WebUI ‰∏ªÁ®ãÂ∫è...\n",
            "/content/stable-diffusion-webui ‰∏çÊòØ‰∏Ä‰∏™ÊúâÊïàÁöÑ Git ‰ªìÂ∫ìÔºåÂáÜÂ§áÂÖãÈöÜ stable-diffusion-webui-forge ‰ªìÂ∫ì...\n",
            "ÂÖãÈöÜ\n",
            "Forge WebUI ÂÆâË£ÖÂíåÊõ¥Êñ∞ÂÆåÊàê„ÄÇÂèØ‰ª•Âú® Google Drive ‰∏≠ÊâæÂà∞Âπ∂ÂêØÂä® WebUI„ÄÇ\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}